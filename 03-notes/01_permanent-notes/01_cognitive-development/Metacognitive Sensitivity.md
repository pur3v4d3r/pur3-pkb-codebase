---
title: Metacognitive Sensitivity
id: 20251105-024830
type: ðŸ§¬concept
status: active
rating: ""
source: ""
url: ""
tags:
  - type/report/psychology
  - cognitive-science
  - cognitive-science
  - project/pur3v4d3r
  - cognitive-science
aliases:
  - Metacognitive Sensitivity
link-up:
  - "[[cog-psy-report-how-can-an-individual-design-a-selfdevelopment-system-that-accurately-measures-personalgrowth-when-the-dunning-kruger-effect-self-assessment-20251105020711]]"
link-related:
  - "[[Calibration Theory]]"
  - "[[Metacognition]]"
  - "[[Illusions Of Comprehension]]"
date created: 2025-11-05T02:39:53
date modified: 2025-11-05T21:48:01
maturity: seedling
confidence: speculative


review-last-reviewed: null
review-next-review: 2025-12-17
review-count: 0
review-interval: 3

review-priority: medium
---

> [!definition]
> - **Key Term:** [[Metacognitive Sensitivity|Metacognitive Sensitivity vs. Metacognitive Bias]]
>     - These represent two orthogonal dimensions of metacognitive accuracy. **Metacognitive sensitivity** (also called type-2 sensitivity or discrimination) measures how well your confidence ratings separate correct from incorrect responsesâ€”when you're confident, are you more likely to be right? A person with high sensitivity issues confidence ratings that are tightly coupled with accuracy. **Metacognitive bias** (also called type-2 bias, calibration, or over/underconfidence) measures the overall level of your confidence judgments relative to your actual performanceâ€”independent of sensitivity. You could have perfect sensitivity (confidence always predicts accuracy) but terrible bias (you're systematically $30$ percentage points overconfident). Both dimensions must be addressed in a complete measurement system.
