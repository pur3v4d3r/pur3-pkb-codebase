---
title: Instruction Misinterpretation
id: 20251111-040453
type: ðŸ§¬concept
status: active
rating: ""
source: ""
url: ""
tags:
  - permanent-note
  - permanent-note/pkb
  - prompt-engineering
aliases:
  - Instruction Misinterpretation
link-up:
  - "[[self-learning-and-cognitive-development-moc]]"
link-related:
  - "[[Knowledge Gaps]]"
  - "[[Reasoning Failures]]"
  - "[[Format Deviations]]"
  - "[[Context Limitations]]"
maturity: seedling
confidence: speculative


review-last-reviewed: null
review-next-review: 2025-12-17
review-count: 0
review-interval: 3

review-priority: medium
---

> [!definition]
> - **Key-Term**:: [[Instruction Misinterpretation]]
> - [**Definition**:: The model follows instructions literally but not as intended.]

 This **often stems** from *ambiguous language*, *conflicting instructions*, or *implicit assumptions*.
- **Solution**: Make instructions *maximally explicit*, *resolve conflicts*, *state assumptions clearly*. **Test** with **diverse inputs** to surface misinterpretations.

> [!connections-and-links]
> - [[atomic-notes_moc]]: This is a link to the *Main Hub* for all **Atomic Notes**, from there you will find sections of each of the various *Subjects* I have been **working on**.
