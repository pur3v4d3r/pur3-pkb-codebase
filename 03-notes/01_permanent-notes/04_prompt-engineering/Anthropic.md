---
title: Anthropic
id: 20251111-100528
type: ðŸ§¬concept
tags:
  - topic/
  - type/pur3
aliases:
  - Anthropic
link-up:
  - "[[permeant-note_moc]]"
link-related:
  - "[[03-notes/01_permanent-notes/04_prompt-engineering/Claude]]"
  - "[[Claude Project]]"
  - "[[Constitutional Ai]]"
  - "[[Generative Ai]]"
  - "[[Large Language Models]]"
  - "[[Prompt Engineering]]"
  - "[[Reinforcement Learning From Human Feedback]]"
  - "[[Gemini]]"
maturity: seedling
confidence: speculative
status: active


review-last-reviewed: null
review-next-review: 2025-12-17
review-count: 0
review-interval: 3

review-priority: medium
---




> [!definition]
> - **Key-Term**:: [[Anthropic]]
> - [**Definition**:: Anthropic PBC is the name of the AI research and development company that created the Claude family of large language models (LLMs).
>   - **The Name's Origin**: The name "Anthropic" comes from the Greek word anthrÅpikÃ³s, meaning "of or relating to human beings". The name reflects the company's mission to build AI systems that are safe, reliable, and aligned with human values.
>   - **The Approach (Constitutional AI)**: Anthropic is known for its strong focus on AI safety and ethics, particularly its development of a training method called Constitutional AI (CAI). This framework uses a set of ethical principles (a "constitution") to guide the AI's behavior, making it more "helpful, honest, and harmless" without relying solely on extensive human supervision.
>   - **Human-Centric Goal**: The company's overall purpose is the responsible development of advanced AI for the long-term benefit of humanity, emphasizing interpretability and steerability of AI systems to ensure they can be understood and controlled by humans.]

> [!questions]
> Active Question During the creation or viewing of this Permeant Note.

