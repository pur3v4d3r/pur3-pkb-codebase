---
title: üìùPrompt_Improve-Current-Prompting-Workflow_üÜî20251019182053
id: 20251019182109
aliases:
  - prompt
  - prompt-engineering
  - prompting
  - prompts
type: üìùprompt
status: ‚ö™dormant
priority: ‚ÅâÔ∏è
created: 2025-10-19T18:21:09
source: gemini-2.5-flash
url: ‚ÅâÔ∏è
tags:
  - type/prompt
  - prompt-engineering
  - prompt-engineering
  - type/prompt
description: to analyze, deconstruct, and radically enhance a proposed workflow for generating academic research reports for a Personal Knowledge Base (PKB).
version: "1.0"
success-rating: üîç‚ÅâÔ∏èneeds-review
date created: 2025-10-19T18:21:09.000-04:00
date modified: 2025-10-19T19:12:59.156-04:00
---

```prompt
---
id: prompt-block-üÜî20251019182053
---

### **Mandate and Persona Directive**

**Act as a highly accomplished Research Director and Information Architect.** Your task is to analyze, deconstruct, and radically enhance a proposed workflow for generating academic research reports for a **Personal Knowledge Base (PKB)**. The core deliverable must be a strategy that ensures **maximum intellectual depth, conceptual coherence, and long-term utility** of the compiled knowledge.

Your response must be delivered in a **thorough, philosophically engaging, and educational** manner, ensuring I understand not just *what* to do, but the **WHY** behind every strategic improvement.

### **Goal and Focus**

My goal is to create a multi-model, advanced workflow that maximizes the **depth, accuracy, and educational value** of the research articles and reports I generate, ensuring everything contributes meaningfully to my PKB in Obsidian. **Quality is the paramount concern, always prevailing over quantity.**

### **Phase 1: Workflow Analysis and Improvement Strategy**

Analyze the **"My Current Workflow"** section provided below. Your primary task is to develop a complete, multi-faceted strategy for its improvement. This strategy must address and elaborate on the following four points:

1.  **Introduce a Structured Prompt Engineering Framework (The WHY of Drafting):**
    * Propose a named, formalized system (e.g., "The Iterative Fidelity Framework," "The Clarity Cascade Method") that structures the prompt drafting and refinement process.
    * This framework must begin with a mandatory **Advanced Role and Constraint Directive** to focus the AI's output from the start.
    * It should introduce specific, high-leverage techniques (e.g., meta-prompts, constrained output formats, explicit negative constraints) that move beyond simple iteration.
2.  **Optimize the Multi-Model Testing Protocol (The WHY of Comparison):**
    * Provide specific, actionable **heuristics for qualitative comparison** of the $5-10+$ model outputs.
    * Define concrete metrics and criteria for review (e.g., **"Conceptual Coherence Score," "Evidential Density Rating," "Citation Rigor Index"**) to make the review process more objective and efficient than simple side-by-side reading.
3.  **Enhance PKB Integration and Documentation (The WHY of Retention):**
    * Design a structured, mandatory **Reflection and Evaluation** step that *precedes* the compilation process.
    * This step must define and capture metrics for the prompt's success and the report's quality. These captured metrics must be integrated as new, standardized fields into the existing Obsidian **Front Matter** list.
4.  **Enrich the "Active Reading" and Post-Generation Process (The WHY of Synthesis):**
    * Propose high-value, active-learning activities that should occur *after* the initial generation and note-taking (addressing Step 9 in the current workflow).
    * These activities must focus on **synthesizing** the new information with existing PKB knowledge to ensure **deep understanding** and **conceptual integration** (e.g., creating synthesis maps, contradiction notes, or new conceptual nodes).

### **My Current Workflow for Review**

*(The following is provided for your analysis and should be referenced in your strategy.)*

1.  **Drafting:** Write a rough draft, then run it through a single AI for initial optimization. (Focus: Educational/Academic reports for research/PKB).
2.  **Testing (Multi-Model):** Run the first version copy through $\approx 5-10+$ AI models, comparing their initial outputs. (Goal: Quality over Quantity. Iteration is assumed).
3.  **Revision Loop:** Review prompt/output, revise the prompt to improve it, and repeat Step 2.
4.  **Finalization:** Perform a final short review, then either continue revision or move to full report/notes compilation.
5.  **PKB Compilation:** Compile all information into separate Obsidian notes (Prompt versions, Full Chat Log, Final Report).
6.  **Note Standardization (Mandatory):** Add **Front Matter** (using the list below), Tidy the note with a custom Linter profile, Double-check Front Matter, and remove excessive blank spaces.
7.  **Note Standardization (Optional/Likely):** Add **Callouts** for visual structure and future self-attention, and brief tidying/emoji.
8.  **Active Reading:** Purposefully sit down to *‚ÄúActively Read‚Äù* the content, taking notes on **a)** learning the topic, and **b)** the performance of each model.
9.  **Post-Process:** *(This is the final area for improvement in Phase 1's strategy.)*

#### **Current General Note Front Matter:**

* `title`
* `aliases`
* `tags`
* `status`
* `created`
* `updated`
* `source`
* `related`

### **Phase 2: Deliverables**

Provide the entire proposed new workflow as a complete, sequential **Checklist**. This checklist must be structured and immediately actionable, serving as the new standard operating procedure.

---

```

# The Draft

```draft
These are some thoughts I currently have, and would like to turn them into a prompt. One that is fully capable of accomplishing my goal. Will you read over this and re-work/re-write it so that its the best it can be?

## Goal

I need an advanced workflow for prompting.

I need you to review my current workflow (Below) and improvise a strategy for improving it in any as many ways as possible. I also require a complete checklist for all of this.
## My current Workflow

**Currently, I:**
1. Write out a rough draft and work through the process of building it up, maybe run it through one of the AI, that I have set up for prompt optimization.[^1]
2. Implement the now first version copy of the prompt, by running it through one or sometimes up to 10+ AI models, testing each of their outputs to one another.[^2]
3. I will review the prompt and output and change the prompt to improve it if need be. And then I repeat step 2.[^3]
4. After receiving the next round of output I perform another short review, at this point I will either continue revising the prompt or finish it, and move to the reports to full review.
5. When I choose to finish the prompt, all the information gets compiled into different notes, inside my [[PKB]] in Obsidian.[^4]
	- These notes consist of:
		- The prompt, and its various versions, gets a note.
		- The entire chat log, gets a note. (Which include the prompt, both sides of the conversation, and the final report.)
		- The report, or document, gets a note.
		- **Note:** I'm working on a way of implementing my thoughts on the prompts success and the reports' outcome Etc.(a review of sorts)[^5]
6. Each note gets a:
	- **These Must happen Each Note:**
		- Front matter section (Must Happen Every Time)
		- Tidy up the note with custom Linter profile.
		- Double check front matter is working and information is correct. Fill in any missing information.
		- Get rid of any super excessive blank spaces.
	- **These are options to add to each note:**(But usually end up happening.)
		- Callouts to add visuals and draw attention to the purpose of this note for future self.
		- Briefly spend time adding emoji and tiding up the note.
7. After completion of the notes, I will sit down, purposefully, to *‚ÄúActively Read‚Äù* the content.
	- And take notes on both on the written word (IE. Learning the topic) and on the performance of each of the models.
8. *This is where you will add in anything I should be doing after this point.*

## List of my current front matter for use on general notes.

- title
- aliases
- tags
- status
- created
- updated
- source
- related

[^1]: Mostly I deal with Educational/Academic reports on various topics for research and to contribute to my PKB.

[^2]: On average, I would say every prompt will be run through roughly 5 AI. (That DOES NOT count the iterative process.)

[^3]: I will only repeat step 2 if I plan to change the prompt which is all the time.

[^4]: My goal is QUALITY OVER QUANITY. ALWAYS.

[^5]: I need your help here in looking up the best practices for doing this. But don't spendtooo much time here I will dedicate a whole prompt to that. Your main focus is to evolve this workflow.
```
