---
title: The G.C.S.E. Framework (Goal, Context, Source, Expectations)
aliases: [AI Prompt Engineering Framework, GCSE Prompting Framework, Goal-Context-Source-Expectations]
tags: [prompt-engineering, type/report/psychology, workflow]
status: seedling
created: 2024-09-29
updated: 2024-09-29
source: 
related:

date created: Sunday, September 28th 2025, 6:39:16 pm
date modified: Monday, September 29th 2025, 12:30:21 am
---

#### Sources:

[^1]: [[Note-Taking for Different Subjects and Contexts]]
[^2]: [[Types of Notes]]
[^3]: [[Outline Note Method]]
[^4]: [[Visual and Associative Methods for Note Taking]]
[^5]: [[How to Properly Cite a Source]]
[^6]: [[Advanced Search Engine Use]]
[^7]: [[ref_chatgpt_research_guide-to-moc's_2025-09-23]]
[^8]: [[ChatGPT Universal Smart Note Template SOP]]
[^9]: [[The Main Goal of My Notes]]
[^10]: [[PICO Framework for Research Questions]]
[^11]: [[S I F T - Lateral Reading for Source Verification]]
[^12]: [[Workflow for Evaluating Sources and Information]]
[^13]: [[The Toulmin Model]]
[^14]: [[Source Evaluation - A Three Tiered Approach]]
[^15]: [[ref_notes_guide-to-active-reading-by-ai's_2025-09-24]]
[^16]: [[Common Logical Fallacies]]
[^17]: [[Function of Notes is Important]]
[^18]: [[Document Your Searches during Research]]
[^19]: [[The SQ3R Active Reading Method]]
[^20]: [[REF_Gemini-Chat_Response-to-Note_Researching Material for use in Vault_2025-09-12]]

> [!the-purpose]
> This is a framework developed by Gemini using a prompt I (Pur3v4d3r) designed. This framework describes a process by which the user can create prompts specifically for the use within the [[PKB]]. The [[The G.C.S.E. Framework (Goal, Context, Source, Expectations)|G.C.S.E.]] framework should be rigorously applied each and every time you create a new prompt or add an existing prompt to your growing prompt library. I have left a selsction of useful links that you can use to go deeper into this if you like or need reference.
> 
> - [[Draft_Copilot-Prompt-Aquisition_Pur3v4d3r]]
> 	- This is a link to the original prompt the I (Pur3v4d3r) developed, and deployed.
> - [[REF_Gemini-Deep-Research_AI-Augmented-Vault_Strategic-Prompting-Guide-for-Copilot-&-Plugin Synergy_2025-09-28]]
> 	- This is a link to the original article written by [[Gemini]]. 
> 		- Using the prompt from above.
> - [[The AI-Augmented Vault Guide for Obsidian Copilot and Plugin Synergy]]
> 	- This is a link to another article that was generated using this same exact prompt.
> 		- This Note however, is composed of many different AIs that I ran the original prompt through. 
> 		- This give you a nice overview of what each model is currently capable of. ([[2025-09-28]])

# The G.C.S.E. Framework

- **Goal:** The Goal is the **clear and specific articulation of the desired outcome**. It defines _what_ the AI should produce. This **instruction should be direct and action-oriented**. Instead of a vague request like "help with this text," a precise goal would be "Generate 3-5 bullet points summarizing this text" or "Draft an outline for a blog post based on these ideas". **Effective prompts often use positive instructions**, telling the AI what to do rather than what to avoid. For example, "Give me a list of high-risk unmanaged devices, removing any named 'test'" is more effective than "Give me a list of unmanaged devices, but don't include test devices".
    
- **Context:** The Context provides the "**why**" behind the request, guiding the AI's tone, complexity, and focus. **This element explains the purpose of the output, the target audience, or the broader project it contributes to**. For instance, adding "...to prepare me for a meeting with a client" or "...for a presentation to a non-technical audience" fundamentally alters the AI's response, ensuring it is fit for purpose. *This contextual layer is what elevates the AI from a simple text generator to a genuine assistant that understands intent.*
    
- **Source:** **The Source specifies the raw material the AI should use for its task**. In many applications, this involves manually pasting text into the prompt. However, within Obsidian, the source is far more dynamic. **It can be a selection of text, the content of the currently active note, a specific linked note, or even the aggregated content of an entire folder or a collection of tagged notes.** This ability to dynamically define the source material is a cornerstone of advanced AI workflows in Obsidian.
    
- **Expectations:** The Expectations element **details the desired format, structure, and any constraints for the output**. This is where the user dictates the final presentation of the information. Instructions can include specifying Markdown formatting (e.g., "Use H2 for main sections"), a particular tone of voice (e.g., "The tone should be formal and academic"), or adhering to a specific length or structure (e.g., "The summary must be under 200 words and presented as a single paragraph").
    

*A fundamental shift occurs when applying this framework within Obsidian. The vault's inherent structure —* **its network of links, its system of tags, its organization into folders — becomes the most potent provider of `Context` and `Source`.** *A well-architected vault is inherently more* "**promptable**.*" When notes are* **consistently structured with metadata** *(using plugins like Dataview) and organized logically, the* **AI has a richer, more precise set of information to draw from**. *This creates a virtuous cycle: the effort to prepare a vault for effective AI use simultaneously enforces superior knowledge management practices. The act of structuring knowledge for a machine collaborator forces a higher degree of clarity and organization upon the human user, leading to deeper understanding and more robust connections even before a prompt is written. Prompt engineering in Obsidian is therefore not merely a linguistic skill but an extension of knowledge architecture itself.*
