This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.
The content has been processed where empty lines have been removed, line numbers have been added, security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: __LOCAL-REPO/__skills/article-extractor/SKILL.md, __LOCAL-REPO/__skills/d3.js Visualisation/SKILL.md, __LOCAL-REPO/__skills/development/api-integration-specialist/SKILL.md, __LOCAL-REPO/__skills/development/code-reviewer/SKILL.md, __LOCAL-REPO/__skills/development/code-reviewer/scripts/code_quality_checker.py, __LOCAL-REPO/__skills/development/code-reviewer/scripts/pr_analyzer.py, __LOCAL-REPO/__skills/development/code-reviewer/scripts/review_report_generator.py, __LOCAL-REPO/__skills/development/mcp-integration/SKILL.md, __LOCAL-REPO/__skills/development/mcp-integration/references/tool-usage.md, __LOCAL-REPO/__skills/development/mcp-integration/references/server-types.md, __LOCAL-REPO/__skills/development/mcp-integration/references/authentication.md, __LOCAL-REPO/__skills/development/skill-development/SKILL.md, __LOCAL-REPO/__skills/development/subagent-driven-development/SKILL.md, __LOCAL-REPO/__skills/development/systematic-debugging/SKILL.md, __LOCAL-REPO/__skills/development/systematic-debugging/root-cause-tracing.md, __LOCAL-REPO/__skills/development/systematic-debugging/defense-in-depth.md, __LOCAL-REPO/__skills/development/systematic-debugging/condition-based-waiting.md, __LOCAL-REPO/__skills/development/test-driven-development/SKILL.md, __LOCAL-REPO/__skills/development/test-driven-development/testing-anti-patterns.md
- Files matching patterns in .gitignore are excluded
- Empty lines have been removed from all files
- Line numbers have been added to the beginning of each line
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
__LOCAL-REPO/__skills/article-extractor/SKILL.md
__LOCAL-REPO/__skills/d3.js Visualisation/SKILL.md
__LOCAL-REPO/__skills/development/api-integration-specialist/SKILL.md
__LOCAL-REPO/__skills/development/code-reviewer/scripts/code_quality_checker.py
__LOCAL-REPO/__skills/development/code-reviewer/scripts/pr_analyzer.py
__LOCAL-REPO/__skills/development/code-reviewer/scripts/review_report_generator.py
__LOCAL-REPO/__skills/development/code-reviewer/SKILL.md
__LOCAL-REPO/__skills/development/mcp-integration/references/authentication.md
__LOCAL-REPO/__skills/development/mcp-integration/references/server-types.md
__LOCAL-REPO/__skills/development/mcp-integration/references/tool-usage.md
__LOCAL-REPO/__skills/development/mcp-integration/SKILL.md
__LOCAL-REPO/__skills/development/skill-development/SKILL.md
__LOCAL-REPO/__skills/development/subagent-driven-development/SKILL.md
__LOCAL-REPO/__skills/development/systematic-debugging/condition-based-waiting.md
__LOCAL-REPO/__skills/development/systematic-debugging/defense-in-depth.md
__LOCAL-REPO/__skills/development/systematic-debugging/root-cause-tracing.md
__LOCAL-REPO/__skills/development/systematic-debugging/SKILL.md
__LOCAL-REPO/__skills/development/test-driven-development/SKILL.md
__LOCAL-REPO/__skills/development/test-driven-development/testing-anti-patterns.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="__LOCAL-REPO/__skills/article-extractor/SKILL.md">
  1: ---
  2: name: article-extractor
  3: description: Extract clean article content from URLs (blog posts, articles, tutorials) and save as readable text. Use when user wants to download, extract, or save an article/blog post from a URL without ads, navigation, or clutter.
  4: allowed-tools: Bash,Write
  5: ---
  6: 
  7: # Article Extractor
  8: 
  9: This skill extracts the main content from web articles and blog posts, removing navigation, ads, newsletter signups, and other clutter. Saves clean, readable text.
 10: 
 11: ## When to Use This Skill
 12: 
 13: Activate when the user:
 14: - Provides an article/blog URL and wants the text content
 15: - Asks to "download this article"
 16: - Wants to "extract the content from [URL]"
 17: - Asks to "save this blog post as text"
 18: - Needs clean article text without distractions
 19: 
 20: ## How It Works
 21: 
 22: ### Priority Order:
 23: 1. **Check if tools are installed** (reader or trafilatura)
 24: 2. **Download and extract article** using best available tool
 25: 3. **Clean up the content** (remove extra whitespace, format properly)
 26: 4. **Save to file** with article title as filename
 27: 5. **Confirm location** and show preview
 28: 
 29: ## Installation Check
 30: 
 31: Check for article extraction tools in this order:
 32: 
 33: ### Option 1: reader (Recommended - Mozilla's Readability)
 34: 
 35: ```bash
 36: command -v reader
 37: ```
 38: 
 39: If not installed:
 40: ```bash
 41: npm install -g @mozilla/readability-cli
 42: # or
 43: npm install -g reader-cli
 44: ```
 45: 
 46: ### Option 2: trafilatura (Python-based, very good)
 47: 
 48: ```bash
 49: command -v trafilatura
 50: ```
 51: 
 52: If not installed:
 53: ```bash
 54: pip3 install trafilatura
 55: ```
 56: 
 57: ### Option 3: Fallback (curl + simple parsing)
 58: 
 59: If no tools available, use basic curl + text extraction (less reliable but works)
 60: 
 61: ## Extraction Methods
 62: 
 63: ### Method 1: Using reader (Best for most articles)
 64: 
 65: ```bash
 66: # Extract article
 67: reader "URL" > article.txt
 68: ```
 69: 
 70: **Pros:**
 71: - Based on Mozilla's Readability algorithm
 72: - Excellent at removing clutter
 73: - Preserves article structure
 74: 
 75: ### Method 2: Using trafilatura (Best for blogs/news)
 76: 
 77: ```bash
 78: # Extract article
 79: trafilatura --URL "URL" --output-format txt > article.txt
 80: 
 81: # Or with more options
 82: trafilatura --URL "URL" --output-format txt --no-comments --no-tables > article.txt
 83: ```
 84: 
 85: **Pros:**
 86: - Very accurate extraction
 87: - Good with various site structures
 88: - Handles multiple languages
 89: 
 90: **Options:**
 91: - `--no-comments`: Skip comment sections
 92: - `--no-tables`: Skip data tables
 93: - `--precision`: Favor precision over recall
 94: - `--recall`: Extract more content (may include some noise)
 95: 
 96: ### Method 3: Fallback (curl + basic parsing)
 97: 
 98: ```bash
 99: # Download and extract basic content
100: curl -s "URL" | python3 -c "
101: from html.parser import HTMLParser
102: import sys
103: 
104: class ArticleExtractor(HTMLParser):
105:     def __init__(self):
106:         super().__init__()
107:         self.in_content = False
108:         self.content = []
109:         self.skip_tags = {'script', 'style', 'nav', 'header', 'footer', 'aside'}
110:         self.current_tag = None
111: 
112:     def handle_starttag(self, tag, attrs):
113:         if tag not in self.skip_tags:
114:             if tag in {'p', 'article', 'main', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'}:
115:                 self.in_content = True
116:         self.current_tag = tag
117: 
118:     def handle_data(self, data):
119:         if self.in_content and data.strip():
120:             self.content.append(data.strip())
121: 
122:     def get_content(self):
123:         return '\n\n'.join(self.content)
124: 
125: parser = ArticleExtractor()
126: parser.feed(sys.stdin.read())
127: print(parser.get_content())
128: " > article.txt
129: ```
130: 
131: **Note:** This is less reliable but works without dependencies.
132: 
133: ## Getting Article Title
134: 
135: Extract title for filename:
136: 
137: ### Using reader:
138: ```bash
139: # reader outputs markdown with title at top
140: TITLE=$(reader "URL" | head -n 1 | sed 's/^# //')
141: ```
142: 
143: ### Using trafilatura:
144: ```bash
145: # Get metadata including title
146: TITLE=$(trafilatura --URL "URL" --json | python3 -c "import json, sys; print(json.load(sys.stdin)['title'])")
147: ```
148: 
149: ### Using curl (fallback):
150: ```bash
151: TITLE=$(curl -s "URL" | grep -oP '<title>\K[^<]+' | sed 's/ - .*//' | sed 's/ | .*//')
152: ```
153: 
154: ## Filename Creation
155: 
156: Clean title for filesystem:
157: 
158: ```bash
159: # Get title
160: TITLE="Article Title from Website"
161: 
162: # Clean for filesystem (remove special chars, limit length)
163: FILENAME=$(echo "$TITLE" | tr '/' '-' | tr ':' '-' | tr '?' '' | tr '"' '' | tr '<' '' | tr '>' '' | tr '|' '-' | cut -c 1-100 | sed 's/ *$//')
164: 
165: # Add extension
166: FILENAME="${FILENAME}.txt"
167: ```
168: 
169: ## Complete Workflow
170: 
171: ```bash
172: ARTICLE_URL="https://example.com/article"
173: 
174: # Check for tools
175: if command -v reader &> /dev/null; then
176:     TOOL="reader"
177:     echo "Using reader (Mozilla Readability)"
178: elif command -v trafilatura &> /dev/null; then
179:     TOOL="trafilatura"
180:     echo "Using trafilatura"
181: else
182:     TOOL="fallback"
183:     echo "Using fallback method (may be less accurate)"
184: fi
185: 
186: # Extract article
187: case $TOOL in
188:     reader)
189:         # Get content
190:         reader "$ARTICLE_URL" > temp_article.txt
191: 
192:         # Get title (first line after # in markdown)
193:         TITLE=$(head -n 1 temp_article.txt | sed 's/^# //')
194:         ;;
195: 
196:     trafilatura)
197:         # Get title from metadata
198:         METADATA=$(trafilatura --URL "$ARTICLE_URL" --json)
199:         TITLE=$(echo "$METADATA" | python3 -c "import json, sys; print(json.load(sys.stdin).get('title', 'Article'))")
200: 
201:         # Get clean content
202:         trafilatura --URL "$ARTICLE_URL" --output-format txt --no-comments > temp_article.txt
203:         ;;
204: 
205:     fallback)
206:         # Get title
207:         TITLE=$(curl -s "$ARTICLE_URL" | grep -oP '<title>\K[^<]+' | head -n 1)
208:         TITLE=${TITLE%% - *}  # Remove site name
209:         TITLE=${TITLE%% | *}  # Remove site name (alternate)
210: 
211:         # Get content (basic extraction)
212:         curl -s "$ARTICLE_URL" | python3 -c "
213: from html.parser import HTMLParser
214: import sys
215: 
216: class ArticleExtractor(HTMLParser):
217:     def __init__(self):
218:         super().__init__()
219:         self.in_content = False
220:         self.content = []
221:         self.skip_tags = {'script', 'style', 'nav', 'header', 'footer', 'aside', 'form'}
222: 
223:     def handle_starttag(self, tag, attrs):
224:         if tag not in self.skip_tags:
225:             if tag in {'p', 'article', 'main'}:
226:                 self.in_content = True
227:         if tag in {'h1', 'h2', 'h3'}:
228:             self.content.append('\n')
229: 
230:     def handle_data(self, data):
231:         if self.in_content and data.strip():
232:             self.content.append(data.strip())
233: 
234:     def get_content(self):
235:         return '\n\n'.join(self.content)
236: 
237: parser = ArticleExtractor()
238: parser.feed(sys.stdin.read())
239: print(parser.get_content())
240: " > temp_article.txt
241:         ;;
242: esac
243: 
244: # Clean filename
245: FILENAME=$(echo "$TITLE" | tr '/' '-' | tr ':' '-' | tr '?' '' | tr '"' '' | tr '<>' '' | tr '|' '-' | cut -c 1-80 | sed 's/ *$//' | sed 's/^ *//')
246: FILENAME="${FILENAME}.txt"
247: 
248: # Move to final filename
249: mv temp_article.txt "$FILENAME"
250: 
251: # Show result
252: echo "✓ Extracted article: $TITLE"
253: echo "✓ Saved to: $FILENAME"
254: echo ""
255: echo "Preview (first 10 lines):"
256: head -n 10 "$FILENAME"
257: ```
258: 
259: ## Error Handling
260: 
261: ### Common Issues
262: 
263: **1. Tool not installed**
264: - Try alternate tool (reader → trafilatura → fallback)
265: - Offer to install: "Install reader with: npm install -g reader-cli"
266: 
267: **2. Paywall or login required**
268: - Extraction tools may fail
269: - Inform user: "This article requires authentication. Cannot extract."
270: 
271: **3. Invalid URL**
272: - Check URL format
273: - Try with and without redirects
274: 
275: **4. No content extracted**
276: - Site may use heavy JavaScript
277: - Try fallback method
278: - Inform user if extraction fails
279: 
280: **5. Special characters in title**
281: - Clean title for filesystem
282: - Remove: `/`, `:`, `?`, `"`, `<`, `>`, `|`
283: - Replace with `-` or remove
284: 
285: ## Output Format
286: 
287: ### Saved File Contains:
288: - Article title (if available)
289: - Author (if available from tool)
290: - Main article text
291: - Section headings
292: - No navigation, ads, or clutter
293: 
294: ### What Gets Removed:
295: - Navigation menus
296: - Ads and promotional content
297: - Newsletter signup forms
298: - Related articles sidebars
299: - Comment sections (optional)
300: - Social media buttons
301: - Cookie notices
302: 
303: ## Tips for Best Results
304: 
305: **1. Use reader for most articles**
306: - Best all-around tool
307: - Based on Firefox Reader View
308: - Works on most news sites and blogs
309: 
310: **2. Use trafilatura for:**
311: - Academic articles
312: - News sites
313: - Blogs with complex layouts
314: - Non-English content
315: 
316: **3. Fallback method limitations:**
317: - May include some noise
318: - Less accurate paragraph detection
319: - Better than nothing for simple sites
320: 
321: **4. Check extraction quality:**
322: - Always show preview to user
323: - Ask if it looks correct
324: - Offer to try different tool if needed
325: 
326: ## Example Usage
327: 
328: **Simple extraction:**
329: ```bash
330: # User: "Extract https://example.com/article"
331: reader "https://example.com/article" > temp.txt
332: TITLE=$(head -n 1 temp.txt | sed 's/^# //')
333: FILENAME="$(echo "$TITLE" | tr '/' '-').txt"
334: mv temp.txt "$FILENAME"
335: echo "✓ Saved to: $FILENAME"
336: ```
337: 
338: **With error handling:**
339: ```bash
340: if ! reader "$URL" > temp.txt 2>/dev/null; then
341:     if command -v trafilatura &> /dev/null; then
342:         trafilatura --URL "$URL" --output-format txt > temp.txt
343:     else
344:         echo "Error: Could not extract article. Install reader or trafilatura."
345:         exit 1
346:     fi
347: fi
348: ```
349: 
350: ## Best Practices
351: 
352: - ✅ Always show preview after extraction (first 10 lines)
353: - ✅ Verify extraction succeeded before saving
354: - ✅ Clean filename for filesystem compatibility
355: - ✅ Try fallback method if primary fails
356: - ✅ Inform user which tool was used
357: - ✅ Keep filename length reasonable (< 100 chars)
358: 
359: ## After Extraction
360: 
361: Display to user:
362: 1. "✓ Extracted: [Article Title]"
363: 2. "✓ Saved to: [filename]"
364: 3. Show preview (first 10-15 lines)
365: 4. File size and location
366: 
367: Ask if needed:
368: - "Would you like me to also create a Ship-Learn-Next plan from this?" (if using ship-learn-next skill)
369: - "Should I extract another article?"
</file>

<file path="__LOCAL-REPO/__skills/d3.js Visualisation/SKILL.md">
  1: ---
  2: name: d3-viz
  3: description: Creating interactive data visualisations using d3.js. This skill should be used when creating custom charts, graphs, network diagrams, geographic visualisations, or any complex SVG-based data visualisation that requires fine-grained control over visual elements, transitions, or interactions. Use this for bespoke visualisations beyond standard charting libraries, whether in React, Vue, Svelte, vanilla JavaScript, or any other environment.
  4: ---
  5: 
  6: # D3.js Visualisation
  7: 
  8: ## Overview
  9: 
 10: This skill provides guidance for creating sophisticated, interactive data visualisations using d3.js. D3.js (Data-Driven Documents) excels at binding data to DOM elements and applying data-driven transformations to create custom, publication-quality visualisations with precise control over every visual element. The techniques work across any JavaScript environment, including vanilla JavaScript, React, Vue, Svelte, and other frameworks.
 11: 
 12: ## When to use d3.js
 13: 
 14: **Use d3.js for:**
 15: - Custom visualisations requiring unique visual encodings or layouts
 16: - Interactive explorations with complex pan, zoom, or brush behaviours
 17: - Network/graph visualisations (force-directed layouts, tree diagrams, hierarchies, chord diagrams)
 18: - Geographic visualisations with custom projections
 19: - Visualisations requiring smooth, choreographed transitions
 20: - Publication-quality graphics with fine-grained styling control
 21: - Novel chart types not available in standard libraries
 22: 
 23: **Consider alternatives for:**
 24: - 3D visualisations - use Three.js instead
 25: 
 26: ## Core workflow
 27: 
 28: ### 1. Set up d3.js
 29: 
 30: Import d3 at the top of your script:
 31: 
 32: ```javascript
 33: import * as d3 from 'd3';
 34: ```
 35: 
 36: Or use the CDN version (7.x):
 37: 
 38: ```html
 39: <script src="https://d3js.org/d3.v7.min.js"></script>
 40: ```
 41: 
 42: All modules (scales, axes, shapes, transitions, etc.) are accessible through the `d3` namespace.
 43: 
 44: ### 2. Choose the integration pattern
 45: 
 46: **Pattern A: Direct DOM manipulation (recommended for most cases)**
 47: Use d3 to select DOM elements and manipulate them imperatively. This works in any JavaScript environment:
 48: 
 49: ```javascript
 50: function drawChart(data) {
 51:   if (!data || data.length === 0) return;
 52: 
 53:   const svg = d3.select('#chart'); // Select by ID, class, or DOM element
 54: 
 55:   // Clear previous content
 56:   svg.selectAll("*").remove();
 57: 
 58:   // Set up dimensions
 59:   const width = 800;
 60:   const height = 400;
 61:   const margin = { top: 20, right: 30, bottom: 40, left: 50 };
 62: 
 63:   // Create scales, axes, and draw visualisation
 64:   // ... d3 code here ...
 65: }
 66: 
 67: // Call when data changes
 68: drawChart(myData);
 69: ```
 70: 
 71: **Pattern B: Declarative rendering (for frameworks with templating)**
 72: Use d3 for data calculations (scales, layouts) but render elements via your framework:
 73: 
 74: ```javascript
 75: function getChartElements(data) {
 76:   const xScale = d3.scaleLinear()
 77:     .domain([0, d3.max(data, d => d.value)])
 78:     .range([0, 400]);
 79: 
 80:   return data.map((d, i) => ({
 81:     x: 50,
 82:     y: i * 30,
 83:     width: xScale(d.value),
 84:     height: 25
 85:   }));
 86: }
 87: 
 88: // In React: {getChartElements(data).map((d, i) => <rect key={i} {...d} fill="steelblue" />)}
 89: // In Vue: v-for directive over the returned array
 90: // In vanilla JS: Create elements manually from the returned data
 91: ```
 92: 
 93: Use Pattern A for complex visualisations with transitions, interactions, or when leveraging d3's full capabilities. Use Pattern B for simpler visualisations or when your framework prefers declarative rendering.
 94: 
 95: ### 3. Structure the visualisation code
 96: 
 97: Follow this standard structure in your drawing function:
 98: 
 99: ```javascript
100: function drawVisualization(data) {
101:   if (!data || data.length === 0) return;
102: 
103:   const svg = d3.select('#chart'); // Or pass a selector/element
104:   svg.selectAll("*").remove(); // Clear previous render
105: 
106:   // 1. Define dimensions
107:   const width = 800;
108:   const height = 400;
109:   const margin = { top: 20, right: 30, bottom: 40, left: 50 };
110:   const innerWidth = width - margin.left - margin.right;
111:   const innerHeight = height - margin.top - margin.bottom;
112: 
113:   // 2. Create main group with margins
114:   const g = svg.append("g")
115:     .attr("transform", `translate(${margin.left},${margin.top})`);
116: 
117:   // 3. Create scales
118:   const xScale = d3.scaleLinear()
119:     .domain([0, d3.max(data, d => d.x)])
120:     .range([0, innerWidth]);
121: 
122:   const yScale = d3.scaleLinear()
123:     .domain([0, d3.max(data, d => d.y)])
124:     .range([innerHeight, 0]); // Note: inverted for SVG coordinates
125: 
126:   // 4. Create and append axes
127:   const xAxis = d3.axisBottom(xScale);
128:   const yAxis = d3.axisLeft(yScale);
129: 
130:   g.append("g")
131:     .attr("transform", `translate(0,${innerHeight})`)
132:     .call(xAxis);
133: 
134:   g.append("g")
135:     .call(yAxis);
136: 
137:   // 5. Bind data and create visual elements
138:   g.selectAll("circle")
139:     .data(data)
140:     .join("circle")
141:     .attr("cx", d => xScale(d.x))
142:     .attr("cy", d => yScale(d.y))
143:     .attr("r", 5)
144:     .attr("fill", "steelblue");
145: }
146: 
147: // Call when data changes
148: drawVisualization(myData);
149: ```
150: 
151: ### 4. Implement responsive sizing
152: 
153: Make visualisations responsive to container size:
154: 
155: ```javascript
156: function setupResponsiveChart(containerId, data) {
157:   const container = document.getElementById(containerId);
158:   const svg = d3.select(`#${containerId}`).append('svg');
159: 
160:   function updateChart() {
161:     const { width, height } = container.getBoundingClientRect();
162:     svg.attr('width', width).attr('height', height);
163: 
164:     // Redraw visualisation with new dimensions
165:     drawChart(data, svg, width, height);
166:   }
167: 
168:   // Update on initial load
169:   updateChart();
170: 
171:   // Update on window resize
172:   window.addEventListener('resize', updateChart);
173: 
174:   // Return cleanup function
175:   return () => window.removeEventListener('resize', updateChart);
176: }
177: 
178: // Usage:
179: // const cleanup = setupResponsiveChart('chart-container', myData);
180: // cleanup(); // Call when component unmounts or element removed
181: ```
182: 
183: Or use ResizeObserver for more direct container monitoring:
184: 
185: ```javascript
186: function setupResponsiveChartWithObserver(svgElement, data) {
187:   const observer = new ResizeObserver(() => {
188:     const { width, height } = svgElement.getBoundingClientRect();
189:     d3.select(svgElement)
190:       .attr('width', width)
191:       .attr('height', height);
192: 
193:     // Redraw visualisation
194:     drawChart(data, d3.select(svgElement), width, height);
195:   });
196: 
197:   observer.observe(svgElement.parentElement);
198:   return () => observer.disconnect();
199: }
200: ```
201: 
202: ## Common visualisation patterns
203: 
204: ### Bar chart
205: 
206: ```javascript
207: function drawBarChart(data, svgElement) {
208:   if (!data || data.length === 0) return;
209: 
210:   const svg = d3.select(svgElement);
211:   svg.selectAll("*").remove();
212: 
213:   const width = 800;
214:   const height = 400;
215:   const margin = { top: 20, right: 30, bottom: 40, left: 50 };
216:   const innerWidth = width - margin.left - margin.right;
217:   const innerHeight = height - margin.top - margin.bottom;
218: 
219:   const g = svg.append("g")
220:     .attr("transform", `translate(${margin.left},${margin.top})`);
221: 
222:   const xScale = d3.scaleBand()
223:     .domain(data.map(d => d.category))
224:     .range([0, innerWidth])
225:     .padding(0.1);
226: 
227:   const yScale = d3.scaleLinear()
228:     .domain([0, d3.max(data, d => d.value)])
229:     .range([innerHeight, 0]);
230: 
231:   g.append("g")
232:     .attr("transform", `translate(0,${innerHeight})`)
233:     .call(d3.axisBottom(xScale));
234: 
235:   g.append("g")
236:     .call(d3.axisLeft(yScale));
237: 
238:   g.selectAll("rect")
239:     .data(data)
240:     .join("rect")
241:     .attr("x", d => xScale(d.category))
242:     .attr("y", d => yScale(d.value))
243:     .attr("width", xScale.bandwidth())
244:     .attr("height", d => innerHeight - yScale(d.value))
245:     .attr("fill", "steelblue");
246: }
247: 
248: // Usage:
249: // drawBarChart(myData, document.getElementById('chart'));
250: ```
251: 
252: ### Line chart
253: 
254: ```javascript
255: const line = d3.line()
256:   .x(d => xScale(d.date))
257:   .y(d => yScale(d.value))
258:   .curve(d3.curveMonotoneX); // Smooth curve
259: 
260: g.append("path")
261:   .datum(data)
262:   .attr("fill", "none")
263:   .attr("stroke", "steelblue")
264:   .attr("stroke-width", 2)
265:   .attr("d", line);
266: ```
267: 
268: ### Scatter plot
269: 
270: ```javascript
271: g.selectAll("circle")
272:   .data(data)
273:   .join("circle")
274:   .attr("cx", d => xScale(d.x))
275:   .attr("cy", d => yScale(d.y))
276:   .attr("r", d => sizeScale(d.size)) // Optional: size encoding
277:   .attr("fill", d => colourScale(d.category)) // Optional: colour encoding
278:   .attr("opacity", 0.7);
279: ```
280: 
281: ### Chord diagram
282: 
283: A chord diagram shows relationships between entities in a circular layout, with ribbons representing flows between them:
284: 
285: ```javascript
286: function drawChordDiagram(data) {
287:   // data format: array of objects with source, target, and value
288:   // Example: [{ source: 'A', target: 'B', value: 10 }, ...]
289: 
290:   if (!data || data.length === 0) return;
291: 
292:   const svg = d3.select('#chart');
293:   svg.selectAll("*").remove();
294: 
295:   const width = 600;
296:   const height = 600;
297:   const innerRadius = Math.min(width, height) * 0.3;
298:   const outerRadius = innerRadius + 30;
299: 
300:   // Create matrix from data
301:   const nodes = Array.from(new Set(data.flatMap(d => [d.source, d.target])));
302:   const matrix = Array.from({ length: nodes.length }, () => Array(nodes.length).fill(0));
303: 
304:   data.forEach(d => {
305:     const i = nodes.indexOf(d.source);
306:     const j = nodes.indexOf(d.target);
307:     matrix[i][j] += d.value;
308:     matrix[j][i] += d.value;
309:   });
310: 
311:   // Create chord layout
312:   const chord = d3.chord()
313:     .padAngle(0.05)
314:     .sortSubgroups(d3.descending);
315: 
316:   const arc = d3.arc()
317:     .innerRadius(innerRadius)
318:     .outerRadius(outerRadius);
319: 
320:   const ribbon = d3.ribbon()
321:     .source(d => d.source)
322:     .target(d => d.target);
323: 
324:   const colourScale = d3.scaleOrdinal(d3.schemeCategory10)
325:     .domain(nodes);
326: 
327:   const g = svg.append("g")
328:     .attr("transform", `translate(${width / 2},${height / 2})`);
329: 
330:   const chords = chord(matrix);
331: 
332:   // Draw ribbons
333:   g.append("g")
334:     .attr("fill-opacity", 0.67)
335:     .selectAll("path")
336:     .data(chords)
337:     .join("path")
338:     .attr("d", ribbon)
339:     .attr("fill", d => colourScale(nodes[d.source.index]))
340:     .attr("stroke", d => d3.rgb(colourScale(nodes[d.source.index])).darker());
341: 
342:   // Draw groups (arcs)
343:   const group = g.append("g")
344:     .selectAll("g")
345:     .data(chords.groups)
346:     .join("g");
347: 
348:   group.append("path")
349:     .attr("d", arc)
350:     .attr("fill", d => colourScale(nodes[d.index]))
351:     .attr("stroke", d => d3.rgb(colourScale(nodes[d.index])).darker());
352: 
353:   // Add labels
354:   group.append("text")
355:     .each(d => { d.angle = (d.startAngle + d.endAngle) / 2; })
356:     .attr("dy", "0.31em")
357:     .attr("transform", d => `rotate(${(d.angle * 180 / Math.PI) - 90})translate(${outerRadius + 30})${d.angle > Math.PI ? "rotate(180)" : ""}`)
358:     .attr("text-anchor", d => d.angle > Math.PI ? "end" : null)
359:     .text((d, i) => nodes[i])
360:     .style("font-size", "12px");
361: }
362: ```
363: 
364: ### Heatmap
365: 
366: A heatmap uses colour to encode values in a two-dimensional grid, useful for showing patterns across categories:
367: 
368: ```javascript
369: function drawHeatmap(data) {
370:   // data format: array of objects with row, column, and value
371:   // Example: [{ row: 'A', column: 'X', value: 10 }, ...]
372: 
373:   if (!data || data.length === 0) return;
374: 
375:   const svg = d3.select('#chart');
376:   svg.selectAll("*").remove();
377: 
378:   const width = 800;
379:   const height = 600;
380:   const margin = { top: 100, right: 30, bottom: 30, left: 100 };
381:   const innerWidth = width - margin.left - margin.right;
382:   const innerHeight = height - margin.top - margin.bottom;
383: 
384:   // Get unique rows and columns
385:   const rows = Array.from(new Set(data.map(d => d.row)));
386:   const columns = Array.from(new Set(data.map(d => d.column)));
387: 
388:   const g = svg.append("g")
389:     .attr("transform", `translate(${margin.left},${margin.top})`);
390: 
391:   // Create scales
392:   const xScale = d3.scaleBand()
393:     .domain(columns)
394:     .range([0, innerWidth])
395:     .padding(0.01);
396: 
397:   const yScale = d3.scaleBand()
398:     .domain(rows)
399:     .range([0, innerHeight])
400:     .padding(0.01);
401: 
402:   // Colour scale for values
403:   const colourScale = d3.scaleSequential(d3.interpolateYlOrRd)
404:     .domain([0, d3.max(data, d => d.value)]);
405: 
406:   // Draw rectangles
407:   g.selectAll("rect")
408:     .data(data)
409:     .join("rect")
410:     .attr("x", d => xScale(d.column))
411:     .attr("y", d => yScale(d.row))
412:     .attr("width", xScale.bandwidth())
413:     .attr("height", yScale.bandwidth())
414:     .attr("fill", d => colourScale(d.value));
415: 
416:   // Add x-axis labels
417:   svg.append("g")
418:     .attr("transform", `translate(${margin.left},${margin.top})`)
419:     .selectAll("text")
420:     .data(columns)
421:     .join("text")
422:     .attr("x", d => xScale(d) + xScale.bandwidth() / 2)
423:     .attr("y", -10)
424:     .attr("text-anchor", "middle")
425:     .text(d => d)
426:     .style("font-size", "12px");
427: 
428:   // Add y-axis labels
429:   svg.append("g")
430:     .attr("transform", `translate(${margin.left},${margin.top})`)
431:     .selectAll("text")
432:     .data(rows)
433:     .join("text")
434:     .attr("x", -10)
435:     .attr("y", d => yScale(d) + yScale.bandwidth() / 2)
436:     .attr("dy", "0.35em")
437:     .attr("text-anchor", "end")
438:     .text(d => d)
439:     .style("font-size", "12px");
440: 
441:   // Add colour legend
442:   const legendWidth = 20;
443:   const legendHeight = 200;
444:   const legend = svg.append("g")
445:     .attr("transform", `translate(${width - 60},${margin.top})`);
446: 
447:   const legendScale = d3.scaleLinear()
448:     .domain(colourScale.domain())
449:     .range([legendHeight, 0]);
450: 
451:   const legendAxis = d3.axisRight(legendScale)
452:     .ticks(5);
453: 
454:   // Draw colour gradient in legend
455:   for (let i = 0; i < legendHeight; i++) {
456:     legend.append("rect")
457:       .attr("y", i)
458:       .attr("width", legendWidth)
459:       .attr("height", 1)
460:       .attr("fill", colourScale(legendScale.invert(i)));
461:   }
462: 
463:   legend.append("g")
464:     .attr("transform", `translate(${legendWidth},0)`)
465:     .call(legendAxis);
466: }
467: ```
468: 
469: ### Pie chart
470: 
471: ```javascript
472: const pie = d3.pie()
473:   .value(d => d.value)
474:   .sort(null);
475: 
476: const arc = d3.arc()
477:   .innerRadius(0)
478:   .outerRadius(Math.min(width, height) / 2 - 20);
479: 
480: const colourScale = d3.scaleOrdinal(d3.schemeCategory10);
481: 
482: const g = svg.append("g")
483:   .attr("transform", `translate(${width / 2},${height / 2})`);
484: 
485: g.selectAll("path")
486:   .data(pie(data))
487:   .join("path")
488:   .attr("d", arc)
489:   .attr("fill", (d, i) => colourScale(i))
490:   .attr("stroke", "white")
491:   .attr("stroke-width", 2);
492: ```
493: 
494: ### Force-directed network
495: 
496: ```javascript
497: const simulation = d3.forceSimulation(nodes)
498:   .force("link", d3.forceLink(links).id(d => d.id).distance(100))
499:   .force("charge", d3.forceManyBody().strength(-300))
500:   .force("center", d3.forceCenter(width / 2, height / 2));
501: 
502: const link = g.selectAll("line")
503:   .data(links)
504:   .join("line")
505:   .attr("stroke", "#999")
506:   .attr("stroke-width", 1);
507: 
508: const node = g.selectAll("circle")
509:   .data(nodes)
510:   .join("circle")
511:   .attr("r", 8)
512:   .attr("fill", "steelblue")
513:   .call(d3.drag()
514:     .on("start", dragstarted)
515:     .on("drag", dragged)
516:     .on("end", dragended));
517: 
518: simulation.on("tick", () => {
519:   link
520:     .attr("x1", d => d.source.x)
521:     .attr("y1", d => d.source.y)
522:     .attr("x2", d => d.target.x)
523:     .attr("y2", d => d.target.y);
524:   
525:   node
526:     .attr("cx", d => d.x)
527:     .attr("cy", d => d.y);
528: });
529: 
530: function dragstarted(event) {
531:   if (!event.active) simulation.alphaTarget(0.3).restart();
532:   event.subject.fx = event.subject.x;
533:   event.subject.fy = event.subject.y;
534: }
535: 
536: function dragged(event) {
537:   event.subject.fx = event.x;
538:   event.subject.fy = event.y;
539: }
540: 
541: function dragended(event) {
542:   if (!event.active) simulation.alphaTarget(0);
543:   event.subject.fx = null;
544:   event.subject.fy = null;
545: }
546: ```
547: 
548: ## Adding interactivity
549: 
550: ### Tooltips
551: 
552: ```javascript
553: // Create tooltip div (outside SVG)
554: const tooltip = d3.select("body").append("div")
555:   .attr("class", "tooltip")
556:   .style("position", "absolute")
557:   .style("visibility", "hidden")
558:   .style("background-color", "white")
559:   .style("border", "1px solid #ddd")
560:   .style("padding", "10px")
561:   .style("border-radius", "4px")
562:   .style("pointer-events", "none");
563: 
564: // Add to elements
565: circles
566:   .on("mouseover", function(event, d) {
567:     d3.select(this).attr("opacity", 1);
568:     tooltip
569:       .style("visibility", "visible")
570:       .html(`<strong>${d.label}</strong><br/>Value: ${d.value}`);
571:   })
572:   .on("mousemove", function(event) {
573:     tooltip
574:       .style("top", (event.pageY - 10) + "px")
575:       .style("left", (event.pageX + 10) + "px");
576:   })
577:   .on("mouseout", function() {
578:     d3.select(this).attr("opacity", 0.7);
579:     tooltip.style("visibility", "hidden");
580:   });
581: ```
582: 
583: ### Zoom and pan
584: 
585: ```javascript
586: const zoom = d3.zoom()
587:   .scaleExtent([0.5, 10])
588:   .on("zoom", (event) => {
589:     g.attr("transform", event.transform);
590:   });
591: 
592: svg.call(zoom);
593: ```
594: 
595: ### Click interactions
596: 
597: ```javascript
598: circles
599:   .on("click", function(event, d) {
600:     // Handle click (dispatch event, update app state, etc.)
601:     console.log("Clicked:", d);
602: 
603:     // Visual feedback
604:     d3.selectAll("circle").attr("fill", "steelblue");
605:     d3.select(this).attr("fill", "orange");
606: 
607:     // Optional: dispatch custom event for your framework/app to listen to
608:     // window.dispatchEvent(new CustomEvent('chartClick', { detail: d }));
609:   });
610: ```
611: 
612: ## Transitions and animations
613: 
614: Add smooth transitions to visual changes:
615: 
616: ```javascript
617: // Basic transition
618: circles
619:   .transition()
620:   .duration(750)
621:   .attr("r", 10);
622: 
623: // Chained transitions
624: circles
625:   .transition()
626:   .duration(500)
627:   .attr("fill", "orange")
628:   .transition()
629:   .duration(500)
630:   .attr("r", 15);
631: 
632: // Staggered transitions
633: circles
634:   .transition()
635:   .delay((d, i) => i * 50)
636:   .duration(500)
637:   .attr("cy", d => yScale(d.value));
638: 
639: // Custom easing
640: circles
641:   .transition()
642:   .duration(1000)
643:   .ease(d3.easeBounceOut)
644:   .attr("r", 10);
645: ```
646: 
647: ## Scales reference
648: 
649: ### Quantitative scales
650: 
651: ```javascript
652: // Linear scale
653: const xScale = d3.scaleLinear()
654:   .domain([0, 100])
655:   .range([0, 500]);
656: 
657: // Log scale (for exponential data)
658: const logScale = d3.scaleLog()
659:   .domain([1, 1000])
660:   .range([0, 500]);
661: 
662: // Power scale
663: const powScale = d3.scalePow()
664:   .exponent(2)
665:   .domain([0, 100])
666:   .range([0, 500]);
667: 
668: // Time scale
669: const timeScale = d3.scaleTime()
670:   .domain([new Date(2020, 0, 1), new Date(2024, 0, 1)])
671:   .range([0, 500]);
672: ```
673: 
674: ### Ordinal scales
675: 
676: ```javascript
677: // Band scale (for bar charts)
678: const bandScale = d3.scaleBand()
679:   .domain(['A', 'B', 'C', 'D'])
680:   .range([0, 400])
681:   .padding(0.1);
682: 
683: // Point scale (for line/scatter categories)
684: const pointScale = d3.scalePoint()
685:   .domain(['A', 'B', 'C', 'D'])
686:   .range([0, 400]);
687: 
688: // Ordinal scale (for colours)
689: const colourScale = d3.scaleOrdinal(d3.schemeCategory10);
690: ```
691: 
692: ### Sequential scales
693: 
694: ```javascript
695: // Sequential colour scale
696: const colourScale = d3.scaleSequential(d3.interpolateBlues)
697:   .domain([0, 100]);
698: 
699: // Diverging colour scale
700: const divScale = d3.scaleDiverging(d3.interpolateRdBu)
701:   .domain([-10, 0, 10]);
702: ```
703: 
704: ## Best practices
705: 
706: ### Data preparation
707: 
708: Always validate and prepare data before visualisation:
709: 
710: ```javascript
711: // Filter invalid values
712: const cleanData = data.filter(d => d.value != null && !isNaN(d.value));
713: 
714: // Sort data if order matters
715: const sortedData = [...data].sort((a, b) => b.value - a.value);
716: 
717: // Parse dates
718: const parsedData = data.map(d => ({
719:   ...d,
720:   date: d3.timeParse("%Y-%m-%d")(d.date)
721: }));
722: ```
723: 
724: ### Performance optimisation
725: 
726: For large datasets (>1000 elements):
727: 
728: ```javascript
729: // Use canvas instead of SVG for many elements
730: // Use quadtree for collision detection
731: // Simplify paths with d3.line().curve(d3.curveStep)
732: // Implement virtual scrolling for large lists
733: // Use requestAnimationFrame for custom animations
734: ```
735: 
736: ### Accessibility
737: 
738: Make visualisations accessible:
739: 
740: ```javascript
741: // Add ARIA labels
742: svg.attr("role", "img")
743:    .attr("aria-label", "Bar chart showing quarterly revenue");
744: 
745: // Add title and description
746: svg.append("title").text("Quarterly Revenue 2024");
747: svg.append("desc").text("Bar chart showing revenue growth across four quarters");
748: 
749: // Ensure sufficient colour contrast
750: // Provide keyboard navigation for interactive elements
751: // Include data table alternative
752: ```
753: 
754: ### Styling
755: 
756: Use consistent, professional styling:
757: 
758: ```javascript
759: // Define colour palettes upfront
760: const colours = {
761:   primary: '#4A90E2',
762:   secondary: '#7B68EE',
763:   background: '#F5F7FA',
764:   text: '#333333',
765:   gridLines: '#E0E0E0'
766: };
767: 
768: // Apply consistent typography
769: svg.selectAll("text")
770:   .style("font-family", "Inter, sans-serif")
771:   .style("font-size", "12px");
772: 
773: // Use subtle grid lines
774: g.selectAll(".tick line")
775:   .attr("stroke", colours.gridLines)
776:   .attr("stroke-dasharray", "2,2");
777: ```
778: 
779: ## Common issues and solutions
780: 
781: **Issue**: Axes not appearing
782: - Ensure scales have valid domains (check for NaN values)
783: - Verify axis is appended to correct group
784: - Check transform translations are correct
785: 
786: **Issue**: Transitions not working
787: - Call `.transition()` before attribute changes
788: - Ensure elements have unique keys for proper data binding
789: - Check that useEffect dependencies include all changing data
790: 
791: **Issue**: Responsive sizing not working
792: - Use ResizeObserver or window resize listener
793: - Update dimensions in state to trigger re-render
794: - Ensure SVG has width/height attributes or viewBox
795: 
796: **Issue**: Performance problems
797: - Limit number of DOM elements (consider canvas for >1000 items)
798: - Debounce resize handlers
799: - Use `.join()` instead of separate enter/update/exit selections
800: - Avoid unnecessary re-renders by checking dependencies
801: 
802: ## Resources
803: 
804: ### references/
805: Contains detailed reference materials:
806: - `d3-patterns.md` - Comprehensive collection of visualisation patterns and code examples
807: - `scale-reference.md` - Complete guide to d3 scales with examples
808: - `colour-schemes.md` - D3 colour schemes and palette recommendations
809: 
810: ### assets/
811: 
812: Contains boilerplate templates:
813: 
814: - `chart-template.js` - Starter template for basic chart
815: - `interactive-template.js` - Template with tooltips, zoom, and interactions
816: - `sample-data.json` - Example datasets for testing
817: 
818: These templates work with vanilla JavaScript, React, Vue, Svelte, or any other JavaScript environment. Adapt them as needed for your specific framework.
819: 
820: To use these resources, read the relevant files when detailed guidance is needed for specific visualisation types or patterns.
</file>

<file path="__LOCAL-REPO/__skills/development/api-integration-specialist/SKILL.md">
  1: ---
  2: name: API Integration Specialist
  3: description: Expert in integrating third-party APIs with proper authentication, error handling, rate limiting, and retry logic. Use when integrating REST APIs, GraphQL endpoints, webhooks, or external services. Specializes in OAuth flows, API key management, request/response transformation, and building robust API clients.
  4: ---
  5: 
  6: # API Integration Specialist
  7: 
  8: Expert guidance for integrating external APIs into applications with production-ready patterns, security best practices, and comprehensive error handling.
  9: 
 10: ## When to Use This Skill
 11: 
 12: Use this skill when:
 13: - Integrating third-party APIs (Stripe, Twilio, SendGrid, etc.)
 14: - Building API client libraries or wrappers
 15: - Implementing OAuth 2.0, API keys, or JWT authentication
 16: - Setting up webhooks and event-driven integrations
 17: - Handling rate limits, retries, and circuit breakers
 18: - Transforming API responses for application use
 19: - Debugging API integration issues
 20: 
 21: ## Core Integration Principles
 22: 
 23: ### 1. Authentication & Security
 24: 
 25: **API Key Management:**
 26: ```javascript
 27: // Store keys in environment variables, never in code
 28: const apiClient = new APIClient({
 29:   apiKey: process.env.SERVICE_API_KEY,
 30:   baseURL: process.env.SERVICE_BASE_URL
 31: });
 32: ```
 33: 
 34: **OAuth 2.0 Flow:**
 35: ```javascript
 36: // Authorization Code Flow
 37: const oauth = new OAuth2Client({
 38:   clientId: process.env.CLIENT_ID,
 39:   clientSecret: process.env.CLIENT_SECRET,
 40:   redirectUri: process.env.REDIRECT_URI,
 41:   scopes: ['read:users', 'write:data']
 42: });
 43: 
 44: // Get authorization URL
 45: const authUrl = oauth.getAuthorizationUrl();
 46: 
 47: // Exchange code for tokens
 48: const tokens = await oauth.exchangeCode(code);
 49: ```
 50: 
 51: ### 2. Request/Response Handling
 52: 
 53: **Standardized Request Structure:**
 54: ```javascript
 55: async function makeRequest(endpoint, options = {}) {
 56:   const defaultHeaders = {
 57:     'Content-Type': 'application/json',
 58:     'Authorization': `Bearer ${apiKey}`,
 59:     'User-Agent': 'MyApp/1.0.0'
 60:   };
 61: 
 62:   const response = await fetch(`${baseURL}${endpoint}`, {
 63:     ...options,
 64:     headers: { ...defaultHeaders, ...options.headers }
 65:   });
 66: 
 67:   if (!response.ok) {
 68:     throw new APIError(response.status, await response.json());
 69:   }
 70: 
 71:   return response.json();
 72: }
 73: ```
 74: 
 75: **Response Transformation:**
 76: ```javascript
 77: class APIClient {
 78:   async getUser(userId) {
 79:     const raw = await this.request(`/users/${userId}`);
 80: 
 81:     // Transform external API format to internal model
 82:     return {
 83:       id: raw.user_id,
 84:       email: raw.email_address,
 85:       name: `${raw.first_name} ${raw.last_name}`,
 86:       createdAt: new Date(raw.created_timestamp)
 87:     };
 88:   }
 89: }
 90: ```
 91: 
 92: ### 3. Error Handling
 93: 
 94: **Structured Error Types:**
 95: ```javascript
 96: class APIError extends Error {
 97:   constructor(status, body) {
 98:     super(`API Error: ${status}`);
 99:     this.status = status;
100:     this.body = body;
101:     this.isAPIError = true;
102:   }
103: 
104:   isRateLimited() {
105:     return this.status === 429;
106:   }
107: 
108:   isUnauthorized() {
109:     return this.status === 401;
110:   }
111: 
112:   isServerError() {
113:     return this.status >= 500;
114:   }
115: }
116: ```
117: 
118: **Retry Logic with Exponential Backoff:**
119: ```javascript
120: async function retryWithBackoff(fn, maxRetries = 3) {
121:   for (let i = 0; i < maxRetries; i++) {
122:     try {
123:       return await fn();
124:     } catch (error) {
125:       if (!error.isAPIError || !error.isServerError()) {
126:         throw error; // Don't retry client errors
127:       }
128: 
129:       if (i === maxRetries - 1) throw error;
130: 
131:       const delay = Math.pow(2, i) * 1000; // 1s, 2s, 4s
132:       await sleep(delay);
133:     }
134:   }
135: }
136: ```
137: 
138: ### 4. Rate Limiting
139: 
140: **Client-Side Rate Limiter:**
141: ```javascript
142: class RateLimiter {
143:   constructor(maxRequests, windowMs) {
144:     this.maxRequests = maxRequests;
145:     this.windowMs = windowMs;
146:     this.requests = [];
147:   }
148: 
149:   async acquire() {
150:     const now = Date.now();
151:     this.requests = this.requests.filter(t => now - t < this.windowMs);
152: 
153:     if (this.requests.length >= this.maxRequests) {
154:       const oldestRequest = this.requests[0];
155:       const waitTime = this.windowMs - (now - oldestRequest);
156:       await sleep(waitTime);
157:       return this.acquire();
158:     }
159: 
160:     this.requests.push(now);
161:   }
162: }
163: 
164: const limiter = new RateLimiter(100, 60000); // 100 requests per minute
165: 
166: async function rateLimitedRequest(endpoint, options) {
167:   await limiter.acquire();
168:   return makeRequest(endpoint, options);
169: }
170: ```
171: 
172: ### 5. Webhook Handling
173: 
174: **Webhook Verification:**
175: ```javascript
176: function verifyWebhookSignature(payload, signature, secret) {
177:   const expectedSignature = crypto
178:     .createHmac('sha256', secret)
179:     .update(payload)
180:     .digest('hex');
181: 
182:   return crypto.timingSafeEqual(
183:     Buffer.from(signature),
184:     Buffer.from(expectedSignature)
185:   );
186: }
187: 
188: app.post('/webhooks/stripe', express.raw({ type: 'application/json' }), (req, res) => {
189:   const signature = req.headers['stripe-signature'];
190: 
191:   if (!verifyWebhookSignature(req.body, signature, process.env.STRIPE_WEBHOOK_SECRET)) {
192:     return res.status(401).send('Invalid signature');
193:   }
194: 
195:   const event = JSON.parse(req.body);
196:   handleWebhookEvent(event);
197: 
198:   res.status(200).send('Received');
199: });
200: ```
201: 
202: ## Integration Patterns
203: 
204: ### REST API Client Pattern
205: 
206: ```javascript
207: class ServiceAPIClient {
208:   constructor(config) {
209:     this.apiKey = config.apiKey;
210:     this.baseURL = config.baseURL;
211:     this.timeout = config.timeout || 30000;
212:   }
213: 
214:   async request(method, endpoint, data = null) {
215:     const options = {
216:       method,
217:       headers: {
218:         'Authorization': `Bearer ${this.apiKey}`,
219:         'Content-Type': 'application/json'
220:       },
221:       timeout: this.timeout
222:     };
223: 
224:     if (data) {
225:       options.body = JSON.stringify(data);
226:     }
227: 
228:     const response = await retryWithBackoff(() =>
229:       fetch(`${this.baseURL}${endpoint}`, options)
230:     );
231: 
232:     return response.json();
233:   }
234: 
235:   // Resource methods
236:   async getResource(id) {
237:     return this.request('GET', `/resources/${id}`);
238:   }
239: 
240:   async createResource(data) {
241:     return this.request('POST', '/resources', data);
242:   }
243: 
244:   async updateResource(id, data) {
245:     return this.request('PUT', `/resources/${id}`, data);
246:   }
247: 
248:   async deleteResource(id) {
249:     return this.request('DELETE', `/resources/${id}`);
250:   }
251: }
252: ```
253: 
254: ### Pagination Handling
255: 
256: ```javascript
257: async function* fetchAllPages(endpoint, pageSize = 100) {
258:   let cursor = null;
259: 
260:   do {
261:     const params = new URLSearchParams({
262:       limit: pageSize,
263:       ...(cursor && { cursor })
264:     });
265: 
266:     const response = await apiClient.request('GET', `${endpoint}?${params}`);
267: 
268:     yield response.data;
269: 
270:     cursor = response.pagination?.next_cursor;
271:   } while (cursor);
272: }
273: 
274: // Usage
275: for await (const page of fetchAllPages('/users')) {
276:   processUsers(page);
277: }
278: ```
279: 
280: ## Best Practices
281: 
282: ### Security
283: - Store API keys in environment variables or secrets management
284: - Use HTTPS for all API calls
285: - Verify webhook signatures
286: - Implement request signing for sensitive operations
287: - Rotate API keys regularly
288: 
289: ### Reliability
290: - Implement exponential backoff retry logic
291: - Handle rate limits gracefully
292: - Set appropriate timeouts
293: - Use circuit breakers for failing services
294: - Log all API interactions for debugging
295: 
296: ### Performance
297: - Cache responses when appropriate
298: - Batch requests when the API supports it
299: - Use streaming for large responses
300: - Implement connection pooling
301: - Monitor API usage and costs
302: 
303: ### Monitoring
304: - Track API response times
305: - Alert on error rate increases
306: - Monitor rate limit consumption
307: - Log failed requests with context
308: - Set up health checks for critical integrations
309: 
310: ## Common Integration Examples
311: 
312: ### Stripe Payment Processing
313: ```javascript
314: const stripe = require('stripe')(process.env.STRIPE_SECRET_KEY);
315: 
316: async function createPaymentIntent(amount, currency = 'usd') {
317:   return await stripe.paymentIntents.create({
318:     amount,
319:     currency,
320:     automatic_payment_methods: { enabled: true }
321:   });
322: }
323: ```
324: 
325: ### SendGrid Email Sending
326: ```javascript
327: const sgMail = require('@sendgrid/mail');
328: sgMail.setApiKey(process.env.SENDGRID_API_KEY);
329: 
330: async function sendEmail(to, subject, html) {
331:   await sgMail.send({
332:     to,
333:     from: process.env.FROM_EMAIL,
334:     subject,
335:     html
336:   });
337: }
338: ```
339: 
340: ### Twilio SMS
341: ```javascript
342: const twilio = require('twilio')(
343:   process.env.TWILIO_ACCOUNT_SID,
344:   process.env.TWILIO_AUTH_TOKEN
345: );
346: 
347: async function sendSMS(to, body) {
348:   await twilio.messages.create({
349:     to,
350:     from: process.env.TWILIO_PHONE_NUMBER,
351:     body
352:   });
353: }
354: ```
355: 
356: ## Troubleshooting
357: 
358: ### Authentication Issues
359: - Verify API keys are correctly set
360: - Check token expiration
361: - Ensure proper OAuth scopes
362: - Validate signature generation
363: 
364: ### Rate Limiting
365: - Implement client-side rate limiting
366: - Use batch endpoints when available
367: - Spread requests over time
368: - Consider upgrading API tier
369: 
370: ### Timeout Errors
371: - Increase timeout values for slow endpoints
372: - Implement request cancellation
373: - Use streaming for large payloads
374: - Check network connectivity
375: 
376: When integrating APIs, prioritize security, reliability, and maintainability. Always test error scenarios and edge cases before production deployment.
</file>

<file path="__LOCAL-REPO/__skills/development/code-reviewer/scripts/code_quality_checker.py">
 1: #!/usr/bin/env python3
 2: """
 3: Code Quality Checker
 4: Automated tool for code reviewer tasks
 5: """
 6: import os
 7: import sys
 8: import json
 9: import argparse
10: from pathlib import Path
11: from typing import Dict, List, Optional
12: class CodeQualityChecker:
13:     """Main class for code quality checker functionality"""
14:     def __init__(self, target_path: str, verbose: bool = False):
15:         self.target_path = Path(target_path)
16:         self.verbose = verbose
17:         self.results = {}
18:     def run(self) -> Dict:
19:         """Execute the main functionality"""
20:         print(f"🚀 Running {self.__class__.__name__}...")
21:         print(f"📁 Target: {self.target_path}")
22:         try:
23:             self.validate_target()
24:             self.analyze()
25:             self.generate_report()
26:             print("✅ Completed successfully!")
27:             return self.results
28:         except Exception as e:
29:             print(f"❌ Error: {e}")
30:             sys.exit(1)
31:     def validate_target(self):
32:         """Validate the target path exists and is accessible"""
33:         if not self.target_path.exists():
34:             raise ValueError(f"Target path does not exist: {self.target_path}")
35:         if self.verbose:
36:             print(f"✓ Target validated: {self.target_path}")
37:     def analyze(self):
38:         """Perform the main analysis or operation"""
39:         if self.verbose:
40:             print("📊 Analyzing...")
41:         # Main logic here
42:         self.results['status'] = 'success'
43:         self.results['target'] = str(self.target_path)
44:         self.results['findings'] = []
45:         # Add analysis results
46:         if self.verbose:
47:             print(f"✓ Analysis complete: {len(self.results.get('findings', []))} findings")
48:     def generate_report(self):
49:         """Generate and display the report"""
50:         print("\n" + "="*50)
51:         print("REPORT")
52:         print("="*50)
53:         print(f"Target: {self.results.get('target')}")
54:         print(f"Status: {self.results.get('status')}")
55:         print(f"Findings: {len(self.results.get('findings', []))}")
56:         print("="*50 + "\n")
57: def main():
58:     """Main entry point"""
59:     parser = argparse.ArgumentParser(
60:         description="Code Quality Checker"
61:     )
62:     parser.add_argument(
63:         'target',
64:         help='Target path to analyze or process'
65:     )
66:     parser.add_argument(
67:         '--verbose', '-v',
68:         action='store_true',
69:         help='Enable verbose output'
70:     )
71:     parser.add_argument(
72:         '--json',
73:         action='store_true',
74:         help='Output results as JSON'
75:     )
76:     parser.add_argument(
77:         '--output', '-o',
78:         help='Output file path'
79:     )
80:     args = parser.parse_args()
81:     tool = CodeQualityChecker(
82:         args.target,
83:         verbose=args.verbose
84:     )
85:     results = tool.run()
86:     if args.json:
87:         output = json.dumps(results, indent=2)
88:         if args.output:
89:             with open(args.output, 'w') as f:
90:                 f.write(output)
91:             print(f"Results written to {args.output}")
92:         else:
93:             print(output)
94: if __name__ == '__main__':
95:     main()
</file>

<file path="__LOCAL-REPO/__skills/development/code-reviewer/scripts/pr_analyzer.py">
 1: #!/usr/bin/env python3
 2: """
 3: Pr Analyzer
 4: Automated tool for code reviewer tasks
 5: """
 6: import os
 7: import sys
 8: import json
 9: import argparse
10: from pathlib import Path
11: from typing import Dict, List, Optional
12: class PrAnalyzer:
13:     """Main class for pr analyzer functionality"""
14:     def __init__(self, target_path: str, verbose: bool = False):
15:         self.target_path = Path(target_path)
16:         self.verbose = verbose
17:         self.results = {}
18:     def run(self) -> Dict:
19:         """Execute the main functionality"""
20:         print(f"🚀 Running {self.__class__.__name__}...")
21:         print(f"📁 Target: {self.target_path}")
22:         try:
23:             self.validate_target()
24:             self.analyze()
25:             self.generate_report()
26:             print("✅ Completed successfully!")
27:             return self.results
28:         except Exception as e:
29:             print(f"❌ Error: {e}")
30:             sys.exit(1)
31:     def validate_target(self):
32:         """Validate the target path exists and is accessible"""
33:         if not self.target_path.exists():
34:             raise ValueError(f"Target path does not exist: {self.target_path}")
35:         if self.verbose:
36:             print(f"✓ Target validated: {self.target_path}")
37:     def analyze(self):
38:         """Perform the main analysis or operation"""
39:         if self.verbose:
40:             print("📊 Analyzing...")
41:         # Main logic here
42:         self.results['status'] = 'success'
43:         self.results['target'] = str(self.target_path)
44:         self.results['findings'] = []
45:         # Add analysis results
46:         if self.verbose:
47:             print(f"✓ Analysis complete: {len(self.results.get('findings', []))} findings")
48:     def generate_report(self):
49:         """Generate and display the report"""
50:         print("\n" + "="*50)
51:         print("REPORT")
52:         print("="*50)
53:         print(f"Target: {self.results.get('target')}")
54:         print(f"Status: {self.results.get('status')}")
55:         print(f"Findings: {len(self.results.get('findings', []))}")
56:         print("="*50 + "\n")
57: def main():
58:     """Main entry point"""
59:     parser = argparse.ArgumentParser(
60:         description="Pr Analyzer"
61:     )
62:     parser.add_argument(
63:         'target',
64:         help='Target path to analyze or process'
65:     )
66:     parser.add_argument(
67:         '--verbose', '-v',
68:         action='store_true',
69:         help='Enable verbose output'
70:     )
71:     parser.add_argument(
72:         '--json',
73:         action='store_true',
74:         help='Output results as JSON'
75:     )
76:     parser.add_argument(
77:         '--output', '-o',
78:         help='Output file path'
79:     )
80:     args = parser.parse_args()
81:     tool = PrAnalyzer(
82:         args.target,
83:         verbose=args.verbose
84:     )
85:     results = tool.run()
86:     if args.json:
87:         output = json.dumps(results, indent=2)
88:         if args.output:
89:             with open(args.output, 'w') as f:
90:                 f.write(output)
91:             print(f"Results written to {args.output}")
92:         else:
93:             print(output)
94: if __name__ == '__main__':
95:     main()
</file>

<file path="__LOCAL-REPO/__skills/development/code-reviewer/scripts/review_report_generator.py">
 1: #!/usr/bin/env python3
 2: """
 3: Review Report Generator
 4: Automated tool for code reviewer tasks
 5: """
 6: import os
 7: import sys
 8: import json
 9: import argparse
10: from pathlib import Path
11: from typing import Dict, List, Optional
12: class ReviewReportGenerator:
13:     """Main class for review report generator functionality"""
14:     def __init__(self, target_path: str, verbose: bool = False):
15:         self.target_path = Path(target_path)
16:         self.verbose = verbose
17:         self.results = {}
18:     def run(self) -> Dict:
19:         """Execute the main functionality"""
20:         print(f"🚀 Running {self.__class__.__name__}...")
21:         print(f"📁 Target: {self.target_path}")
22:         try:
23:             self.validate_target()
24:             self.analyze()
25:             self.generate_report()
26:             print("✅ Completed successfully!")
27:             return self.results
28:         except Exception as e:
29:             print(f"❌ Error: {e}")
30:             sys.exit(1)
31:     def validate_target(self):
32:         """Validate the target path exists and is accessible"""
33:         if not self.target_path.exists():
34:             raise ValueError(f"Target path does not exist: {self.target_path}")
35:         if self.verbose:
36:             print(f"✓ Target validated: {self.target_path}")
37:     def analyze(self):
38:         """Perform the main analysis or operation"""
39:         if self.verbose:
40:             print("📊 Analyzing...")
41:         # Main logic here
42:         self.results['status'] = 'success'
43:         self.results['target'] = str(self.target_path)
44:         self.results['findings'] = []
45:         # Add analysis results
46:         if self.verbose:
47:             print(f"✓ Analysis complete: {len(self.results.get('findings', []))} findings")
48:     def generate_report(self):
49:         """Generate and display the report"""
50:         print("\n" + "="*50)
51:         print("REPORT")
52:         print("="*50)
53:         print(f"Target: {self.results.get('target')}")
54:         print(f"Status: {self.results.get('status')}")
55:         print(f"Findings: {len(self.results.get('findings', []))}")
56:         print("="*50 + "\n")
57: def main():
58:     """Main entry point"""
59:     parser = argparse.ArgumentParser(
60:         description="Review Report Generator"
61:     )
62:     parser.add_argument(
63:         'target',
64:         help='Target path to analyze or process'
65:     )
66:     parser.add_argument(
67:         '--verbose', '-v',
68:         action='store_true',
69:         help='Enable verbose output'
70:     )
71:     parser.add_argument(
72:         '--json',
73:         action='store_true',
74:         help='Output results as JSON'
75:     )
76:     parser.add_argument(
77:         '--output', '-o',
78:         help='Output file path'
79:     )
80:     args = parser.parse_args()
81:     tool = ReviewReportGenerator(
82:         args.target,
83:         verbose=args.verbose
84:     )
85:     results = tool.run()
86:     if args.json:
87:         output = json.dumps(results, indent=2)
88:         if args.output:
89:             with open(args.output, 'w') as f:
90:                 f.write(output)
91:             print(f"Results written to {args.output}")
92:         else:
93:             print(output)
94: if __name__ == '__main__':
95:     main()
</file>

<file path="__LOCAL-REPO/__skills/development/code-reviewer/SKILL.md">
  1: ---
  2: name: code-reviewer
  3: description: Comprehensive code review skill for TypeScript, JavaScript, Python, Swift, Kotlin, Go. Includes automated code analysis, best practice checking, security scanning, and review checklist generation. Use when reviewing pull requests, providing code feedback, identifying issues, or ensuring code quality standards.
  4: ---
  5: 
  6: # Code Reviewer
  7: 
  8: Complete toolkit for code reviewer with modern tools and best practices.
  9: 
 10: ## Quick Start
 11: 
 12: ### Main Capabilities
 13: 
 14: This skill provides three core capabilities through automated scripts:
 15: 
 16: ```bash
 17: # Script 1: Pr Analyzer
 18: python scripts/pr_analyzer.py [options]
 19: 
 20: # Script 2: Code Quality Checker
 21: python scripts/code_quality_checker.py [options]
 22: 
 23: # Script 3: Review Report Generator
 24: python scripts/review_report_generator.py [options]
 25: ```
 26: 
 27: ## Core Capabilities
 28: 
 29: ### 1. Pr Analyzer
 30: 
 31: Automated tool for pr analyzer tasks.
 32: 
 33: **Features:**
 34: - Automated scaffolding
 35: - Best practices built-in
 36: - Configurable templates
 37: - Quality checks
 38: 
 39: **Usage:**
 40: ```bash
 41: python scripts/pr_analyzer.py <project-path> [options]
 42: ```
 43: 
 44: ### 2. Code Quality Checker
 45: 
 46: Comprehensive analysis and optimization tool.
 47: 
 48: **Features:**
 49: - Deep analysis
 50: - Performance metrics
 51: - Recommendations
 52: - Automated fixes
 53: 
 54: **Usage:**
 55: ```bash
 56: python scripts/code_quality_checker.py <target-path> [--verbose]
 57: ```
 58: 
 59: ### 3. Review Report Generator
 60: 
 61: Advanced tooling for specialized tasks.
 62: 
 63: **Features:**
 64: - Expert-level automation
 65: - Custom configurations
 66: - Integration ready
 67: - Production-grade output
 68: 
 69: **Usage:**
 70: ```bash
 71: python scripts/review_report_generator.py [arguments] [options]
 72: ```
 73: 
 74: ## Reference Documentation
 75: 
 76: ### Code Review Checklist
 77: 
 78: Comprehensive guide available in `references/code_review_checklist.md`:
 79: 
 80: - Detailed patterns and practices
 81: - Code examples
 82: - Best practices
 83: - Anti-patterns to avoid
 84: - Real-world scenarios
 85: 
 86: ### Coding Standards
 87: 
 88: Complete workflow documentation in `references/coding_standards.md`:
 89: 
 90: - Step-by-step processes
 91: - Optimization strategies
 92: - Tool integrations
 93: - Performance tuning
 94: - Troubleshooting guide
 95: 
 96: ### Common Antipatterns
 97: 
 98: Technical reference guide in `references/common_antipatterns.md`:
 99: 
100: - Technology stack details
101: - Configuration examples
102: - Integration patterns
103: - Security considerations
104: - Scalability guidelines
105: 
106: ## Tech Stack
107: 
108: **Languages:** TypeScript, JavaScript, Python, Go, Swift, Kotlin
109: **Frontend:** React, Next.js, React Native, Flutter
110: **Backend:** Node.js, Express, GraphQL, REST APIs
111: **Database:** PostgreSQL, Prisma, NeonDB, Supabase
112: **DevOps:** Docker, Kubernetes, Terraform, GitHub Actions, CircleCI
113: **Cloud:** AWS, GCP, Azure
114: 
115: ## Development Workflow
116: 
117: ### 1. Setup and Configuration
118: 
119: ```bash
120: # Install dependencies
121: npm install
122: # or
123: pip install -r requirements.txt
124: 
125: # Configure environment
126: cp .env.example .env
127: ```
128: 
129: ### 2. Run Quality Checks
130: 
131: ```bash
132: # Use the analyzer script
133: python scripts/code_quality_checker.py .
134: 
135: # Review recommendations
136: # Apply fixes
137: ```
138: 
139: ### 3. Implement Best Practices
140: 
141: Follow the patterns and practices documented in:
142: - `references/code_review_checklist.md`
143: - `references/coding_standards.md`
144: - `references/common_antipatterns.md`
145: 
146: ## Best Practices Summary
147: 
148: ### Code Quality
149: - Follow established patterns
150: - Write comprehensive tests
151: - Document decisions
152: - Review regularly
153: 
154: ### Performance
155: - Measure before optimizing
156: - Use appropriate caching
157: - Optimize critical paths
158: - Monitor in production
159: 
160: ### Security
161: - Validate all inputs
162: - Use parameterized queries
163: - Implement proper authentication
164: - Keep dependencies updated
165: 
166: ### Maintainability
167: - Write clear code
168: - Use consistent naming
169: - Add helpful comments
170: - Keep it simple
171: 
172: ## Common Commands
173: 
174: ```bash
175: # Development
176: npm run dev
177: npm run build
178: npm run test
179: npm run lint
180: 
181: # Analysis
182: python scripts/code_quality_checker.py .
183: python scripts/review_report_generator.py --analyze
184: 
185: # Deployment
186: docker build -t app:latest .
187: docker-compose up -d
188: kubectl apply -f k8s/
189: ```
190: 
191: ## Troubleshooting
192: 
193: ### Common Issues
194: 
195: Check the comprehensive troubleshooting section in `references/common_antipatterns.md`.
196: 
197: ### Getting Help
198: 
199: - Review reference documentation
200: - Check script output messages
201: - Consult tech stack documentation
202: - Review error logs
203: 
204: ## Resources
205: 
206: - Pattern Reference: `references/code_review_checklist.md`
207: - Workflow Guide: `references/coding_standards.md`
208: - Technical Guide: `references/common_antipatterns.md`
209: - Tool Scripts: `scripts/` directory
</file>

<file path="__LOCAL-REPO/__skills/development/mcp-integration/references/authentication.md">
  1: # MCP Authentication Patterns
  2: 
  3: Complete guide to authentication methods for MCP servers in Claude Code plugins.
  4: 
  5: ## Overview
  6: 
  7: MCP servers support multiple authentication methods depending on the server type and service requirements. Choose the method that best matches your use case and security requirements.
  8: 
  9: ## OAuth (Automatic)
 10: 
 11: ### How It Works
 12: 
 13: Claude Code automatically handles the complete OAuth 2.0 flow for SSE and HTTP servers:
 14: 
 15: 1. User attempts to use MCP tool
 16: 2. Claude Code detects authentication needed
 17: 3. Opens browser for OAuth consent
 18: 4. User authorizes in browser
 19: 5. Tokens stored securely by Claude Code
 20: 6. Automatic token refresh
 21: 
 22: ### Configuration
 23: 
 24: ```json
 25: {
 26:   "service": {
 27:     "type": "sse",
 28:     "url": "https://mcp.example.com/sse"
 29:   }
 30: }
 31: ```
 32: 
 33: No additional auth configuration needed! Claude Code handles everything.
 34: 
 35: ### Supported Services
 36: 
 37: **Known OAuth-enabled MCP servers:**
 38: - Asana: `https://mcp.asana.com/sse`
 39: - GitHub (when available)
 40: - Google services (when available)
 41: - Custom OAuth servers
 42: 
 43: ### OAuth Scopes
 44: 
 45: OAuth scopes are determined by the MCP server. Users see required scopes during the consent flow.
 46: 
 47: **Document required scopes in your README:**
 48: ```markdown
 49: ## Authentication
 50: 
 51: This plugin requires the following Asana permissions:
 52: - Read tasks and projects
 53: - Create and update tasks
 54: - Access workspace data
 55: ```
 56: 
 57: ### Token Storage
 58: 
 59: Tokens are stored securely by Claude Code:
 60: - Not accessible to plugins
 61: - Encrypted at rest
 62: - Automatic refresh
 63: - Cleared on sign-out
 64: 
 65: ### Troubleshooting OAuth
 66: 
 67: **Authentication loop:**
 68: - Clear cached tokens (sign out and sign in)
 69: - Check OAuth redirect URLs
 70: - Verify server OAuth configuration
 71: 
 72: **Scope issues:**
 73: - User may need to re-authorize for new scopes
 74: - Check server documentation for required scopes
 75: 
 76: **Token expiration:**
 77: - Claude Code auto-refreshes
 78: - If refresh fails, prompts re-authentication
 79: 
 80: ## Token-Based Authentication
 81: 
 82: ### Bearer Tokens
 83: 
 84: Most common for HTTP and WebSocket servers.
 85: 
 86: **Configuration:**
 87: ```json
 88: {
 89:   "api": {
 90:     "type": "http",
 91:     "url": "https://api.example.com/mcp",
 92:     "headers": {
 93:       "Authorization": "Bearer ${API_TOKEN}"
 94:     }
 95:   }
 96: }
 97: ```
 98: 
 99: **Environment variable:**
100: ```bash
101: export API_TOKEN="your-secret-token-here"
102: ```
103: 
104: ### API Keys
105: 
106: Alternative to Bearer tokens, often in custom headers.
107: 
108: **Configuration:**
109: ```json
110: {
111:   "api": {
112:     "type": "http",
113:     "url": "https://api.example.com/mcp",
114:     "headers": {
115:       "X-API-Key": "${API_KEY}",
116:       "X-API-Secret": "${API_SECRET}"
117:     }
118:   }
119: }
120: ```
121: 
122: ### Custom Headers
123: 
124: Services may use custom authentication headers.
125: 
126: **Configuration:**
127: ```json
128: {
129:   "service": {
130:     "type": "sse",
131:     "url": "https://mcp.example.com/sse",
132:     "headers": {
133:       "X-Auth-Token": "${AUTH_TOKEN}",
134:       "X-User-ID": "${USER_ID}",
135:       "X-Tenant-ID": "${TENANT_ID}"
136:     }
137:   }
138: }
139: ```
140: 
141: ### Documenting Token Requirements
142: 
143: Always document in your README:
144: 
145: ```markdown
146: ## Setup
147: 
148: ### Required Environment Variables
149: 
150: Set these environment variables before using the plugin:
151: 
152: \`\`\`bash
153: export API_TOKEN="your-token-here"
154: export API_SECRET="your-secret-here"
155: \`\`\`
156: 
157: ### Obtaining Tokens
158: 
159: 1. Visit https://api.example.com/tokens
160: 2. Create a new API token
161: 3. Copy the token and secret
162: 4. Set environment variables as shown above
163: 
164: ### Token Permissions
165: 
166: The API token needs the following permissions:
167: - Read access to resources
168: - Write access for creating items
169: - Delete access (optional, for cleanup operations)
170: \`\`\`
171: ```
172: 
173: ## Environment Variable Authentication (stdio)
174: 
175: ### Passing Credentials to Server
176: 
177: For stdio servers, pass credentials via environment variables:
178: 
179: ```json
180: {
181:   "database": {
182:     "command": "python",
183:     "args": ["-m", "mcp_server_db"],
184:     "env": {
185:       "DATABASE_URL": "${DATABASE_URL}",
186:       "DB_USER": "${DB_USER}",
187:       "DB_PASSWORD": "${DB_PASSWORD}"
188:     }
189:   }
190: }
191: ```
192: 
193: ### User Environment Variables
194: 
195: ```bash
196: # User sets these in their shell
197: export DATABASE_URL="postgresql://localhost/mydb"
198: export DB_USER="myuser"
199: export DB_PASSWORD="mypassword"
200: ```
201: 
202: ### Documentation Template
203: 
204: ```markdown
205: ## Database Configuration
206: 
207: Set these environment variables:
208: 
209: \`\`\`bash
210: export DATABASE_URL="postgresql://host:port/database"
211: export DB_USER="username"
212: export DB_PASSWORD="password"
213: \`\`\`
214: 
215: Or create a `.env` file (add to `.gitignore`):
216: 
217: \`\`\`
218: DATABASE_URL=postgresql://localhost:5432/mydb
219: DB_USER=myuser
220: DB_PASSWORD=mypassword
221: \`\`\`
222: 
223: Load with: \`source .env\` or \`export $(cat .env | xargs)\`
224: \`\`\`
225: ```
226: 
227: ## Dynamic Headers
228: 
229: ### Headers Helper Script
230: 
231: For tokens that change or expire, use a helper script:
232: 
233: ```json
234: {
235:   "api": {
236:     "type": "sse",
237:     "url": "https://api.example.com",
238:     "headersHelper": "${CLAUDE_PLUGIN_ROOT}/scripts/get-headers.sh"
239:   }
240: }
241: ```
242: 
243: **Script (get-headers.sh):**
244: ```bash
245: #!/bin/bash
246: # Generate dynamic authentication headers
247: 
248: # Fetch fresh token
249: TOKEN=$(get-fresh-token-from-somewhere)
250: 
251: # Output JSON headers
252: cat <<EOF
253: {
254:   "Authorization": "Bearer $TOKEN",
255:   "X-Timestamp": "$(date -Iseconds)"
256: }
257: EOF
258: ```
259: 
260: ### Use Cases for Dynamic Headers
261: 
262: - Short-lived tokens that need refresh
263: - Tokens with HMAC signatures
264: - Time-based authentication
265: - Dynamic tenant/workspace selection
266: 
267: ## Security Best Practices
268: 
269: ### DO
270: 
271: ✅ **Use environment variables:**
272: ```json
273: {
274:   "headers": {
275:     "Authorization": "Bearer ${API_TOKEN}"
276:   }
277: }
278: ```
279: 
280: ✅ **Document required variables in README**
281: 
282: ✅ **Use HTTPS/WSS always**
283: 
284: ✅ **Implement token rotation**
285: 
286: ✅ **Store tokens securely (env vars, not files)**
287: 
288: ✅ **Let OAuth handle authentication when available**
289: 
290: ### DON'T
291: 
292: ❌ **Hardcode tokens:**
293: ```json
294: {
295:   "headers": {
296:     "Authorization": "Bearer sk-abc123..."  // NEVER!
297:   }
298: }
299: ```
300: 
301: ❌ **Commit tokens to git**
302: 
303: ❌ **Share tokens in documentation**
304: 
305: ❌ **Use HTTP instead of HTTPS**
306: 
307: ❌ **Store tokens in plugin files**
308: 
309: ❌ **Log tokens or sensitive headers**
310: 
311: ## Multi-Tenancy Patterns
312: 
313: ### Workspace/Tenant Selection
314: 
315: **Via environment variable:**
316: ```json
317: {
318:   "api": {
319:     "type": "http",
320:     "url": "https://api.example.com/mcp",
321:     "headers": {
322:       "Authorization": "Bearer ${API_TOKEN}",
323:       "X-Workspace-ID": "${WORKSPACE_ID}"
324:     }
325:   }
326: }
327: ```
328: 
329: **Via URL:**
330: ```json
331: {
332:   "api": {
333:     "type": "http",
334:     "url": "https://${TENANT_ID}.api.example.com/mcp"
335:   }
336: }
337: ```
338: 
339: ### Per-User Configuration
340: 
341: Users set their own workspace:
342: 
343: ```bash
344: export WORKSPACE_ID="my-workspace-123"
345: export TENANT_ID="my-company"
346: ```
347: 
348: ## Authentication Troubleshooting
349: 
350: ### Common Issues
351: 
352: **401 Unauthorized:**
353: - Check token is set correctly
354: - Verify token hasn't expired
355: - Check token has required permissions
356: - Ensure header format is correct
357: 
358: **403 Forbidden:**
359: - Token valid but lacks permissions
360: - Check scope/permissions
361: - Verify workspace/tenant ID
362: - May need admin approval
363: 
364: **Token not found:**
365: ```bash
366: # Check environment variable is set
367: echo $API_TOKEN
368: 
369: # If empty, set it
370: export API_TOKEN="your-token"
371: ```
372: 
373: **Token in wrong format:**
374: ```json
375: // Correct
376: "Authorization": "Bearer sk-abc123"
377: 
378: // Wrong
379: "Authorization": "sk-abc123"
380: ```
381: 
382: ### Debugging Authentication
383: 
384: **Enable debug mode:**
385: ```bash
386: claude --debug
387: ```
388: 
389: Look for:
390: - Authentication header values (sanitized)
391: - OAuth flow progress
392: - Token refresh attempts
393: - Authentication errors
394: 
395: **Test authentication separately:**
396: ```bash
397: # Test HTTP endpoint
398: curl -H "Authorization: Bearer $API_TOKEN" \
399:      https://api.example.com/mcp/health
400: 
401: # Should return 200 OK
402: ```
403: 
404: ## Migration Patterns
405: 
406: ### From Hardcoded to Environment Variables
407: 
408: **Before:**
409: ```json
410: {
411:   "headers": {
412:     "Authorization": "Bearer sk-hardcoded-token"
413:   }
414: }
415: ```
416: 
417: **After:**
418: ```json
419: {
420:   "headers": {
421:     "Authorization": "Bearer ${API_TOKEN}"
422:   }
423: }
424: ```
425: 
426: **Migration steps:**
427: 1. Add environment variable to plugin README
428: 2. Update configuration to use ${VAR}
429: 3. Test with variable set
430: 4. Remove hardcoded value
431: 5. Commit changes
432: 
433: ### From Basic Auth to OAuth
434: 
435: **Before:**
436: ```json
437: {
438:   "headers": {
439:     "Authorization": "Basic ${BASE64_CREDENTIALS}"
440:   }
441: }
442: ```
443: 
444: **After:**
445: ```json
446: {
447:   "type": "sse",
448:   "url": "https://mcp.example.com/sse"
449: }
450: ```
451: 
452: **Benefits:**
453: - Better security
454: - No credential management
455: - Automatic token refresh
456: - Scoped permissions
457: 
458: ## Advanced Authentication
459: 
460: ### Mutual TLS (mTLS)
461: 
462: Some enterprise services require client certificates.
463: 
464: **Not directly supported in MCP configuration.**
465: 
466: **Workaround:** Wrap in stdio server that handles mTLS:
467: 
468: ```json
469: {
470:   "secure-api": {
471:     "command": "${CLAUDE_PLUGIN_ROOT}/servers/mtls-wrapper",
472:     "args": ["--cert", "${CLIENT_CERT}", "--key", "${CLIENT_KEY}"],
473:     "env": {
474:       "API_URL": "https://secure.example.com"
475:     }
476:   }
477: }
478: ```
479: 
480: ### JWT Tokens
481: 
482: Generate JWT tokens dynamically with headers helper:
483: 
484: ```bash
485: #!/bin/bash
486: # generate-jwt.sh
487: 
488: # Generate JWT (using library or API call)
489: JWT=$(generate-jwt-token)
490: 
491: echo "{\"Authorization\": \"Bearer $JWT\"}"
492: ```
493: 
494: ```json
495: {
496:   "headersHelper": "${CLAUDE_PLUGIN_ROOT}/scripts/generate-jwt.sh"
497: }
498: ```
499: 
500: ### HMAC Signatures
501: 
502: For APIs requiring request signing:
503: 
504: ```bash
505: #!/bin/bash
506: # generate-hmac.sh
507: 
508: TIMESTAMP=$(date -Iseconds)
509: SIGNATURE=$(echo -n "$TIMESTAMP" | openssl dgst -sha256 -hmac "$SECRET_KEY" | cut -d' ' -f2)
510: 
511: cat <<EOF
512: {
513:   "X-Timestamp": "$TIMESTAMP",
514:   "X-Signature": "$SIGNATURE",
515:   "X-API-Key": "$API_KEY"
516: }
517: EOF
518: ```
519: 
520: ## Best Practices Summary
521: 
522: ### For Plugin Developers
523: 
524: 1. **Prefer OAuth** when service supports it
525: 2. **Use environment variables** for tokens
526: 3. **Document all required variables** in README
527: 4. **Provide setup instructions** with examples
528: 5. **Never commit credentials**
529: 6. **Use HTTPS/WSS only**
530: 7. **Test authentication thoroughly**
531: 
532: ### For Plugin Users
533: 
534: 1. **Set environment variables** before using plugin
535: 2. **Keep tokens secure** and private
536: 3. **Rotate tokens regularly**
537: 4. **Use different tokens** for dev/prod
538: 5. **Don't commit .env files** to git
539: 6. **Review OAuth scopes** before authorizing
540: 
541: ## Conclusion
542: 
543: Choose the authentication method that matches your MCP server's requirements:
544: - **OAuth** for cloud services (easiest for users)
545: - **Bearer tokens** for API services
546: - **Environment variables** for stdio servers
547: - **Dynamic headers** for complex auth flows
548: 
549: Always prioritize security and provide clear setup documentation for users.
</file>

<file path="__LOCAL-REPO/__skills/development/mcp-integration/references/server-types.md">
  1: # MCP Server Types: Deep Dive
  2: 
  3: Complete reference for all MCP server types supported in Claude Code plugins.
  4: 
  5: ## stdio (Standard Input/Output)
  6: 
  7: ### Overview
  8: 
  9: Execute local MCP servers as child processes with communication via stdin/stdout. Best choice for local tools, custom servers, and NPM packages.
 10: 
 11: ### Configuration
 12: 
 13: **Basic:**
 14: ```json
 15: {
 16:   "my-server": {
 17:     "command": "npx",
 18:     "args": ["-y", "my-mcp-server"]
 19:   }
 20: }
 21: ```
 22: 
 23: **With environment:**
 24: ```json
 25: {
 26:   "my-server": {
 27:     "command": "${CLAUDE_PLUGIN_ROOT}/servers/custom-server",
 28:     "args": ["--config", "${CLAUDE_PLUGIN_ROOT}/config.json"],
 29:     "env": {
 30:       "API_KEY": "${MY_API_KEY}",
 31:       "LOG_LEVEL": "debug",
 32:       "DATABASE_URL": "${DB_URL}"
 33:     }
 34:   }
 35: }
 36: ```
 37: 
 38: ### Process Lifecycle
 39: 
 40: 1. **Startup**: Claude Code spawns process with `command` and `args`
 41: 2. **Communication**: JSON-RPC messages via stdin/stdout
 42: 3. **Lifecycle**: Process runs for entire Claude Code session
 43: 4. **Shutdown**: Process terminated when Claude Code exits
 44: 
 45: ### Use Cases
 46: 
 47: **NPM Packages:**
 48: ```json
 49: {
 50:   "filesystem": {
 51:     "command": "npx",
 52:     "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path"]
 53:   }
 54: }
 55: ```
 56: 
 57: **Custom Scripts:**
 58: ```json
 59: {
 60:   "custom": {
 61:     "command": "${CLAUDE_PLUGIN_ROOT}/servers/my-server.js",
 62:     "args": ["--verbose"]
 63:   }
 64: }
 65: ```
 66: 
 67: **Python Servers:**
 68: ```json
 69: {
 70:   "python-server": {
 71:     "command": "python",
 72:     "args": ["-m", "my_mcp_server"],
 73:     "env": {
 74:       "PYTHONUNBUFFERED": "1"
 75:     }
 76:   }
 77: }
 78: ```
 79: 
 80: ### Best Practices
 81: 
 82: 1. **Use absolute paths or ${CLAUDE_PLUGIN_ROOT}**
 83: 2. **Set PYTHONUNBUFFERED for Python servers**
 84: 3. **Pass configuration via args or env, not stdin**
 85: 4. **Handle server crashes gracefully**
 86: 5. **Log to stderr, not stdout (stdout is for MCP protocol)**
 87: 
 88: ### Troubleshooting
 89: 
 90: **Server won't start:**
 91: - Check command exists and is executable
 92: - Verify file paths are correct
 93: - Check permissions
 94: - Review `claude --debug` logs
 95: 
 96: **Communication fails:**
 97: - Ensure server uses stdin/stdout correctly
 98: - Check for stray print/console.log statements
 99: - Verify JSON-RPC format
100: 
101: ## SSE (Server-Sent Events)
102: 
103: ### Overview
104: 
105: Connect to hosted MCP servers via HTTP with server-sent events for streaming. Best for cloud services and OAuth authentication.
106: 
107: ### Configuration
108: 
109: **Basic:**
110: ```json
111: {
112:   "hosted-service": {
113:     "type": "sse",
114:     "url": "https://mcp.example.com/sse"
115:   }
116: }
117: ```
118: 
119: **With headers:**
120: ```json
121: {
122:   "service": {
123:     "type": "sse",
124:     "url": "https://mcp.example.com/sse",
125:     "headers": {
126:       "X-API-Version": "v1",
127:       "X-Client-ID": "${CLIENT_ID}"
128:     }
129:   }
130: }
131: ```
132: 
133: ### Connection Lifecycle
134: 
135: 1. **Initialization**: HTTP connection established to URL
136: 2. **Handshake**: MCP protocol negotiation
137: 3. **Streaming**: Server sends events via SSE
138: 4. **Requests**: Client sends HTTP POST for tool calls
139: 5. **Reconnection**: Automatic reconnection on disconnect
140: 
141: ### Authentication
142: 
143: **OAuth (Automatic):**
144: ```json
145: {
146:   "asana": {
147:     "type": "sse",
148:     "url": "https://mcp.asana.com/sse"
149:   }
150: }
151: ```
152: 
153: Claude Code handles OAuth flow:
154: 1. User prompted to authenticate on first use
155: 2. Opens browser for OAuth flow
156: 3. Tokens stored securely
157: 4. Automatic token refresh
158: 
159: **Custom Headers:**
160: ```json
161: {
162:   "service": {
163:     "type": "sse",
164:     "url": "https://mcp.example.com/sse",
165:     "headers": {
166:       "Authorization": "Bearer ${API_TOKEN}"
167:     }
168:   }
169: }
170: ```
171: 
172: ### Use Cases
173: 
174: **Official Services:**
175: - Asana: `https://mcp.asana.com/sse`
176: - GitHub: `https://mcp.github.com/sse`
177: - Other hosted MCP servers
178: 
179: **Custom Hosted Servers:**
180: Deploy your own MCP server and expose via HTTPS + SSE.
181: 
182: ### Best Practices
183: 
184: 1. **Always use HTTPS, never HTTP**
185: 2. **Let OAuth handle authentication when available**
186: 3. **Use environment variables for tokens**
187: 4. **Handle connection failures gracefully**
188: 5. **Document OAuth scopes required**
189: 
190: ### Troubleshooting
191: 
192: **Connection refused:**
193: - Check URL is correct and accessible
194: - Verify HTTPS certificate is valid
195: - Check network connectivity
196: - Review firewall settings
197: 
198: **OAuth fails:**
199: - Clear cached tokens
200: - Check OAuth scopes
201: - Verify redirect URLs
202: - Re-authenticate
203: 
204: ## HTTP (REST API)
205: 
206: ### Overview
207: 
208: Connect to RESTful MCP servers via standard HTTP requests. Best for token-based auth and stateless interactions.
209: 
210: ### Configuration
211: 
212: **Basic:**
213: ```json
214: {
215:   "api": {
216:     "type": "http",
217:     "url": "https://api.example.com/mcp"
218:   }
219: }
220: ```
221: 
222: **With authentication:**
223: ```json
224: {
225:   "api": {
226:     "type": "http",
227:     "url": "https://api.example.com/mcp",
228:     "headers": {
229:       "Authorization": "Bearer ${API_TOKEN}",
230:       "Content-Type": "application/json",
231:       "X-API-Version": "2024-01-01"
232:     }
233:   }
234: }
235: ```
236: 
237: ### Request/Response Flow
238: 
239: 1. **Tool Discovery**: GET to discover available tools
240: 2. **Tool Invocation**: POST with tool name and parameters
241: 3. **Response**: JSON response with results or errors
242: 4. **Stateless**: Each request independent
243: 
244: ### Authentication
245: 
246: **Token-Based:**
247: ```json
248: {
249:   "headers": {
250:     "Authorization": "Bearer ${API_TOKEN}"
251:   }
252: }
253: ```
254: 
255: **API Key:**
256: ```json
257: {
258:   "headers": {
259:     "X-API-Key": "${API_KEY}"
260:   }
261: }
262: ```
263: 
264: **Custom Auth:**
265: ```json
266: {
267:   "headers": {
268:     "X-Auth-Token": "${AUTH_TOKEN}",
269:     "X-User-ID": "${USER_ID}"
270:   }
271: }
272: ```
273: 
274: ### Use Cases
275: 
276: - REST API backends
277: - Internal services
278: - Microservices
279: - Serverless functions
280: 
281: ### Best Practices
282: 
283: 1. **Use HTTPS for all connections**
284: 2. **Store tokens in environment variables**
285: 3. **Implement retry logic for transient failures**
286: 4. **Handle rate limiting**
287: 5. **Set appropriate timeouts**
288: 
289: ### Troubleshooting
290: 
291: **HTTP errors:**
292: - 401: Check authentication headers
293: - 403: Verify permissions
294: - 429: Implement rate limiting
295: - 500: Check server logs
296: 
297: **Timeout issues:**
298: - Increase timeout if needed
299: - Check server performance
300: - Optimize tool implementations
301: 
302: ## WebSocket (Real-time)
303: 
304: ### Overview
305: 
306: Connect to MCP servers via WebSocket for real-time bidirectional communication. Best for streaming and low-latency applications.
307: 
308: ### Configuration
309: 
310: **Basic:**
311: ```json
312: {
313:   "realtime": {
314:     "type": "ws",
315:     "url": "wss://mcp.example.com/ws"
316:   }
317: }
318: ```
319: 
320: **With authentication:**
321: ```json
322: {
323:   "realtime": {
324:     "type": "ws",
325:     "url": "wss://mcp.example.com/ws",
326:     "headers": {
327:       "Authorization": "Bearer ${TOKEN}",
328:       "X-Client-ID": "${CLIENT_ID}"
329:     }
330:   }
331: }
332: ```
333: 
334: ### Connection Lifecycle
335: 
336: 1. **Handshake**: WebSocket upgrade request
337: 2. **Connection**: Persistent bidirectional channel
338: 3. **Messages**: JSON-RPC over WebSocket
339: 4. **Heartbeat**: Keep-alive messages
340: 5. **Reconnection**: Automatic on disconnect
341: 
342: ### Use Cases
343: 
344: - Real-time data streaming
345: - Live updates and notifications
346: - Collaborative editing
347: - Low-latency tool calls
348: - Push notifications from server
349: 
350: ### Best Practices
351: 
352: 1. **Use WSS (secure WebSocket), never WS**
353: 2. **Implement heartbeat/ping-pong**
354: 3. **Handle reconnection logic**
355: 4. **Buffer messages during disconnection**
356: 5. **Set connection timeouts**
357: 
358: ### Troubleshooting
359: 
360: **Connection drops:**
361: - Implement reconnection logic
362: - Check network stability
363: - Verify server supports WebSocket
364: - Review firewall settings
365: 
366: **Message delivery:**
367: - Implement message acknowledgment
368: - Handle out-of-order messages
369: - Buffer during disconnection
370: 
371: ## Comparison Matrix
372: 
373: | Feature | stdio | SSE | HTTP | WebSocket |
374: |---------|-------|-----|------|-----------|
375: | **Transport** | Process | HTTP/SSE | HTTP | WebSocket |
376: | **Direction** | Bidirectional | Server→Client | Request/Response | Bidirectional |
377: | **State** | Stateful | Stateful | Stateless | Stateful |
378: | **Auth** | Env vars | OAuth/Headers | Headers | Headers |
379: | **Use Case** | Local tools | Cloud services | REST APIs | Real-time |
380: | **Latency** | Lowest | Medium | Medium | Low |
381: | **Setup** | Easy | Medium | Easy | Medium |
382: | **Reconnect** | Process respawn | Automatic | N/A | Automatic |
383: 
384: ## Choosing the Right Type
385: 
386: **Use stdio when:**
387: - Running local tools or custom servers
388: - Need lowest latency
389: - Working with file systems or local databases
390: - Distributing server with plugin
391: 
392: **Use SSE when:**
393: - Connecting to hosted services
394: - Need OAuth authentication
395: - Using official MCP servers (Asana, GitHub)
396: - Want automatic reconnection
397: 
398: **Use HTTP when:**
399: - Integrating with REST APIs
400: - Need stateless interactions
401: - Using token-based auth
402: - Simple request/response pattern
403: 
404: **Use WebSocket when:**
405: - Need real-time updates
406: - Building collaborative features
407: - Low-latency critical
408: - Bi-directional streaming required
409: 
410: ## Migration Between Types
411: 
412: ### From stdio to SSE
413: 
414: **Before (stdio):**
415: ```json
416: {
417:   "local-server": {
418:     "command": "node",
419:     "args": ["server.js"]
420:   }
421: }
422: ```
423: 
424: **After (SSE - deploy server):**
425: ```json
426: {
427:   "hosted-server": {
428:     "type": "sse",
429:     "url": "https://mcp.example.com/sse"
430:   }
431: }
432: ```
433: 
434: ### From HTTP to WebSocket
435: 
436: **Before (HTTP):**
437: ```json
438: {
439:   "api": {
440:     "type": "http",
441:     "url": "https://api.example.com/mcp"
442:   }
443: }
444: ```
445: 
446: **After (WebSocket):**
447: ```json
448: {
449:   "realtime": {
450:     "type": "ws",
451:     "url": "wss://api.example.com/ws"
452:   }
453: }
454: ```
455: 
456: Benefits: Real-time updates, lower latency, bi-directional communication.
457: 
458: ## Advanced Configuration
459: 
460: ### Multiple Servers
461: 
462: Combine different types:
463: 
464: ```json
465: {
466:   "local-db": {
467:     "command": "npx",
468:     "args": ["-y", "mcp-server-sqlite", "./data.db"]
469:   },
470:   "cloud-api": {
471:     "type": "sse",
472:     "url": "https://mcp.example.com/sse"
473:   },
474:   "internal-service": {
475:     "type": "http",
476:     "url": "https://api.example.com/mcp",
477:     "headers": {
478:       "Authorization": "Bearer ${API_TOKEN}"
479:     }
480:   }
481: }
482: ```
483: 
484: ### Conditional Configuration
485: 
486: Use environment variables to switch servers:
487: 
488: ```json
489: {
490:   "api": {
491:     "type": "http",
492:     "url": "${API_URL}",
493:     "headers": {
494:       "Authorization": "Bearer ${API_TOKEN}"
495:     }
496:   }
497: }
498: ```
499: 
500: Set different values for dev/prod:
501: - Dev: `API_URL=http://localhost:8080/mcp`
502: - Prod: `API_URL=https://api.production.com/mcp`
503: 
504: ## Security Considerations
505: 
506: ### Stdio Security
507: 
508: - Validate command paths
509: - Don't execute user-provided commands
510: - Limit environment variable access
511: - Restrict file system access
512: 
513: ### Network Security
514: 
515: - Always use HTTPS/WSS
516: - Validate SSL certificates
517: - Don't skip certificate verification
518: - Use secure token storage
519: 
520: ### Token Management
521: 
522: - Never hardcode tokens
523: - Use environment variables
524: - Rotate tokens regularly
525: - Implement token refresh
526: - Document scopes required
527: 
528: ## Conclusion
529: 
530: Choose the MCP server type based on your use case:
531: - **stdio** for local, custom, or NPM-packaged servers
532: - **SSE** for hosted services with OAuth
533: - **HTTP** for REST APIs with token auth
534: - **WebSocket** for real-time bidirectional communication
535: 
536: Test thoroughly and handle errors gracefully for robust MCP integration.
</file>

<file path="__LOCAL-REPO/__skills/development/mcp-integration/references/tool-usage.md">
  1: # Using MCP Tools in Commands and Agents
  2: 
  3: Complete guide to using MCP tools effectively in Claude Code plugin commands and agents.
  4: 
  5: ## Overview
  6: 
  7: Once an MCP server is configured, its tools become available with the prefix `mcp__plugin_<plugin-name>_<server-name>__<tool-name>`. Use these tools in commands and agents just like built-in Claude Code tools.
  8: 
  9: ## Tool Naming Convention
 10: 
 11: ### Format
 12: 
 13: ```
 14: mcp__plugin_<plugin-name>_<server-name>__<tool-name>
 15: ```
 16: 
 17: ### Examples
 18: 
 19: **Asana plugin with asana server:**
 20: - `mcp__plugin_asana_asana__asana_create_task`
 21: - `mcp__plugin_asana_asana__asana_search_tasks`
 22: - `mcp__plugin_asana_asana__asana_get_project`
 23: 
 24: **Custom plugin with database server:**
 25: - `mcp__plugin_myplug_database__query`
 26: - `mcp__plugin_myplug_database__execute`
 27: - `mcp__plugin_myplug_database__list_tables`
 28: 
 29: ### Discovering Tool Names
 30: 
 31: **Use `/mcp` command:**
 32: ```bash
 33: /mcp
 34: ```
 35: 
 36: This shows:
 37: - All available MCP servers
 38: - Tools provided by each server
 39: - Tool schemas and descriptions
 40: - Full tool names for use in configuration
 41: 
 42: ## Using Tools in Commands
 43: 
 44: ### Pre-Allowing Tools
 45: 
 46: Specify MCP tools in command frontmatter:
 47: 
 48: ```markdown
 49: ---
 50: description: Create a new Asana task
 51: allowed-tools: [
 52:   "mcp__plugin_asana_asana__asana_create_task"
 53: ]
 54: ---
 55: 
 56: # Create Task Command
 57: 
 58: To create a task:
 59: 1. Gather task details from user
 60: 2. Use mcp__plugin_asana_asana__asana_create_task with the details
 61: 3. Confirm creation to user
 62: ```
 63: 
 64: ### Multiple Tools
 65: 
 66: ```markdown
 67: ---
 68: allowed-tools: [
 69:   "mcp__plugin_asana_asana__asana_create_task",
 70:   "mcp__plugin_asana_asana__asana_search_tasks",
 71:   "mcp__plugin_asana_asana__asana_get_project"
 72: ]
 73: ---
 74: ```
 75: 
 76: ### Wildcard (Use Sparingly)
 77: 
 78: ```markdown
 79: ---
 80: allowed-tools: ["mcp__plugin_asana_asana__*"]
 81: ---
 82: ```
 83: 
 84: **Caution:** Only use wildcards if the command truly needs access to all tools from a server.
 85: 
 86: ### Tool Usage in Command Instructions
 87: 
 88: **Example command:**
 89: ```markdown
 90: ---
 91: description: Search and create Asana tasks
 92: allowed-tools: [
 93:   "mcp__plugin_asana_asana__asana_search_tasks",
 94:   "mcp__plugin_asana_asana__asana_create_task"
 95: ]
 96: ---
 97: 
 98: # Asana Task Management
 99: 
100: ## Searching Tasks
101: 
102: To search for tasks:
103: 1. Use mcp__plugin_asana_asana__asana_search_tasks
104: 2. Provide search filters (assignee, project, etc.)
105: 3. Display results to user
106: 
107: ## Creating Tasks
108: 
109: To create a task:
110: 1. Gather task details:
111:    - Title (required)
112:    - Description
113:    - Project
114:    - Assignee
115:    - Due date
116: 2. Use mcp__plugin_asana_asana__asana_create_task
117: 3. Show confirmation with task link
118: ```
119: 
120: ## Using Tools in Agents
121: 
122: ### Agent Configuration
123: 
124: Agents can use MCP tools autonomously without pre-allowing them:
125: 
126: ```markdown
127: ---
128: name: asana-status-updater
129: description: This agent should be used when the user asks to "update Asana status", "generate project report", or "sync Asana tasks"
130: model: inherit
131: color: blue
132: ---
133: 
134: ## Role
135: 
136: Autonomous agent for generating Asana project status reports.
137: 
138: ## Process
139: 
140: 1. **Query tasks**: Use mcp__plugin_asana_asana__asana_search_tasks to get all tasks
141: 2. **Analyze progress**: Calculate completion rates and identify blockers
142: 3. **Generate report**: Create formatted status update
143: 4. **Update Asana**: Use mcp__plugin_asana_asana__asana_create_comment to post report
144: 
145: ## Available Tools
146: 
147: The agent has access to all Asana MCP tools without pre-approval.
148: ```
149: 
150: ### Agent Tool Access
151: 
152: Agents have broader tool access than commands:
153: - Can use any tool Claude determines is necessary
154: - Don't need pre-allowed lists
155: - Should document which tools they typically use
156: 
157: ## Tool Call Patterns
158: 
159: ### Pattern 1: Simple Tool Call
160: 
161: Single tool call with validation:
162: 
163: ```markdown
164: Steps:
165: 1. Validate user provided required fields
166: 2. Call mcp__plugin_api_server__create_item with validated data
167: 3. Check for errors
168: 4. Display confirmation
169: ```
170: 
171: ### Pattern 2: Sequential Tools
172: 
173: Chain multiple tool calls:
174: 
175: ```markdown
176: Steps:
177: 1. Search for existing items: mcp__plugin_api_server__search
178: 2. If not found, create new: mcp__plugin_api_server__create
179: 3. Add metadata: mcp__plugin_api_server__update_metadata
180: 4. Return final item ID
181: ```
182: 
183: ### Pattern 3: Batch Operations
184: 
185: Multiple calls with same tool:
186: 
187: ```markdown
188: Steps:
189: 1. Get list of items to process
190: 2. For each item:
191:    - Call mcp__plugin_api_server__update_item
192:    - Track success/failure
193: 3. Report results summary
194: ```
195: 
196: ### Pattern 4: Error Handling
197: 
198: Graceful error handling:
199: 
200: ```markdown
201: Steps:
202: 1. Try to call mcp__plugin_api_server__get_data
203: 2. If error (rate limit, network, etc.):
204:    - Wait and retry (max 3 attempts)
205:    - If still failing, inform user
206:    - Suggest checking configuration
207: 3. On success, process data
208: ```
209: 
210: ## Tool Parameters
211: 
212: ### Understanding Tool Schemas
213: 
214: Each MCP tool has a schema defining its parameters. View with `/mcp`.
215: 
216: **Example schema:**
217: ```json
218: {
219:   "name": "asana_create_task",
220:   "description": "Create a new Asana task",
221:   "inputSchema": {
222:     "type": "object",
223:     "properties": {
224:       "name": {
225:         "type": "string",
226:         "description": "Task title"
227:       },
228:       "notes": {
229:         "type": "string",
230:         "description": "Task description"
231:       },
232:       "workspace": {
233:         "type": "string",
234:         "description": "Workspace GID"
235:       }
236:     },
237:     "required": ["name", "workspace"]
238:   }
239: }
240: ```
241: 
242: ### Calling Tools with Parameters
243: 
244: Claude automatically structures tool calls based on schema:
245: 
246: ```typescript
247: // Claude generates this internally
248: {
249:   toolName: "mcp__plugin_asana_asana__asana_create_task",
250:   input: {
251:     name: "Review PR #123",
252:     notes: "Code review for new feature",
253:     workspace: "12345",
254:     assignee: "67890",
255:     due_on: "2025-01-15"
256:   }
257: }
258: ```
259: 
260: ### Parameter Validation
261: 
262: **In commands, validate before calling:**
263: 
264: ```markdown
265: Steps:
266: 1. Check required parameters:
267:    - Title is not empty
268:    - Workspace ID is provided
269:    - Due date is valid format (YYYY-MM-DD)
270: 2. If validation fails, ask user to provide missing data
271: 3. If validation passes, call MCP tool
272: 4. Handle tool errors gracefully
273: ```
274: 
275: ## Response Handling
276: 
277: ### Success Responses
278: 
279: ```markdown
280: Steps:
281: 1. Call MCP tool
282: 2. On success:
283:    - Extract relevant data from response
284:    - Format for user display
285:    - Provide confirmation message
286:    - Include relevant links or IDs
287: ```
288: 
289: ### Error Responses
290: 
291: ```markdown
292: Steps:
293: 1. Call MCP tool
294: 2. On error:
295:    - Check error type (auth, rate limit, validation, etc.)
296:    - Provide helpful error message
297:    - Suggest remediation steps
298:    - Don't expose internal error details to user
299: ```
300: 
301: ### Partial Success
302: 
303: ```markdown
304: Steps:
305: 1. Batch operation with multiple MCP calls
306: 2. Track successes and failures separately
307: 3. Report summary:
308:    - "Successfully processed 8 of 10 items"
309:    - "Failed items: [item1, item2] due to [reason]"
310:    - Suggest retry or manual intervention
311: ```
312: 
313: ## Performance Optimization
314: 
315: ### Batching Requests
316: 
317: **Good: Single query with filters**
318: ```markdown
319: Steps:
320: 1. Call mcp__plugin_api_server__search with filters:
321:    - project_id: "123"
322:    - status: "active"
323:    - limit: 100
324: 2. Process all results
325: ```
326: 
327: **Avoid: Many individual queries**
328: ```markdown
329: Steps:
330: 1. For each item ID:
331:    - Call mcp__plugin_api_server__get_item
332:    - Process item
333: ```
334: 
335: ### Caching Results
336: 
337: ```markdown
338: Steps:
339: 1. Call expensive MCP operation: mcp__plugin_api_server__analyze
340: 2. Store results in variable for reuse
341: 3. Use cached results for subsequent operations
342: 4. Only re-fetch if data changes
343: ```
344: 
345: ### Parallel Tool Calls
346: 
347: When tools don't depend on each other, call in parallel:
348: 
349: ```markdown
350: Steps:
351: 1. Make parallel calls (Claude handles this automatically):
352:    - mcp__plugin_api_server__get_project
353:    - mcp__plugin_api_server__get_users
354:    - mcp__plugin_api_server__get_tags
355: 2. Wait for all to complete
356: 3. Combine results
357: ```
358: 
359: ## Integration Best Practices
360: 
361: ### User Experience
362: 
363: **Provide feedback:**
364: ```markdown
365: Steps:
366: 1. Inform user: "Searching Asana tasks..."
367: 2. Call mcp__plugin_asana_asana__asana_search_tasks
368: 3. Show progress: "Found 15 tasks, analyzing..."
369: 4. Present results
370: ```
371: 
372: **Handle long operations:**
373: ```markdown
374: Steps:
375: 1. Warn user: "This may take a minute..."
376: 2. Break into smaller steps with updates
377: 3. Show incremental progress
378: 4. Final summary when complete
379: ```
380: 
381: ### Error Messages
382: 
383: **Good error messages:**
384: ```
385: ❌ "Could not create task. Please check:
386:    1. You're logged into Asana
387:    2. You have access to workspace 'Engineering'
388:    3. The project 'Q1 Goals' exists"
389: ```
390: 
391: **Poor error messages:**
392: ```
393: ❌ "Error: MCP tool returned 403"
394: ```
395: 
396: ### Documentation
397: 
398: **Document MCP tool usage in command:**
399: ```markdown
400: ## MCP Tools Used
401: 
402: This command uses the following Asana MCP tools:
403: - **asana_search_tasks**: Search for tasks matching criteria
404: - **asana_create_task**: Create new task with details
405: - **asana_update_task**: Update existing task properties
406: 
407: Ensure you're authenticated to Asana before running this command.
408: ```
409: 
410: ## Testing Tool Usage
411: 
412: ### Local Testing
413: 
414: 1. **Configure MCP server** in `.mcp.json`
415: 2. **Install plugin locally** in `.claude-plugin/`
416: 3. **Verify tools available** with `/mcp`
417: 4. **Test command** that uses tools
418: 5. **Check debug output**: `claude --debug`
419: 
420: ### Test Scenarios
421: 
422: **Test successful calls:**
423: ```markdown
424: Steps:
425: 1. Create test data in external service
426: 2. Run command that queries this data
427: 3. Verify correct results returned
428: ```
429: 
430: **Test error cases:**
431: ```markdown
432: Steps:
433: 1. Test with missing authentication
434: 2. Test with invalid parameters
435: 3. Test with non-existent resources
436: 4. Verify graceful error handling
437: ```
438: 
439: **Test edge cases:**
440: ```markdown
441: Steps:
442: 1. Test with empty results
443: 2. Test with maximum results
444: 3. Test with special characters
445: 4. Test with concurrent access
446: ```
447: 
448: ## Common Patterns
449: 
450: ### Pattern: CRUD Operations
451: 
452: ```markdown
453: ---
454: allowed-tools: [
455:   "mcp__plugin_api_server__create_item",
456:   "mcp__plugin_api_server__read_item",
457:   "mcp__plugin_api_server__update_item",
458:   "mcp__plugin_api_server__delete_item"
459: ]
460: ---
461: 
462: # Item Management
463: 
464: ## Create
465: Use create_item with required fields...
466: 
467: ## Read
468: Use read_item with item ID...
469: 
470: ## Update
471: Use update_item with item ID and changes...
472: 
473: ## Delete
474: Use delete_item with item ID (ask for confirmation first)...
475: ```
476: 
477: ### Pattern: Search and Process
478: 
479: ```markdown
480: Steps:
481: 1. **Search**: mcp__plugin_api_server__search with filters
482: 2. **Filter**: Apply additional local filtering if needed
483: 3. **Transform**: Process each result
484: 4. **Present**: Format and display to user
485: ```
486: 
487: ### Pattern: Multi-Step Workflow
488: 
489: ```markdown
490: Steps:
491: 1. **Setup**: Gather all required information
492: 2. **Validate**: Check data completeness
493: 3. **Execute**: Chain of MCP tool calls:
494:    - Create parent resource
495:    - Create child resources
496:    - Link resources together
497:    - Add metadata
498: 4. **Verify**: Confirm all steps succeeded
499: 5. **Report**: Provide summary to user
500: ```
501: 
502: ## Troubleshooting
503: 
504: ### Tools Not Available
505: 
506: **Check:**
507: - MCP server configured correctly
508: - Server connected (check `/mcp`)
509: - Tool names match exactly (case-sensitive)
510: - Restart Claude Code after config changes
511: 
512: ### Tool Calls Failing
513: 
514: **Check:**
515: - Authentication is valid
516: - Parameters match tool schema
517: - Required parameters provided
518: - Check `claude --debug` logs
519: 
520: ### Performance Issues
521: 
522: **Check:**
523: - Batching queries instead of individual calls
524: - Caching results when appropriate
525: - Not making unnecessary tool calls
526: - Parallel calls when possible
527: 
528: ## Conclusion
529: 
530: Effective MCP tool usage requires:
531: 1. **Understanding tool schemas** via `/mcp`
532: 2. **Pre-allowing tools** in commands appropriately
533: 3. **Handling errors gracefully**
534: 4. **Optimizing performance** with batching and caching
535: 5. **Providing good UX** with feedback and clear errors
536: 6. **Testing thoroughly** before deployment
537: 
538: Follow these patterns for robust MCP tool integration in your plugin commands and agents.
</file>

<file path="__LOCAL-REPO/__skills/development/mcp-integration/SKILL.md">
  1: ---
  2: name: MCP Integration
  3: description: This skill should be used when the user asks to "add MCP server", "integrate MCP", "configure MCP in plugin", "use .mcp.json", "set up Model Context Protocol", "connect external service", mentions "${CLAUDE_PLUGIN_ROOT} with MCP", or discusses MCP server types (SSE, stdio, HTTP, WebSocket). Provides comprehensive guidance for integrating Model Context Protocol servers into Claude Code plugins for external tool and service integration.
  4: version: 0.1.0
  5: ---
  6: 
  7: # MCP Integration for Claude Code Plugins
  8: 
  9: ## Overview
 10: 
 11: Model Context Protocol (MCP) enables Claude Code plugins to integrate with external services and APIs by providing structured tool access. Use MCP integration to expose external service capabilities as tools within Claude Code.
 12: 
 13: **Key capabilities:**
 14: - Connect to external services (databases, APIs, file systems)
 15: - Provide 10+ related tools from a single service
 16: - Handle OAuth and complex authentication flows
 17: - Bundle MCP servers with plugins for automatic setup
 18: 
 19: ## MCP Server Configuration Methods
 20: 
 21: Plugins can bundle MCP servers in two ways:
 22: 
 23: ### Method 1: Dedicated .mcp.json (Recommended)
 24: 
 25: Create `.mcp.json` at plugin root:
 26: 
 27: ```json
 28: {
 29:   "database-tools": {
 30:     "command": "${CLAUDE_PLUGIN_ROOT}/servers/db-server",
 31:     "args": ["--config", "${CLAUDE_PLUGIN_ROOT}/config.json"],
 32:     "env": {
 33:       "DB_URL": "${DB_URL}"
 34:     }
 35:   }
 36: }
 37: ```
 38: 
 39: **Benefits:**
 40: - Clear separation of concerns
 41: - Easier to maintain
 42: - Better for multiple servers
 43: 
 44: ### Method 2: Inline in plugin.json
 45: 
 46: Add `mcpServers` field to plugin.json:
 47: 
 48: ```json
 49: {
 50:   "name": "my-plugin",
 51:   "version": "1.0.0",
 52:   "mcpServers": {
 53:     "plugin-api": {
 54:       "command": "${CLAUDE_PLUGIN_ROOT}/servers/api-server",
 55:       "args": ["--port", "8080"]
 56:     }
 57:   }
 58: }
 59: ```
 60: 
 61: **Benefits:**
 62: - Single configuration file
 63: - Good for simple single-server plugins
 64: 
 65: ## MCP Server Types
 66: 
 67: ### stdio (Local Process)
 68: 
 69: Execute local MCP servers as child processes. Best for local tools and custom servers.
 70: 
 71: **Configuration:**
 72: ```json
 73: {
 74:   "filesystem": {
 75:     "command": "npx",
 76:     "args": ["-y", "@modelcontextprotocol/server-filesystem", "/allowed/path"],
 77:     "env": {
 78:       "LOG_LEVEL": "debug"
 79:     }
 80:   }
 81: }
 82: ```
 83: 
 84: **Use cases:**
 85: - File system access
 86: - Local database connections
 87: - Custom MCP servers
 88: - NPM-packaged MCP servers
 89: 
 90: **Process management:**
 91: - Claude Code spawns and manages the process
 92: - Communicates via stdin/stdout
 93: - Terminates when Claude Code exits
 94: 
 95: ### SSE (Server-Sent Events)
 96: 
 97: Connect to hosted MCP servers with OAuth support. Best for cloud services.
 98: 
 99: **Configuration:**
100: ```json
101: {
102:   "asana": {
103:     "type": "sse",
104:     "url": "https://mcp.asana.com/sse"
105:   }
106: }
107: ```
108: 
109: **Use cases:**
110: - Official hosted MCP servers (Asana, GitHub, etc.)
111: - Cloud services with MCP endpoints
112: - OAuth-based authentication
113: - No local installation needed
114: 
115: **Authentication:**
116: - OAuth flows handled automatically
117: - User prompted on first use
118: - Tokens managed by Claude Code
119: 
120: ### HTTP (REST API)
121: 
122: Connect to RESTful MCP servers with token authentication.
123: 
124: **Configuration:**
125: ```json
126: {
127:   "api-service": {
128:     "type": "http",
129:     "url": "https://api.example.com/mcp",
130:     "headers": {
131:       "Authorization": "Bearer ${API_TOKEN}",
132:       "X-Custom-Header": "value"
133:     }
134:   }
135: }
136: ```
137: 
138: **Use cases:**
139: - REST API-based MCP servers
140: - Token-based authentication
141: - Custom API backends
142: - Stateless interactions
143: 
144: ### WebSocket (Real-time)
145: 
146: Connect to WebSocket MCP servers for real-time bidirectional communication.
147: 
148: **Configuration:**
149: ```json
150: {
151:   "realtime-service": {
152:     "type": "ws",
153:     "url": "wss://mcp.example.com/ws",
154:     "headers": {
155:       "Authorization": "Bearer ${TOKEN}"
156:     }
157:   }
158: }
159: ```
160: 
161: **Use cases:**
162: - Real-time data streaming
163: - Persistent connections
164: - Push notifications from server
165: - Low-latency requirements
166: 
167: ## Environment Variable Expansion
168: 
169: All MCP configurations support environment variable substitution:
170: 
171: **${CLAUDE_PLUGIN_ROOT}** - Plugin directory (always use for portability):
172: ```json
173: {
174:   "command": "${CLAUDE_PLUGIN_ROOT}/servers/my-server"
175: }
176: ```
177: 
178: **User environment variables** - From user's shell:
179: ```json
180: {
181:   "env": {
182:     "API_KEY": "${MY_API_KEY}",
183:     "DATABASE_URL": "${DB_URL}"
184:   }
185: }
186: ```
187: 
188: **Best practice:** Document all required environment variables in plugin README.
189: 
190: ## MCP Tool Naming
191: 
192: When MCP servers provide tools, they're automatically prefixed:
193: 
194: **Format:** `mcp__plugin_<plugin-name>_<server-name>__<tool-name>`
195: 
196: **Example:**
197: - Plugin: `asana`
198: - Server: `asana`
199: - Tool: `create_task`
200: - **Full name:** `mcp__plugin_asana_asana__asana_create_task`
201: 
202: ### Using MCP Tools in Commands
203: 
204: Pre-allow specific MCP tools in command frontmatter:
205: 
206: ```markdown
207: ---
208: allowed-tools: [
209:   "mcp__plugin_asana_asana__asana_create_task",
210:   "mcp__plugin_asana_asana__asana_search_tasks"
211: ]
212: ---
213: ```
214: 
215: **Wildcard (use sparingly):**
216: ```markdown
217: ---
218: allowed-tools: ["mcp__plugin_asana_asana__*"]
219: ---
220: ```
221: 
222: **Best practice:** Pre-allow specific tools, not wildcards, for security.
223: 
224: ## Lifecycle Management
225: 
226: **Automatic startup:**
227: - MCP servers start when plugin enables
228: - Connection established before first tool use
229: - Restart required for configuration changes
230: 
231: **Lifecycle:**
232: 1. Plugin loads
233: 2. MCP configuration parsed
234: 3. Server process started (stdio) or connection established (SSE/HTTP/WS)
235: 4. Tools discovered and registered
236: 5. Tools available as `mcp__plugin_...__...`
237: 
238: **Viewing servers:**
239: Use `/mcp` command to see all servers including plugin-provided ones.
240: 
241: ## Authentication Patterns
242: 
243: ### OAuth (SSE/HTTP)
244: 
245: OAuth handled automatically by Claude Code:
246: 
247: ```json
248: {
249:   "type": "sse",
250:   "url": "https://mcp.example.com/sse"
251: }
252: ```
253: 
254: User authenticates in browser on first use. No additional configuration needed.
255: 
256: ### Token-Based (Headers)
257: 
258: Static or environment variable tokens:
259: 
260: ```json
261: {
262:   "type": "http",
263:   "url": "https://api.example.com",
264:   "headers": {
265:     "Authorization": "Bearer ${API_TOKEN}"
266:   }
267: }
268: ```
269: 
270: Document required environment variables in README.
271: 
272: ### Environment Variables (stdio)
273: 
274: Pass configuration to MCP server:
275: 
276: ```json
277: {
278:   "command": "python",
279:   "args": ["-m", "my_mcp_server"],
280:   "env": {
281:     "DATABASE_URL": "${DB_URL}",
282:     "API_KEY": "${API_KEY}",
283:     "LOG_LEVEL": "info"
284:   }
285: }
286: ```
287: 
288: ## Integration Patterns
289: 
290: ### Pattern 1: Simple Tool Wrapper
291: 
292: Commands use MCP tools with user interaction:
293: 
294: ```markdown
295: # Command: create-item.md
296: ---
297: allowed-tools: ["mcp__plugin_name_server__create_item"]
298: ---
299: 
300: Steps:
301: 1. Gather item details from user
302: 2. Use mcp__plugin_name_server__create_item
303: 3. Confirm creation
304: ```
305: 
306: **Use for:** Adding validation or preprocessing before MCP calls.
307: 
308: ### Pattern 2: Autonomous Agent
309: 
310: Agents use MCP tools autonomously:
311: 
312: ```markdown
313: # Agent: data-analyzer.md
314: 
315: Analysis Process:
316: 1. Query data via mcp__plugin_db_server__query
317: 2. Process and analyze results
318: 3. Generate insights report
319: ```
320: 
321: **Use for:** Multi-step MCP workflows without user interaction.
322: 
323: ### Pattern 3: Multi-Server Plugin
324: 
325: Integrate multiple MCP servers:
326: 
327: ```json
328: {
329:   "github": {
330:     "type": "sse",
331:     "url": "https://mcp.github.com/sse"
332:   },
333:   "jira": {
334:     "type": "sse",
335:     "url": "https://mcp.jira.com/sse"
336:   }
337: }
338: ```
339: 
340: **Use for:** Workflows spanning multiple services.
341: 
342: ## Security Best Practices
343: 
344: ### Use HTTPS/WSS
345: 
346: Always use secure connections:
347: 
348: ```json
349: ✅ "url": "https://mcp.example.com/sse"
350: ❌ "url": "http://mcp.example.com/sse"
351: ```
352: 
353: ### Token Management
354: 
355: **DO:**
356: - ✅ Use environment variables for tokens
357: - ✅ Document required env vars in README
358: - ✅ Let OAuth flow handle authentication
359: 
360: **DON'T:**
361: - ❌ Hardcode tokens in configuration
362: - ❌ Commit tokens to git
363: - ❌ Share tokens in documentation
364: 
365: ### Permission Scoping
366: 
367: Pre-allow only necessary MCP tools:
368: 
369: ```markdown
370: ✅ allowed-tools: [
371:   "mcp__plugin_api_server__read_data",
372:   "mcp__plugin_api_server__create_item"
373: ]
374: 
375: ❌ allowed-tools: ["mcp__plugin_api_server__*"]
376: ```
377: 
378: ## Error Handling
379: 
380: ### Connection Failures
381: 
382: Handle MCP server unavailability:
383: - Provide fallback behavior in commands
384: - Inform user of connection issues
385: - Check server URL and configuration
386: 
387: ### Tool Call Errors
388: 
389: Handle failed MCP operations:
390: - Validate inputs before calling MCP tools
391: - Provide clear error messages
392: - Check rate limiting and quotas
393: 
394: ### Configuration Errors
395: 
396: Validate MCP configuration:
397: - Test server connectivity during development
398: - Validate JSON syntax
399: - Check required environment variables
400: 
401: ## Performance Considerations
402: 
403: ### Lazy Loading
404: 
405: MCP servers connect on-demand:
406: - Not all servers connect at startup
407: - First tool use triggers connection
408: - Connection pooling managed automatically
409: 
410: ### Batching
411: 
412: Batch similar requests when possible:
413: 
414: ```
415: # Good: Single query with filters
416: tasks = search_tasks(project="X", assignee="me", limit=50)
417: 
418: # Avoid: Many individual queries
419: for id in task_ids:
420:     task = get_task(id)
421: ```
422: 
423: ## Testing MCP Integration
424: 
425: ### Local Testing
426: 
427: 1. Configure MCP server in `.mcp.json`
428: 2. Install plugin locally (`.claude-plugin/`)
429: 3. Run `/mcp` to verify server appears
430: 4. Test tool calls in commands
431: 5. Check `claude --debug` logs for connection issues
432: 
433: ### Validation Checklist
434: 
435: - [ ] MCP configuration is valid JSON
436: - [ ] Server URL is correct and accessible
437: - [ ] Required environment variables documented
438: - [ ] Tools appear in `/mcp` output
439: - [ ] Authentication works (OAuth or tokens)
440: - [ ] Tool calls succeed from commands
441: - [ ] Error cases handled gracefully
442: 
443: ## Debugging
444: 
445: ### Enable Debug Logging
446: 
447: ```bash
448: claude --debug
449: ```
450: 
451: Look for:
452: - MCP server connection attempts
453: - Tool discovery logs
454: - Authentication flows
455: - Tool call errors
456: 
457: ### Common Issues
458: 
459: **Server not connecting:**
460: - Check URL is correct
461: - Verify server is running (stdio)
462: - Check network connectivity
463: - Review authentication configuration
464: 
465: **Tools not available:**
466: - Verify server connected successfully
467: - Check tool names match exactly
468: - Run `/mcp` to see available tools
469: - Restart Claude Code after config changes
470: 
471: **Authentication failing:**
472: - Clear cached auth tokens
473: - Re-authenticate
474: - Check token scopes and permissions
475: - Verify environment variables set
476: 
477: ## Quick Reference
478: 
479: ### MCP Server Types
480: 
481: | Type | Transport | Best For | Auth |
482: |------|-----------|----------|------|
483: | stdio | Process | Local tools, custom servers | Env vars |
484: | SSE | HTTP | Hosted services, cloud APIs | OAuth |
485: | HTTP | REST | API backends, token auth | Tokens |
486: | ws | WebSocket | Real-time, streaming | Tokens |
487: 
488: ### Configuration Checklist
489: 
490: - [ ] Server type specified (stdio/SSE/HTTP/ws)
491: - [ ] Type-specific fields complete (command or url)
492: - [ ] Authentication configured
493: - [ ] Environment variables documented
494: - [ ] HTTPS/WSS used (not HTTP/WS)
495: - [ ] ${CLAUDE_PLUGIN_ROOT} used for paths
496: 
497: ### Best Practices
498: 
499: **DO:**
500: - ✅ Use ${CLAUDE_PLUGIN_ROOT} for portable paths
501: - ✅ Document required environment variables
502: - ✅ Use secure connections (HTTPS/WSS)
503: - ✅ Pre-allow specific MCP tools in commands
504: - ✅ Test MCP integration before publishing
505: - ✅ Handle connection and tool errors gracefully
506: 
507: **DON'T:**
508: - ❌ Hardcode absolute paths
509: - ❌ Commit credentials to git
510: - ❌ Use HTTP instead of HTTPS
511: - ❌ Pre-allow all tools with wildcards
512: - ❌ Skip error handling
513: - ❌ Forget to document setup
514: 
515: ## Additional Resources
516: 
517: ### Reference Files
518: 
519: For detailed information, consult:
520: 
521: - **`references/server-types.md`** - Deep dive on each server type
522: - **`references/authentication.md`** - Authentication patterns and OAuth
523: - **`references/tool-usage.md`** - Using MCP tools in commands and agents
524: 
525: ### Example Configurations
526: 
527: Working examples in `examples/`:
528: 
529: - **`stdio-server.json`** - Local stdio MCP server
530: - **`sse-server.json`** - Hosted SSE server with OAuth
531: - **`http-server.json`** - REST API with token auth
532: 
533: ### External Resources
534: 
535: - **Official MCP Docs**: https://modelcontextprotocol.io/
536: - **Claude Code MCP Docs**: https://docs.claude.com/en/docs/claude-code/mcp
537: - **MCP SDK**: @modelcontextprotocol/sdk
538: - **Testing**: Use `claude --debug` and `/mcp` command
539: 
540: ## Implementation Workflow
541: 
542: To add MCP integration to a plugin:
543: 
544: 1. Choose MCP server type (stdio, SSE, HTTP, ws)
545: 2. Create `.mcp.json` at plugin root with configuration
546: 3. Use ${CLAUDE_PLUGIN_ROOT} for all file references
547: 4. Document required environment variables in README
548: 5. Test locally with `/mcp` command
549: 6. Pre-allow MCP tools in relevant commands
550: 7. Handle authentication (OAuth or tokens)
551: 8. Test error cases (connection failures, auth errors)
552: 9. Document MCP integration in plugin README
553: 
554: Focus on stdio for custom/local servers, SSE for hosted services with OAuth.
</file>

<file path="__LOCAL-REPO/__skills/development/skill-development/SKILL.md">
  1: ---
  2: name: Skill Development
  3: description: This skill should be used when the user wants to "create a skill", "add a skill to plugin", "write a new skill", "improve skill description", "organize skill content", or needs guidance on skill structure, progressive disclosure, or skill development best practices for Claude Code plugins.
  4: version: 0.1.0
  5: ---
  6: 
  7: # Skill Development for Claude Code Plugins
  8: 
  9: This skill provides guidance for creating effective skills for Claude Code plugins.
 10: 
 11: ## About Skills
 12: 
 13: Skills are modular, self-contained packages that extend Claude's capabilities by providing
 14: specialized knowledge, workflows, and tools. Think of them as "onboarding guides" for specific
 15: domains or tasks—they transform Claude from a general-purpose agent into a specialized agent
 16: equipped with procedural knowledge that no model can fully possess.
 17: 
 18: ### What Skills Provide
 19: 
 20: 1. Specialized workflows - Multi-step procedures for specific domains
 21: 2. Tool integrations - Instructions for working with specific file formats or APIs
 22: 3. Domain expertise - Company-specific knowledge, schemas, business logic
 23: 4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks
 24: 
 25: ### Anatomy of a Skill
 26: 
 27: Every skill consists of a required SKILL.md file and optional bundled resources:
 28: 
 29: ```
 30: skill-name/
 31: ├── SKILL.md (required)
 32: │   ├── YAML frontmatter metadata (required)
 33: │   │   ├── name: (required)
 34: │   │   └── description: (required)
 35: │   └── Markdown instructions (required)
 36: └── Bundled Resources (optional)
 37:     ├── scripts/          - Executable code (Python/Bash/etc.)
 38:     ├── references/       - Documentation intended to be loaded into context as needed
 39:     └── assets/           - Files used in output (templates, icons, fonts, etc.)
 40: ```
 41: 
 42: #### SKILL.md (required)
 43: 
 44: **Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. "This skill should be used when..." instead of "Use this skill when...").
 45: 
 46: #### Bundled Resources (optional)
 47: 
 48: ##### Scripts (`scripts/`)
 49: 
 50: Executable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.
 51: 
 52: - **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed
 53: - **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks
 54: - **Benefits**: Token efficient, deterministic, may be executed without loading into context
 55: - **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments
 56: 
 57: ##### References (`references/`)
 58: 
 59: Documentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.
 60: 
 61: - **When to include**: For documentation that Claude should reference while working
 62: - **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications
 63: - **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides
 64: - **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed
 65: - **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md
 66: - **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill—this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.
 67: 
 68: ##### Assets (`assets/`)
 69: 
 70: Files not intended to be loaded into context, but rather used within the output Claude produces.
 71: 
 72: - **When to include**: When the skill needs files that will be used in the final output
 73: - **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography
 74: - **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified
 75: - **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context
 76: 
 77: ### Progressive Disclosure Design Principle
 78: 
 79: Skills use a three-level loading system to manage context efficiently:
 80: 
 81: 1. **Metadata (name + description)** - Always in context (~100 words)
 82: 2. **SKILL.md body** - When skill triggers (<5k words)
 83: 3. **Bundled resources** - As needed by Claude (Unlimited*)
 84: 
 85: *Unlimited because scripts can be executed without reading into context window.
 86: 
 87: ## Skill Creation Process
 88: 
 89: To create a skill, follow the "Skill Creation Process" in order, skipping steps only if there is a clear reason why they are not applicable.
 90: 
 91: ### Step 1: Understanding the Skill with Concrete Examples
 92: 
 93: Skip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.
 94: 
 95: To create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.
 96: 
 97: For example, when building an image-editor skill, relevant questions include:
 98: 
 99: - "What functionality should the image-editor skill support? Editing, rotating, anything else?"
100: - "Can you give some examples of how this skill would be used?"
101: - "I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?"
102: - "What would a user say that should trigger this skill?"
103: 
104: To avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.
105: 
106: Conclude this step when there is a clear sense of the functionality the skill should support.
107: 
108: ### Step 2: Planning the Reusable Skill Contents
109: 
110: To turn concrete examples into an effective skill, analyze each example by:
111: 
112: 1. Considering how to execute on the example from scratch
113: 2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly
114: 
115: Example: When building a `pdf-editor` skill to handle queries like "Help me rotate this PDF," the analysis shows:
116: 
117: 1. Rotating a PDF requires re-writing the same code each time
118: 2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill
119: 
120: Example: When designing a `frontend-webapp-builder` skill for queries like "Build me a todo app" or "Build me a dashboard to track my steps," the analysis shows:
121: 
122: 1. Writing a frontend webapp requires the same boilerplate HTML/React each time
123: 2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill
124: 
125: Example: When building a `big-query` skill to handle queries like "How many users have logged in today?" the analysis shows:
126: 
127: 1. Querying BigQuery requires re-discovering the table schemas and relationships each time
128: 2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill
129: 
130: **For Claude Code plugins:** When building a hooks skill, the analysis shows:
131: 1. Developers repeatedly need to validate hooks.json and test hook scripts
132: 2. `scripts/validate-hook-schema.sh` and `scripts/test-hook.sh` utilities would be helpful
133: 3. `references/patterns.md` for detailed hook patterns to avoid bloating SKILL.md
134: 
135: To establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.
136: 
137: ### Step 3: Create Skill Structure
138: 
139: For Claude Code plugins, create the skill directory structure:
140: 
141: ```bash
142: mkdir -p plugin-name/skills/skill-name/{references,examples,scripts}
143: touch plugin-name/skills/skill-name/SKILL.md
144: ```
145: 
146: **Note:** Unlike the generic skill-creator which uses `init_skill.py`, plugin skills are created directly in the plugin's `skills/` directory with a simpler manual structure.
147: 
148: ### Step 4: Edit the Skill
149: 
150: When editing the (newly-created or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.
151: 
152: #### Start with Reusable Skill Contents
153: 
154: To begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.
155: 
156: Also, delete any example files and directories not needed for the skill. Create only the directories you actually need (references/, examples/, scripts/).
157: 
158: #### Update SKILL.md
159: 
160: **Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., "To accomplish X, do Y" rather than "You should do X" or "If you need to do X"). This maintains consistency and clarity for AI consumption.
161: 
162: **Description (Frontmatter):** Use third-person format with specific trigger phrases:
163: 
164: ```yaml
165: ---
166: name: Skill Name
167: description: This skill should be used when the user asks to "specific phrase 1", "specific phrase 2", "specific phrase 3". Include exact phrases users would say that should trigger this skill. Be concrete and specific.
168: version: 0.1.0
169: ---
170: ```
171: 
172: **Good description examples:**
173: ```yaml
174: description: This skill should be used when the user asks to "create a hook", "add a PreToolUse hook", "validate tool use", "implement prompt-based hooks", or mentions hook events (PreToolUse, PostToolUse, Stop).
175: ```
176: 
177: **Bad description examples:**
178: ```yaml
179: description: Use this skill when working with hooks.  # Wrong person, vague
180: description: Load when user needs hook help.  # Not third person
181: description: Provides hook guidance.  # No trigger phrases
182: ```
183: 
184: To complete SKILL.md body, answer the following questions:
185: 
186: 1. What is the purpose of the skill, in a few sentences?
187: 2. When should the skill be used? (Include this in frontmatter description with specific triggers)
188: 3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.
189: 
190: **Keep SKILL.md lean:** Target 1,500-2,000 words for the body. Move detailed content to references/:
191: - Detailed patterns → `references/patterns.md`
192: - Advanced techniques → `references/advanced.md`
193: - Migration guides → `references/migration.md`
194: - API references → `references/api-reference.md`
195: 
196: **Reference resources in SKILL.md:**
197: ```markdown
198: ## Additional Resources
199: 
200: ### Reference Files
201: 
202: For detailed patterns and techniques, consult:
203: - **`references/patterns.md`** - Common patterns
204: - **`references/advanced.md`** - Advanced use cases
205: 
206: ### Example Files
207: 
208: Working examples in `examples/`:
209: - **`example-script.sh`** - Working example
210: ```
211: 
212: ### Step 5: Validate and Test
213: 
214: **For plugin skills, validation is different from generic skills:**
215: 
216: 1. **Check structure**: Skill directory in `plugin-name/skills/skill-name/`
217: 2. **Validate SKILL.md**: Has frontmatter with name and description
218: 3. **Check trigger phrases**: Description includes specific user queries
219: 4. **Verify writing style**: Body uses imperative/infinitive form, not second person
220: 5. **Test progressive disclosure**: SKILL.md is lean (~1,500-2,000 words), detailed content in references/
221: 6. **Check references**: All referenced files exist
222: 7. **Validate examples**: Examples are complete and correct
223: 8. **Test scripts**: Scripts are executable and work correctly
224: 
225: **Use the skill-reviewer agent:**
226: ```
227: Ask: "Review my skill and check if it follows best practices"
228: ```
229: 
230: The skill-reviewer agent will check description quality, content organization, and progressive disclosure.
231: 
232: ### Step 6: Iterate
233: 
234: After testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.
235: 
236: **Iteration workflow:**
237: 1. Use the skill on real tasks
238: 2. Notice struggles or inefficiencies
239: 3. Identify how SKILL.md or bundled resources should be updated
240: 4. Implement changes and test again
241: 
242: **Common improvements:**
243: - Strengthen trigger phrases in description
244: - Move long sections from SKILL.md to references/
245: - Add missing examples or scripts
246: - Clarify ambiguous instructions
247: - Add edge case handling
248: 
249: ## Plugin-Specific Considerations
250: 
251: ### Skill Location in Plugins
252: 
253: Plugin skills live in the plugin's `skills/` directory:
254: 
255: ```
256: my-plugin/
257: ├── .claude-plugin/
258: │   └── plugin.json
259: ├── commands/
260: ├── agents/
261: └── skills/
262:     └── my-skill/
263:         ├── SKILL.md
264:         ├── references/
265:         ├── examples/
266:         └── scripts/
267: ```
268: 
269: ### Auto-Discovery
270: 
271: Claude Code automatically discovers skills:
272: - Scans `skills/` directory
273: - Finds subdirectories containing `SKILL.md`
274: - Loads skill metadata (name + description) always
275: - Loads SKILL.md body when skill triggers
276: - Loads references/examples when needed
277: 
278: ### No Packaging Needed
279: 
280: Plugin skills are distributed as part of the plugin, not as separate ZIP files. Users get skills when they install the plugin.
281: 
282: ### Testing in Plugins
283: 
284: Test skills by installing plugin locally:
285: 
286: ```bash
287: # Test with --plugin-dir
288: cc --plugin-dir /path/to/plugin
289: 
290: # Ask questions that should trigger the skill
291: # Verify skill loads correctly
292: ```
293: 
294: ## Examples from Plugin-Dev
295: 
296: Study the skills in this plugin as examples of best practices:
297: 
298: **hook-development skill:**
299: - Excellent trigger phrases: "create a hook", "add a PreToolUse hook", etc.
300: - Lean SKILL.md (1,651 words)
301: - 3 references/ files for detailed content
302: - 3 examples/ of working hooks
303: - 3 scripts/ utilities
304: 
305: **agent-development skill:**
306: - Strong triggers: "create an agent", "agent frontmatter", etc.
307: - Focused SKILL.md (1,438 words)
308: - References include the AI generation prompt from Claude Code
309: - Complete agent examples
310: 
311: **plugin-settings skill:**
312: - Specific triggers: "plugin settings", ".local.md files", "YAML frontmatter"
313: - References show real implementations (multi-agent-swarm, ralph-wiggum)
314: - Working parsing scripts
315: 
316: Each demonstrates progressive disclosure and strong triggering.
317: 
318: ## Progressive Disclosure in Practice
319: 
320: ### What Goes in SKILL.md
321: 
322: **Include (always loaded when skill triggers):**
323: - Core concepts and overview
324: - Essential procedures and workflows
325: - Quick reference tables
326: - Pointers to references/examples/scripts
327: - Most common use cases
328: 
329: **Keep under 3,000 words, ideally 1,500-2,000 words**
330: 
331: ### What Goes in references/
332: 
333: **Move to references/ (loaded as needed):**
334: - Detailed patterns and advanced techniques
335: - Comprehensive API documentation
336: - Migration guides
337: - Edge cases and troubleshooting
338: - Extensive examples and walkthroughs
339: 
340: **Each reference file can be large (2,000-5,000+ words)**
341: 
342: ### What Goes in examples/
343: 
344: **Working code examples:**
345: - Complete, runnable scripts
346: - Configuration files
347: - Template files
348: - Real-world usage examples
349: 
350: **Users can copy and adapt these directly**
351: 
352: ### What Goes in scripts/
353: 
354: **Utility scripts:**
355: - Validation tools
356: - Testing helpers
357: - Parsing utilities
358: - Automation scripts
359: 
360: **Should be executable and documented**
361: 
362: ## Writing Style Requirements
363: 
364: ### Imperative/Infinitive Form
365: 
366: Write using verb-first instructions, not second person:
367: 
368: **Correct (imperative):**
369: ```
370: To create a hook, define the event type.
371: Configure the MCP server with authentication.
372: Validate settings before use.
373: ```
374: 
375: **Incorrect (second person):**
376: ```
377: You should create a hook by defining the event type.
378: You need to configure the MCP server.
379: You must validate settings before use.
380: ```
381: 
382: ### Third-Person in Description
383: 
384: The frontmatter description must use third person:
385: 
386: **Correct:**
387: ```yaml
388: description: This skill should be used when the user asks to "create X", "configure Y"...
389: ```
390: 
391: **Incorrect:**
392: ```yaml
393: description: Use this skill when you want to create X...
394: description: Load this skill when user asks...
395: ```
396: 
397: ### Objective, Instructional Language
398: 
399: Focus on what to do, not who should do it:
400: 
401: **Correct:**
402: ```
403: Parse the frontmatter using sed.
404: Extract fields with grep.
405: Validate values before use.
406: ```
407: 
408: **Incorrect:**
409: ```
410: You can parse the frontmatter...
411: Claude should extract fields...
412: The user might validate values...
413: ```
414: 
415: ## Validation Checklist
416: 
417: Before finalizing a skill:
418: 
419: **Structure:**
420: - [ ] SKILL.md file exists with valid YAML frontmatter
421: - [ ] Frontmatter has `name` and `description` fields
422: - [ ] Markdown body is present and substantial
423: - [ ] Referenced files actually exist
424: 
425: **Description Quality:**
426: - [ ] Uses third person ("This skill should be used when...")
427: - [ ] Includes specific trigger phrases users would say
428: - [ ] Lists concrete scenarios ("create X", "configure Y")
429: - [ ] Not vague or generic
430: 
431: **Content Quality:**
432: - [ ] SKILL.md body uses imperative/infinitive form
433: - [ ] Body is focused and lean (1,500-2,000 words ideal, <5k max)
434: - [ ] Detailed content moved to references/
435: - [ ] Examples are complete and working
436: - [ ] Scripts are executable and documented
437: 
438: **Progressive Disclosure:**
439: - [ ] Core concepts in SKILL.md
440: - [ ] Detailed docs in references/
441: - [ ] Working code in examples/
442: - [ ] Utilities in scripts/
443: - [ ] SKILL.md references these resources
444: 
445: **Testing:**
446: - [ ] Skill triggers on expected user queries
447: - [ ] Content is helpful for intended tasks
448: - [ ] No duplicated information across files
449: - [ ] References load when needed
450: 
451: ## Common Mistakes to Avoid
452: 
453: ### Mistake 1: Weak Trigger Description
454: 
455: ❌ **Bad:**
456: ```yaml
457: description: Provides guidance for working with hooks.
458: ```
459: 
460: **Why bad:** Vague, no specific trigger phrases, not third person
461: 
462: ✅ **Good:**
463: ```yaml
464: description: This skill should be used when the user asks to "create a hook", "add a PreToolUse hook", "validate tool use", or mentions hook events. Provides comprehensive hooks API guidance.
465: ```
466: 
467: **Why good:** Third person, specific phrases, concrete scenarios
468: 
469: ### Mistake 2: Too Much in SKILL.md
470: 
471: ❌ **Bad:**
472: ```
473: skill-name/
474: └── SKILL.md  (8,000 words - everything in one file)
475: ```
476: 
477: **Why bad:** Bloats context when skill loads, detailed content always loaded
478: 
479: ✅ **Good:**
480: ```
481: skill-name/
482: ├── SKILL.md  (1,800 words - core essentials)
483: └── references/
484:     ├── patterns.md (2,500 words)
485:     └── advanced.md (3,700 words)
486: ```
487: 
488: **Why good:** Progressive disclosure, detailed content loaded only when needed
489: 
490: ### Mistake 3: Second Person Writing
491: 
492: ❌ **Bad:**
493: ```markdown
494: You should start by reading the configuration file.
495: You need to validate the input.
496: You can use the grep tool to search.
497: ```
498: 
499: **Why bad:** Second person, not imperative form
500: 
501: ✅ **Good:**
502: ```markdown
503: Start by reading the configuration file.
504: Validate the input before processing.
505: Use the grep tool to search for patterns.
506: ```
507: 
508: **Why good:** Imperative form, direct instructions
509: 
510: ### Mistake 4: Missing Resource References
511: 
512: ❌ **Bad:**
513: ```markdown
514: # SKILL.md
515: 
516: [Core content]
517: 
518: [No mention of references/ or examples/]
519: ```
520: 
521: **Why bad:** Claude doesn't know references exist
522: 
523: ✅ **Good:**
524: ```markdown
525: # SKILL.md
526: 
527: [Core content]
528: 
529: ## Additional Resources
530: 
531: ### Reference Files
532: - **`references/patterns.md`** - Detailed patterns
533: - **`references/advanced.md`** - Advanced techniques
534: 
535: ### Examples
536: - **`examples/script.sh`** - Working example
537: ```
538: 
539: **Why good:** Claude knows where to find additional information
540: 
541: ## Quick Reference
542: 
543: ### Minimal Skill
544: 
545: ```
546: skill-name/
547: └── SKILL.md
548: ```
549: 
550: Good for: Simple knowledge, no complex resources needed
551: 
552: ### Standard Skill (Recommended)
553: 
554: ```
555: skill-name/
556: ├── SKILL.md
557: ├── references/
558: │   └── detailed-guide.md
559: └── examples/
560:     └── working-example.sh
561: ```
562: 
563: Good for: Most plugin skills with detailed documentation
564: 
565: ### Complete Skill
566: 
567: ```
568: skill-name/
569: ├── SKILL.md
570: ├── references/
571: │   ├── patterns.md
572: │   └── advanced.md
573: ├── examples/
574: │   ├── example1.sh
575: │   └── example2.json
576: └── scripts/
577:     └── validate.sh
578: ```
579: 
580: Good for: Complex domains with validation utilities
581: 
582: ## Best Practices Summary
583: 
584: ✅ **DO:**
585: - Use third-person in description ("This skill should be used when...")
586: - Include specific trigger phrases ("create X", "configure Y")
587: - Keep SKILL.md lean (1,500-2,000 words)
588: - Use progressive disclosure (move details to references/)
589: - Write in imperative/infinitive form
590: - Reference supporting files clearly
591: - Provide working examples
592: - Create utility scripts for common operations
593: - Study plugin-dev's skills as templates
594: 
595: ❌ **DON'T:**
596: - Use second person anywhere
597: - Have vague trigger conditions
598: - Put everything in SKILL.md (>3,000 words without references/)
599: - Write in second person ("You should...")
600: - Leave resources unreferenced
601: - Include broken or incomplete examples
602: - Skip validation
603: 
604: ## Additional Resources
605: 
606: ### Study These Skills
607: 
608: Plugin-dev's skills demonstrate best practices:
609: - `../hook-development/` - Progressive disclosure, utilities
610: - `../agent-development/` - AI-assisted creation, references
611: - `../mcp-integration/` - Comprehensive references
612: - `../plugin-settings/` - Real-world examples
613: - `../command-development/` - Clear critical concepts
614: - `../plugin-structure/` - Good organization
615: 
616: ### Reference Files
617: 
618: For complete skill-creator methodology:
619: - **`references/skill-creator-original.md`** - Full original skill-creator content
620: 
621: ## Implementation Workflow
622: 
623: To create a skill for your plugin:
624: 
625: 1. **Understand use cases**: Identify concrete examples of skill usage
626: 2. **Plan resources**: Determine what scripts/references/examples needed
627: 3. **Create structure**: `mkdir -p skills/skill-name/{references,examples,scripts}`
628: 4. **Write SKILL.md**:
629:    - Frontmatter with third-person description and trigger phrases
630:    - Lean body (1,500-2,000 words) in imperative form
631:    - Reference supporting files
632: 5. **Add resources**: Create references/, examples/, scripts/ as needed
633: 6. **Validate**: Check description, writing style, organization
634: 7. **Test**: Verify skill loads on expected triggers
635: 8. **Iterate**: Improve based on usage
636: 
637: Focus on strong trigger descriptions, progressive disclosure, and imperative writing style for effective skills that load when needed and provide targeted guidance.
</file>

<file path="__LOCAL-REPO/__skills/development/subagent-driven-development/SKILL.md">
  1: ---
  2: name: subagent-driven-development
  3: description: Use when executing implementation plans with independent tasks in the current session
  4: ---
  5: 
  6: # Subagent-Driven Development
  7: 
  8: Execute plan by dispatching fresh subagent per task, with two-stage review after each: spec compliance review first, then code quality review.
  9: 
 10: **Core principle:** Fresh subagent per task + two-stage review (spec then quality) = high quality, fast iteration
 11: 
 12: ## When to Use
 13: 
 14: ```dot
 15: digraph when_to_use {
 16:     "Have implementation plan?" [shape=diamond];
 17:     "Tasks mostly independent?" [shape=diamond];
 18:     "Stay in this session?" [shape=diamond];
 19:     "subagent-driven-development" [shape=box];
 20:     "executing-plans" [shape=box];
 21:     "Manual execution or brainstorm first" [shape=box];
 22: 
 23:     "Have implementation plan?" -> "Tasks mostly independent?" [label="yes"];
 24:     "Have implementation plan?" -> "Manual execution or brainstorm first" [label="no"];
 25:     "Tasks mostly independent?" -> "Stay in this session?" [label="yes"];
 26:     "Tasks mostly independent?" -> "Manual execution or brainstorm first" [label="no - tightly coupled"];
 27:     "Stay in this session?" -> "subagent-driven-development" [label="yes"];
 28:     "Stay in this session?" -> "executing-plans" [label="no - parallel session"];
 29: }
 30: ```
 31: 
 32: **vs. Executing Plans (parallel session):**
 33: - Same session (no context switch)
 34: - Fresh subagent per task (no context pollution)
 35: - Two-stage review after each task: spec compliance first, then code quality
 36: - Faster iteration (no human-in-loop between tasks)
 37: 
 38: ## The Process
 39: 
 40: ```dot
 41: digraph process {
 42:     rankdir=TB;
 43: 
 44:     subgraph cluster_per_task {
 45:         label="Per Task";
 46:         "Dispatch implementer subagent (./implementer-prompt.md)" [shape=box];
 47:         "Implementer subagent asks questions?" [shape=diamond];
 48:         "Answer questions, provide context" [shape=box];
 49:         "Implementer subagent implements, tests, commits, self-reviews" [shape=box];
 50:         "Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)" [shape=box];
 51:         "Spec reviewer subagent confirms code matches spec?" [shape=diamond];
 52:         "Implementer subagent fixes spec gaps" [shape=box];
 53:         "Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)" [shape=box];
 54:         "Code quality reviewer subagent approves?" [shape=diamond];
 55:         "Implementer subagent fixes quality issues" [shape=box];
 56:         "Mark task complete in TodoWrite" [shape=box];
 57:     }
 58: 
 59:     "Read plan, extract all tasks with full text, note context, create TodoWrite" [shape=box];
 60:     "More tasks remain?" [shape=diamond];
 61:     "Dispatch final code reviewer subagent for entire implementation" [shape=box];
 62:     "Use superpowers:finishing-a-development-branch" [shape=box style=filled fillcolor=lightgreen];
 63: 
 64:     "Read plan, extract all tasks with full text, note context, create TodoWrite" -> "Dispatch implementer subagent (./implementer-prompt.md)";
 65:     "Dispatch implementer subagent (./implementer-prompt.md)" -> "Implementer subagent asks questions?";
 66:     "Implementer subagent asks questions?" -> "Answer questions, provide context" [label="yes"];
 67:     "Answer questions, provide context" -> "Dispatch implementer subagent (./implementer-prompt.md)";
 68:     "Implementer subagent asks questions?" -> "Implementer subagent implements, tests, commits, self-reviews" [label="no"];
 69:     "Implementer subagent implements, tests, commits, self-reviews" -> "Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)";
 70:     "Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)" -> "Spec reviewer subagent confirms code matches spec?";
 71:     "Spec reviewer subagent confirms code matches spec?" -> "Implementer subagent fixes spec gaps" [label="no"];
 72:     "Implementer subagent fixes spec gaps" -> "Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)" [label="re-review"];
 73:     "Spec reviewer subagent confirms code matches spec?" -> "Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)" [label="yes"];
 74:     "Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)" -> "Code quality reviewer subagent approves?";
 75:     "Code quality reviewer subagent approves?" -> "Implementer subagent fixes quality issues" [label="no"];
 76:     "Implementer subagent fixes quality issues" -> "Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)" [label="re-review"];
 77:     "Code quality reviewer subagent approves?" -> "Mark task complete in TodoWrite" [label="yes"];
 78:     "Mark task complete in TodoWrite" -> "More tasks remain?";
 79:     "More tasks remain?" -> "Dispatch implementer subagent (./implementer-prompt.md)" [label="yes"];
 80:     "More tasks remain?" -> "Dispatch final code reviewer subagent for entire implementation" [label="no"];
 81:     "Dispatch final code reviewer subagent for entire implementation" -> "Use superpowers:finishing-a-development-branch";
 82: }
 83: ```
 84: 
 85: ## Prompt Templates
 86: 
 87: - `./implementer-prompt.md` - Dispatch implementer subagent
 88: - `./spec-reviewer-prompt.md` - Dispatch spec compliance reviewer subagent
 89: - `./code-quality-reviewer-prompt.md` - Dispatch code quality reviewer subagent
 90: 
 91: ## Example Workflow
 92: 
 93: ```
 94: You: I'm using Subagent-Driven Development to execute this plan.
 95: 
 96: [Read plan file once: docs/plans/feature-plan.md]
 97: [Extract all 5 tasks with full text and context]
 98: [Create TodoWrite with all tasks]
 99: 
100: Task 1: Hook installation script
101: 
102: [Get Task 1 text and context (already extracted)]
103: [Dispatch implementation subagent with full task text + context]
104: 
105: Implementer: "Before I begin - should the hook be installed at user or system level?"
106: 
107: You: "User level (~/.config/superpowers/hooks/)"
108: 
109: Implementer: "Got it. Implementing now..."
110: [Later] Implementer:
111:   - Implemented install-hook command
112:   - Added tests, 5/5 passing
113:   - Self-review: Found I missed --force flag, added it
114:   - Committed
115: 
116: [Dispatch spec compliance reviewer]
117: Spec reviewer: ✅ Spec compliant - all requirements met, nothing extra
118: 
119: [Get git SHAs, dispatch code quality reviewer]
120: Code reviewer: Strengths: Good test coverage, clean. Issues: None. Approved.
121: 
122: [Mark Task 1 complete]
123: 
124: Task 2: Recovery modes
125: 
126: [Get Task 2 text and context (already extracted)]
127: [Dispatch implementation subagent with full task text + context]
128: 
129: Implementer: [No questions, proceeds]
130: Implementer:
131:   - Added verify/repair modes
132:   - 8/8 tests passing
133:   - Self-review: All good
134:   - Committed
135: 
136: [Dispatch spec compliance reviewer]
137: Spec reviewer: ❌ Issues:
138:   - Missing: Progress reporting (spec says "report every 100 items")
139:   - Extra: Added --json flag (not requested)
140: 
141: [Implementer fixes issues]
142: Implementer: Removed --json flag, added progress reporting
143: 
144: [Spec reviewer reviews again]
145: Spec reviewer: ✅ Spec compliant now
146: 
147: [Dispatch code quality reviewer]
148: Code reviewer: Strengths: Solid. Issues (Important): Magic number (100)
149: 
150: [Implementer fixes]
151: Implementer: Extracted PROGRESS_INTERVAL constant
152: 
153: [Code reviewer reviews again]
154: Code reviewer: ✅ Approved
155: 
156: [Mark Task 2 complete]
157: 
158: ...
159: 
160: [After all tasks]
161: [Dispatch final code-reviewer]
162: Final reviewer: All requirements met, ready to merge
163: 
164: Done!
165: ```
166: 
167: ## Advantages
168: 
169: **vs. Manual execution:**
170: - Subagents follow TDD naturally
171: - Fresh context per task (no confusion)
172: - Parallel-safe (subagents don't interfere)
173: - Subagent can ask questions (before AND during work)
174: 
175: **vs. Executing Plans:**
176: - Same session (no handoff)
177: - Continuous progress (no waiting)
178: - Review checkpoints automatic
179: 
180: **Efficiency gains:**
181: - No file reading overhead (controller provides full text)
182: - Controller curates exactly what context is needed
183: - Subagent gets complete information upfront
184: - Questions surfaced before work begins (not after)
185: 
186: **Quality gates:**
187: - Self-review catches issues before handoff
188: - Two-stage review: spec compliance, then code quality
189: - Review loops ensure fixes actually work
190: - Spec compliance prevents over/under-building
191: - Code quality ensures implementation is well-built
192: 
193: **Cost:**
194: - More subagent invocations (implementer + 2 reviewers per task)
195: - Controller does more prep work (extracting all tasks upfront)
196: - Review loops add iterations
197: - But catches issues early (cheaper than debugging later)
198: 
199: ## Red Flags
200: 
201: **Never:**
202: - Skip reviews (spec compliance OR code quality)
203: - Proceed with unfixed issues
204: - Dispatch multiple implementation subagents in parallel (conflicts)
205: - Make subagent read plan file (provide full text instead)
206: - Skip scene-setting context (subagent needs to understand where task fits)
207: - Ignore subagent questions (answer before letting them proceed)
208: - Accept "close enough" on spec compliance (spec reviewer found issues = not done)
209: - Skip review loops (reviewer found issues = implementer fixes = review again)
210: - Let implementer self-review replace actual review (both are needed)
211: - **Start code quality review before spec compliance is ✅** (wrong order)
212: - Move to next task while either review has open issues
213: 
214: **If subagent asks questions:**
215: - Answer clearly and completely
216: - Provide additional context if needed
217: - Don't rush them into implementation
218: 
219: **If reviewer finds issues:**
220: - Implementer (same subagent) fixes them
221: - Reviewer reviews again
222: - Repeat until approved
223: - Don't skip the re-review
224: 
225: **If subagent fails task:**
226: - Dispatch fix subagent with specific instructions
227: - Don't try to fix manually (context pollution)
228: 
229: ## Integration
230: 
231: **Required workflow skills:**
232: - **superpowers:writing-plans** - Creates the plan this skill executes
233: - **superpowers:requesting-code-review** - Code review template for reviewer subagents
234: - **superpowers:finishing-a-development-branch** - Complete development after all tasks
235: 
236: **Subagents should use:**
237: - **superpowers:test-driven-development** - Subagents follow TDD for each task
238: 
239: **Alternative workflow:**
240: - **superpowers:executing-plans** - Use for parallel session instead of same-session execution
</file>

<file path="__LOCAL-REPO/__skills/development/systematic-debugging/condition-based-waiting.md">
  1: # Condition-Based Waiting
  2: 
  3: ## Overview
  4: 
  5: Flaky tests often guess at timing with arbitrary delays. This creates race conditions where tests pass on fast machines but fail under load or in CI.
  6: 
  7: **Core principle:** Wait for the actual condition you care about, not a guess about how long it takes.
  8: 
  9: ## When to Use
 10: 
 11: ```dot
 12: digraph when_to_use {
 13:     "Test uses setTimeout/sleep?" [shape=diamond];
 14:     "Testing timing behavior?" [shape=diamond];
 15:     "Document WHY timeout needed" [shape=box];
 16:     "Use condition-based waiting" [shape=box];
 17: 
 18:     "Test uses setTimeout/sleep?" -> "Testing timing behavior?" [label="yes"];
 19:     "Testing timing behavior?" -> "Document WHY timeout needed" [label="yes"];
 20:     "Testing timing behavior?" -> "Use condition-based waiting" [label="no"];
 21: }
 22: ```
 23: 
 24: **Use when:**
 25: - Tests have arbitrary delays (`setTimeout`, `sleep`, `time.sleep()`)
 26: - Tests are flaky (pass sometimes, fail under load)
 27: - Tests timeout when run in parallel
 28: - Waiting for async operations to complete
 29: 
 30: **Don't use when:**
 31: - Testing actual timing behavior (debounce, throttle intervals)
 32: - Always document WHY if using arbitrary timeout
 33: 
 34: ## Core Pattern
 35: 
 36: ```typescript
 37: // ❌ BEFORE: Guessing at timing
 38: await new Promise(r => setTimeout(r, 50));
 39: const result = getResult();
 40: expect(result).toBeDefined();
 41: 
 42: // ✅ AFTER: Waiting for condition
 43: await waitFor(() => getResult() !== undefined);
 44: const result = getResult();
 45: expect(result).toBeDefined();
 46: ```
 47: 
 48: ## Quick Patterns
 49: 
 50: | Scenario | Pattern |
 51: |----------|---------|
 52: | Wait for event | `waitFor(() => events.find(e => e.type === 'DONE'))` |
 53: | Wait for state | `waitFor(() => machine.state === 'ready')` |
 54: | Wait for count | `waitFor(() => items.length >= 5)` |
 55: | Wait for file | `waitFor(() => fs.existsSync(path))` |
 56: | Complex condition | `waitFor(() => obj.ready && obj.value > 10)` |
 57: 
 58: ## Implementation
 59: 
 60: Generic polling function:
 61: ```typescript
 62: async function waitFor<T>(
 63:   condition: () => T | undefined | null | false,
 64:   description: string,
 65:   timeoutMs = 5000
 66: ): Promise<T> {
 67:   const startTime = Date.now();
 68: 
 69:   while (true) {
 70:     const result = condition();
 71:     if (result) return result;
 72: 
 73:     if (Date.now() - startTime > timeoutMs) {
 74:       throw new Error(`Timeout waiting for ${description} after ${timeoutMs}ms`);
 75:     }
 76: 
 77:     await new Promise(r => setTimeout(r, 10)); // Poll every 10ms
 78:   }
 79: }
 80: ```
 81: 
 82: See `condition-based-waiting-example.ts` in this directory for complete implementation with domain-specific helpers (`waitForEvent`, `waitForEventCount`, `waitForEventMatch`) from actual debugging session.
 83: 
 84: ## Common Mistakes
 85: 
 86: **❌ Polling too fast:** `setTimeout(check, 1)` - wastes CPU
 87: **✅ Fix:** Poll every 10ms
 88: 
 89: **❌ No timeout:** Loop forever if condition never met
 90: **✅ Fix:** Always include timeout with clear error
 91: 
 92: **❌ Stale data:** Cache state before loop
 93: **✅ Fix:** Call getter inside loop for fresh data
 94: 
 95: ## When Arbitrary Timeout IS Correct
 96: 
 97: ```typescript
 98: // Tool ticks every 100ms - need 2 ticks to verify partial output
 99: await waitForEvent(manager, 'TOOL_STARTED'); // First: wait for condition
100: await new Promise(r => setTimeout(r, 200));   // Then: wait for timed behavior
101: // 200ms = 2 ticks at 100ms intervals - documented and justified
102: ```
103: 
104: **Requirements:**
105: 1. First wait for triggering condition
106: 2. Based on known timing (not guessing)
107: 3. Comment explaining WHY
108: 
109: ## Real-World Impact
110: 
111: From debugging session (2025-10-03):
112: - Fixed 15 flaky tests across 3 files
113: - Pass rate: 60% → 100%
114: - Execution time: 40% faster
115: - No more race conditions
</file>

<file path="__LOCAL-REPO/__skills/development/systematic-debugging/defense-in-depth.md">
  1: # Defense-in-Depth Validation
  2: 
  3: ## Overview
  4: 
  5: When you fix a bug caused by invalid data, adding validation at one place feels sufficient. But that single check can be bypassed by different code paths, refactoring, or mocks.
  6: 
  7: **Core principle:** Validate at EVERY layer data passes through. Make the bug structurally impossible.
  8: 
  9: ## Why Multiple Layers
 10: 
 11: Single validation: "We fixed the bug"
 12: Multiple layers: "We made the bug impossible"
 13: 
 14: Different layers catch different cases:
 15: - Entry validation catches most bugs
 16: - Business logic catches edge cases
 17: - Environment guards prevent context-specific dangers
 18: - Debug logging helps when other layers fail
 19: 
 20: ## The Four Layers
 21: 
 22: ### Layer 1: Entry Point Validation
 23: **Purpose:** Reject obviously invalid input at API boundary
 24: 
 25: ```typescript
 26: function createProject(name: string, workingDirectory: string) {
 27:   if (!workingDirectory || workingDirectory.trim() === '') {
 28:     throw new Error('workingDirectory cannot be empty');
 29:   }
 30:   if (!existsSync(workingDirectory)) {
 31:     throw new Error(`workingDirectory does not exist: ${workingDirectory}`);
 32:   }
 33:   if (!statSync(workingDirectory).isDirectory()) {
 34:     throw new Error(`workingDirectory is not a directory: ${workingDirectory}`);
 35:   }
 36:   // ... proceed
 37: }
 38: ```
 39: 
 40: ### Layer 2: Business Logic Validation
 41: **Purpose:** Ensure data makes sense for this operation
 42: 
 43: ```typescript
 44: function initializeWorkspace(projectDir: string, sessionId: string) {
 45:   if (!projectDir) {
 46:     throw new Error('projectDir required for workspace initialization');
 47:   }
 48:   // ... proceed
 49: }
 50: ```
 51: 
 52: ### Layer 3: Environment Guards
 53: **Purpose:** Prevent dangerous operations in specific contexts
 54: 
 55: ```typescript
 56: async function gitInit(directory: string) {
 57:   // In tests, refuse git init outside temp directories
 58:   if (process.env.NODE_ENV === 'test') {
 59:     const normalized = normalize(resolve(directory));
 60:     const tmpDir = normalize(resolve(tmpdir()));
 61: 
 62:     if (!normalized.startsWith(tmpDir)) {
 63:       throw new Error(
 64:         `Refusing git init outside temp dir during tests: ${directory}`
 65:       );
 66:     }
 67:   }
 68:   // ... proceed
 69: }
 70: ```
 71: 
 72: ### Layer 4: Debug Instrumentation
 73: **Purpose:** Capture context for forensics
 74: 
 75: ```typescript
 76: async function gitInit(directory: string) {
 77:   const stack = new Error().stack;
 78:   logger.debug('About to git init', {
 79:     directory,
 80:     cwd: process.cwd(),
 81:     stack,
 82:   });
 83:   // ... proceed
 84: }
 85: ```
 86: 
 87: ## Applying the Pattern
 88: 
 89: When you find a bug:
 90: 
 91: 1. **Trace the data flow** - Where does bad value originate? Where used?
 92: 2. **Map all checkpoints** - List every point data passes through
 93: 3. **Add validation at each layer** - Entry, business, environment, debug
 94: 4. **Test each layer** - Try to bypass layer 1, verify layer 2 catches it
 95: 
 96: ## Example from Session
 97: 
 98: Bug: Empty `projectDir` caused `git init` in source code
 99: 
100: **Data flow:**
101: 1. Test setup → empty string
102: 2. `Project.create(name, '')`
103: 3. `WorkspaceManager.createWorkspace('')`
104: 4. `git init` runs in `process.cwd()`
105: 
106: **Four layers added:**
107: - Layer 1: `Project.create()` validates not empty/exists/writable
108: - Layer 2: `WorkspaceManager` validates projectDir not empty
109: - Layer 3: `WorktreeManager` refuses git init outside tmpdir in tests
110: - Layer 4: Stack trace logging before git init
111: 
112: **Result:** All 1847 tests passed, bug impossible to reproduce
113: 
114: ## Key Insight
115: 
116: All four layers were necessary. During testing, each layer caught bugs the others missed:
117: - Different code paths bypassed entry validation
118: - Mocks bypassed business logic checks
119: - Edge cases on different platforms needed environment guards
120: - Debug logging identified structural misuse
121: 
122: **Don't stop at one validation point.** Add checks at every layer.
</file>

<file path="__LOCAL-REPO/__skills/development/systematic-debugging/root-cause-tracing.md">
  1: # Root Cause Tracing
  2: 
  3: ## Overview
  4: 
  5: Bugs often manifest deep in the call stack (git init in wrong directory, file created in wrong location, database opened with wrong path). Your instinct is to fix where the error appears, but that's treating a symptom.
  6: 
  7: **Core principle:** Trace backward through the call chain until you find the original trigger, then fix at the source.
  8: 
  9: ## When to Use
 10: 
 11: ```dot
 12: digraph when_to_use {
 13:     "Bug appears deep in stack?" [shape=diamond];
 14:     "Can trace backwards?" [shape=diamond];
 15:     "Fix at symptom point" [shape=box];
 16:     "Trace to original trigger" [shape=box];
 17:     "BETTER: Also add defense-in-depth" [shape=box];
 18: 
 19:     "Bug appears deep in stack?" -> "Can trace backwards?" [label="yes"];
 20:     "Can trace backwards?" -> "Trace to original trigger" [label="yes"];
 21:     "Can trace backwards?" -> "Fix at symptom point" [label="no - dead end"];
 22:     "Trace to original trigger" -> "BETTER: Also add defense-in-depth";
 23: }
 24: ```
 25: 
 26: **Use when:**
 27: - Error happens deep in execution (not at entry point)
 28: - Stack trace shows long call chain
 29: - Unclear where invalid data originated
 30: - Need to find which test/code triggers the problem
 31: 
 32: ## The Tracing Process
 33: 
 34: ### 1. Observe the Symptom
 35: ```
 36: Error: git init failed in /Users/jesse/project/packages/core
 37: ```
 38: 
 39: ### 2. Find Immediate Cause
 40: **What code directly causes this?**
 41: ```typescript
 42: await execFileAsync('git', ['init'], { cwd: projectDir });
 43: ```
 44: 
 45: ### 3. Ask: What Called This?
 46: ```typescript
 47: WorktreeManager.createSessionWorktree(projectDir, sessionId)
 48:   → called by Session.initializeWorkspace()
 49:   → called by Session.create()
 50:   → called by test at Project.create()
 51: ```
 52: 
 53: ### 4. Keep Tracing Up
 54: **What value was passed?**
 55: - `projectDir = ''` (empty string!)
 56: - Empty string as `cwd` resolves to `process.cwd()`
 57: - That's the source code directory!
 58: 
 59: ### 5. Find Original Trigger
 60: **Where did empty string come from?**
 61: ```typescript
 62: const context = setupCoreTest(); // Returns { tempDir: '' }
 63: Project.create('name', context.tempDir); // Accessed before beforeEach!
 64: ```
 65: 
 66: ## Adding Stack Traces
 67: 
 68: When you can't trace manually, add instrumentation:
 69: 
 70: ```typescript
 71: // Before the problematic operation
 72: async function gitInit(directory: string) {
 73:   const stack = new Error().stack;
 74:   console.error('DEBUG git init:', {
 75:     directory,
 76:     cwd: process.cwd(),
 77:     nodeEnv: process.env.NODE_ENV,
 78:     stack,
 79:   });
 80: 
 81:   await execFileAsync('git', ['init'], { cwd: directory });
 82: }
 83: ```
 84: 
 85: **Critical:** Use `console.error()` in tests (not logger - may not show)
 86: 
 87: **Run and capture:**
 88: ```bash
 89: npm test 2>&1 | grep 'DEBUG git init'
 90: ```
 91: 
 92: **Analyze stack traces:**
 93: - Look for test file names
 94: - Find the line number triggering the call
 95: - Identify the pattern (same test? same parameter?)
 96: 
 97: ## Finding Which Test Causes Pollution
 98: 
 99: If something appears during tests but you don't know which test:
100: 
101: Use the bisection script `find-polluter.sh` in this directory:
102: 
103: ```bash
104: ./find-polluter.sh '.git' 'src/**/*.test.ts'
105: ```
106: 
107: Runs tests one-by-one, stops at first polluter. See script for usage.
108: 
109: ## Real Example: Empty projectDir
110: 
111: **Symptom:** `.git` created in `packages/core/` (source code)
112: 
113: **Trace chain:**
114: 1. `git init` runs in `process.cwd()` ← empty cwd parameter
115: 2. WorktreeManager called with empty projectDir
116: 3. Session.create() passed empty string
117: 4. Test accessed `context.tempDir` before beforeEach
118: 5. setupCoreTest() returns `{ tempDir: '' }` initially
119: 
120: **Root cause:** Top-level variable initialization accessing empty value
121: 
122: **Fix:** Made tempDir a getter that throws if accessed before beforeEach
123: 
124: **Also added defense-in-depth:**
125: - Layer 1: Project.create() validates directory
126: - Layer 2: WorkspaceManager validates not empty
127: - Layer 3: NODE_ENV guard refuses git init outside tmpdir
128: - Layer 4: Stack trace logging before git init
129: 
130: ## Key Principle
131: 
132: ```dot
133: digraph principle {
134:     "Found immediate cause" [shape=ellipse];
135:     "Can trace one level up?" [shape=diamond];
136:     "Trace backwards" [shape=box];
137:     "Is this the source?" [shape=diamond];
138:     "Fix at source" [shape=box];
139:     "Add validation at each layer" [shape=box];
140:     "Bug impossible" [shape=doublecircle];
141:     "NEVER fix just the symptom" [shape=octagon, style=filled, fillcolor=red, fontcolor=white];
142: 
143:     "Found immediate cause" -> "Can trace one level up?";
144:     "Can trace one level up?" -> "Trace backwards" [label="yes"];
145:     "Can trace one level up?" -> "NEVER fix just the symptom" [label="no"];
146:     "Trace backwards" -> "Is this the source?";
147:     "Is this the source?" -> "Trace backwards" [label="no - keeps going"];
148:     "Is this the source?" -> "Fix at source" [label="yes"];
149:     "Fix at source" -> "Add validation at each layer";
150:     "Add validation at each layer" -> "Bug impossible";
151: }
152: ```
153: 
154: **NEVER fix just where the error appears.** Trace back to find the original trigger.
155: 
156: ## Stack Trace Tips
157: 
158: **In tests:** Use `console.error()` not logger - logger may be suppressed
159: **Before operation:** Log before the dangerous operation, not after it fails
160: **Include context:** Directory, cwd, environment variables, timestamps
161: **Capture stack:** `new Error().stack` shows complete call chain
162: 
163: ## Real-World Impact
164: 
165: From debugging session (2025-10-03):
166: - Found root cause through 5-level trace
167: - Fixed at source (getter validation)
168: - Added 4 layers of defense
169: - 1847 tests passed, zero pollution
</file>

<file path="__LOCAL-REPO/__skills/development/systematic-debugging/SKILL.md">
  1: ---
  2: name: systematic-debugging
  3: description: Use when encountering any bug, test failure, or unexpected behavior, before proposing fixes
  4: ---
  5: 
  6: # Systematic Debugging
  7: 
  8: ## Overview
  9: 
 10: Random fixes waste time and create new bugs. Quick patches mask underlying issues.
 11: 
 12: **Core principle:** ALWAYS find root cause before attempting fixes. Symptom fixes are failure.
 13: 
 14: **Violating the letter of this process is violating the spirit of debugging.**
 15: 
 16: ## The Iron Law
 17: 
 18: ```
 19: NO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST
 20: ```
 21: 
 22: If you haven't completed Phase 1, you cannot propose fixes.
 23: 
 24: ## When to Use
 25: 
 26: Use for ANY technical issue:
 27: - Test failures
 28: - Bugs in production
 29: - Unexpected behavior
 30: - Performance problems
 31: - Build failures
 32: - Integration issues
 33: 
 34: **Use this ESPECIALLY when:**
 35: - Under time pressure (emergencies make guessing tempting)
 36: - "Just one quick fix" seems obvious
 37: - You've already tried multiple fixes
 38: - Previous fix didn't work
 39: - You don't fully understand the issue
 40: 
 41: **Don't skip when:**
 42: - Issue seems simple (simple bugs have root causes too)
 43: - You're in a hurry (rushing guarantees rework)
 44: - Manager wants it fixed NOW (systematic is faster than thrashing)
 45: 
 46: ## The Four Phases
 47: 
 48: You MUST complete each phase before proceeding to the next.
 49: 
 50: ### Phase 1: Root Cause Investigation
 51: 
 52: **BEFORE attempting ANY fix:**
 53: 
 54: 1. **Read Error Messages Carefully**
 55:    - Don't skip past errors or warnings
 56:    - They often contain the exact solution
 57:    - Read stack traces completely
 58:    - Note line numbers, file paths, error codes
 59: 
 60: 2. **Reproduce Consistently**
 61:    - Can you trigger it reliably?
 62:    - What are the exact steps?
 63:    - Does it happen every time?
 64:    - If not reproducible → gather more data, don't guess
 65: 
 66: 3. **Check Recent Changes**
 67:    - What changed that could cause this?
 68:    - Git diff, recent commits
 69:    - New dependencies, config changes
 70:    - Environmental differences
 71: 
 72: 4. **Gather Evidence in Multi-Component Systems**
 73: 
 74:    **WHEN system has multiple components (CI → build → signing, API → service → database):**
 75: 
 76:    **BEFORE proposing fixes, add diagnostic instrumentation:**
 77:    ```
 78:    For EACH component boundary:
 79:      - Log what data enters component
 80:      - Log what data exits component
 81:      - Verify environment/config propagation
 82:      - Check state at each layer
 83: 
 84:    Run once to gather evidence showing WHERE it breaks
 85:    THEN analyze evidence to identify failing component
 86:    THEN investigate that specific component
 87:    ```
 88: 
 89:    **Example (multi-layer system):**
 90:    ```bash
 91:    # Layer 1: Workflow
 92:    echo "=== Secrets available in workflow: ==="
 93:    echo "IDENTITY: ${IDENTITY:+SET}${IDENTITY:-UNSET}"
 94: 
 95:    # Layer 2: Build script
 96:    echo "=== Env vars in build script: ==="
 97:    env | grep IDENTITY || echo "IDENTITY not in environment"
 98: 
 99:    # Layer 3: Signing script
100:    echo "=== Keychain state: ==="
101:    security list-keychains
102:    security find-identity -v
103: 
104:    # Layer 4: Actual signing
105:    codesign --sign "$IDENTITY" --verbose=4 "$APP"
106:    ```
107: 
108:    **This reveals:** Which layer fails (secrets → workflow ✓, workflow → build ✗)
109: 
110: 5. **Trace Data Flow**
111: 
112:    **WHEN error is deep in call stack:**
113: 
114:    See `root-cause-tracing.md` in this directory for the complete backward tracing technique.
115: 
116:    **Quick version:**
117:    - Where does bad value originate?
118:    - What called this with bad value?
119:    - Keep tracing up until you find the source
120:    - Fix at source, not at symptom
121: 
122: ### Phase 2: Pattern Analysis
123: 
124: **Find the pattern before fixing:**
125: 
126: 1. **Find Working Examples**
127:    - Locate similar working code in same codebase
128:    - What works that's similar to what's broken?
129: 
130: 2. **Compare Against References**
131:    - If implementing pattern, read reference implementation COMPLETELY
132:    - Don't skim - read every line
133:    - Understand the pattern fully before applying
134: 
135: 3. **Identify Differences**
136:    - What's different between working and broken?
137:    - List every difference, however small
138:    - Don't assume "that can't matter"
139: 
140: 4. **Understand Dependencies**
141:    - What other components does this need?
142:    - What settings, config, environment?
143:    - What assumptions does it make?
144: 
145: ### Phase 3: Hypothesis and Testing
146: 
147: **Scientific method:**
148: 
149: 1. **Form Single Hypothesis**
150:    - State clearly: "I think X is the root cause because Y"
151:    - Write it down
152:    - Be specific, not vague
153: 
154: 2. **Test Minimally**
155:    - Make the SMALLEST possible change to test hypothesis
156:    - One variable at a time
157:    - Don't fix multiple things at once
158: 
159: 3. **Verify Before Continuing**
160:    - Did it work? Yes → Phase 4
161:    - Didn't work? Form NEW hypothesis
162:    - DON'T add more fixes on top
163: 
164: 4. **When You Don't Know**
165:    - Say "I don't understand X"
166:    - Don't pretend to know
167:    - Ask for help
168:    - Research more
169: 
170: ### Phase 4: Implementation
171: 
172: **Fix the root cause, not the symptom:**
173: 
174: 1. **Create Failing Test Case**
175:    - Simplest possible reproduction
176:    - Automated test if possible
177:    - One-off test script if no framework
178:    - MUST have before fixing
179:    - Use the `superpowers:test-driven-development` skill for writing proper failing tests
180: 
181: 2. **Implement Single Fix**
182:    - Address the root cause identified
183:    - ONE change at a time
184:    - No "while I'm here" improvements
185:    - No bundled refactoring
186: 
187: 3. **Verify Fix**
188:    - Test passes now?
189:    - No other tests broken?
190:    - Issue actually resolved?
191: 
192: 4. **If Fix Doesn't Work**
193:    - STOP
194:    - Count: How many fixes have you tried?
195:    - If < 3: Return to Phase 1, re-analyze with new information
196:    - **If ≥ 3: STOP and question the architecture (step 5 below)**
197:    - DON'T attempt Fix #4 without architectural discussion
198: 
199: 5. **If 3+ Fixes Failed: Question Architecture**
200: 
201:    **Pattern indicating architectural problem:**
202:    - Each fix reveals new shared state/coupling/problem in different place
203:    - Fixes require "massive refactoring" to implement
204:    - Each fix creates new symptoms elsewhere
205: 
206:    **STOP and question fundamentals:**
207:    - Is this pattern fundamentally sound?
208:    - Are we "sticking with it through sheer inertia"?
209:    - Should we refactor architecture vs. continue fixing symptoms?
210: 
211:    **Discuss with your human partner before attempting more fixes**
212: 
213:    This is NOT a failed hypothesis - this is a wrong architecture.
214: 
215: ## Red Flags - STOP and Follow Process
216: 
217: If you catch yourself thinking:
218: - "Quick fix for now, investigate later"
219: - "Just try changing X and see if it works"
220: - "Add multiple changes, run tests"
221: - "Skip the test, I'll manually verify"
222: - "It's probably X, let me fix that"
223: - "I don't fully understand but this might work"
224: - "Pattern says X but I'll adapt it differently"
225: - "Here are the main problems: [lists fixes without investigation]"
226: - Proposing solutions before tracing data flow
227: - **"One more fix attempt" (when already tried 2+)**
228: - **Each fix reveals new problem in different place**
229: 
230: **ALL of these mean: STOP. Return to Phase 1.**
231: 
232: **If 3+ fixes failed:** Question the architecture (see Phase 4.5)
233: 
234: ## your human partner's Signals You're Doing It Wrong
235: 
236: **Watch for these redirections:**
237: - "Is that not happening?" - You assumed without verifying
238: - "Will it show us...?" - You should have added evidence gathering
239: - "Stop guessing" - You're proposing fixes without understanding
240: - "Ultrathink this" - Question fundamentals, not just symptoms
241: - "We're stuck?" (frustrated) - Your approach isn't working
242: 
243: **When you see these:** STOP. Return to Phase 1.
244: 
245: ## Common Rationalizations
246: 
247: | Excuse | Reality |
248: |--------|---------|
249: | "Issue is simple, don't need process" | Simple issues have root causes too. Process is fast for simple bugs. |
250: | "Emergency, no time for process" | Systematic debugging is FASTER than guess-and-check thrashing. |
251: | "Just try this first, then investigate" | First fix sets the pattern. Do it right from the start. |
252: | "I'll write test after confirming fix works" | Untested fixes don't stick. Test first proves it. |
253: | "Multiple fixes at once saves time" | Can't isolate what worked. Causes new bugs. |
254: | "Reference too long, I'll adapt the pattern" | Partial understanding guarantees bugs. Read it completely. |
255: | "I see the problem, let me fix it" | Seeing symptoms ≠ understanding root cause. |
256: | "One more fix attempt" (after 2+ failures) | 3+ failures = architectural problem. Question pattern, don't fix again. |
257: 
258: ## Quick Reference
259: 
260: | Phase | Key Activities | Success Criteria |
261: |-------|---------------|------------------|
262: | **1. Root Cause** | Read errors, reproduce, check changes, gather evidence | Understand WHAT and WHY |
263: | **2. Pattern** | Find working examples, compare | Identify differences |
264: | **3. Hypothesis** | Form theory, test minimally | Confirmed or new hypothesis |
265: | **4. Implementation** | Create test, fix, verify | Bug resolved, tests pass |
266: 
267: ## When Process Reveals "No Root Cause"
268: 
269: If systematic investigation reveals issue is truly environmental, timing-dependent, or external:
270: 
271: 1. You've completed the process
272: 2. Document what you investigated
273: 3. Implement appropriate handling (retry, timeout, error message)
274: 4. Add monitoring/logging for future investigation
275: 
276: **But:** 95% of "no root cause" cases are incomplete investigation.
277: 
278: ## Supporting Techniques
279: 
280: These techniques are part of systematic debugging and available in this directory:
281: 
282: - **`root-cause-tracing.md`** - Trace bugs backward through call stack to find original trigger
283: - **`defense-in-depth.md`** - Add validation at multiple layers after finding root cause
284: - **`condition-based-waiting.md`** - Replace arbitrary timeouts with condition polling
285: 
286: **Related skills:**
287: - **superpowers:test-driven-development** - For creating failing test case (Phase 4, Step 1)
288: - **superpowers:verification-before-completion** - Verify fix worked before claiming success
289: 
290: ## Real-World Impact
291: 
292: From debugging sessions:
293: - Systematic approach: 15-30 minutes to fix
294: - Random fixes approach: 2-3 hours of thrashing
295: - First-time fix rate: 95% vs 40%
296: - New bugs introduced: Near zero vs common
</file>

<file path="__LOCAL-REPO/__skills/development/test-driven-development/SKILL.md">
  1: ---
  2: name: test-driven-development
  3: description: Use when implementing any feature or bugfix, before writing implementation code
  4: ---
  5: 
  6: # Test-Driven Development (TDD)
  7: 
  8: ## Overview
  9: 
 10: Write the test first. Watch it fail. Write minimal code to pass.
 11: 
 12: **Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.
 13: 
 14: **Violating the letter of the rules is violating the spirit of the rules.**
 15: 
 16: ## When to Use
 17: 
 18: **Always:**
 19: - New features
 20: - Bug fixes
 21: - Refactoring
 22: - Behavior changes
 23: 
 24: **Exceptions (ask your human partner):**
 25: - Throwaway prototypes
 26: - Generated code
 27: - Configuration files
 28: 
 29: Thinking "skip TDD just this once"? Stop. That's rationalization.
 30: 
 31: ## The Iron Law
 32: 
 33: ```
 34: NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
 35: ```
 36: 
 37: Write code before the test? Delete it. Start over.
 38: 
 39: **No exceptions:**
 40: - Don't keep it as "reference"
 41: - Don't "adapt" it while writing tests
 42: - Don't look at it
 43: - Delete means delete
 44: 
 45: Implement fresh from tests. Period.
 46: 
 47: ## Red-Green-Refactor
 48: 
 49: ```dot
 50: digraph tdd_cycle {
 51:     rankdir=LR;
 52:     red [label="RED\nWrite failing test", shape=box, style=filled, fillcolor="#ffcccc"];
 53:     verify_red [label="Verify fails\ncorrectly", shape=diamond];
 54:     green [label="GREEN\nMinimal code", shape=box, style=filled, fillcolor="#ccffcc"];
 55:     verify_green [label="Verify passes\nAll green", shape=diamond];
 56:     refactor [label="REFACTOR\nClean up", shape=box, style=filled, fillcolor="#ccccff"];
 57:     next [label="Next", shape=ellipse];
 58: 
 59:     red -> verify_red;
 60:     verify_red -> green [label="yes"];
 61:     verify_red -> red [label="wrong\nfailure"];
 62:     green -> verify_green;
 63:     verify_green -> refactor [label="yes"];
 64:     verify_green -> green [label="no"];
 65:     refactor -> verify_green [label="stay\ngreen"];
 66:     verify_green -> next;
 67:     next -> red;
 68: }
 69: ```
 70: 
 71: ### RED - Write Failing Test
 72: 
 73: Write one minimal test showing what should happen.
 74: 
 75: <Good>
 76: ```typescript
 77: test('retries failed operations 3 times', async () => {
 78:   let attempts = 0;
 79:   const operation = () => {
 80:     attempts++;
 81:     if (attempts < 3) throw new Error('fail');
 82:     return 'success';
 83:   };
 84: 
 85:   const result = await retryOperation(operation);
 86: 
 87:   expect(result).toBe('success');
 88:   expect(attempts).toBe(3);
 89: });
 90: ```
 91: Clear name, tests real behavior, one thing
 92: </Good>
 93: 
 94: <Bad>
 95: ```typescript
 96: test('retry works', async () => {
 97:   const mock = jest.fn()
 98:     .mockRejectedValueOnce(new Error())
 99:     .mockRejectedValueOnce(new Error())
100:     .mockResolvedValueOnce('success');
101:   await retryOperation(mock);
102:   expect(mock).toHaveBeenCalledTimes(3);
103: });
104: ```
105: Vague name, tests mock not code
106: </Bad>
107: 
108: **Requirements:**
109: - One behavior
110: - Clear name
111: - Real code (no mocks unless unavoidable)
112: 
113: ### Verify RED - Watch It Fail
114: 
115: **MANDATORY. Never skip.**
116: 
117: ```bash
118: npm test path/to/test.test.ts
119: ```
120: 
121: Confirm:
122: - Test fails (not errors)
123: - Failure message is expected
124: - Fails because feature missing (not typos)
125: 
126: **Test passes?** You're testing existing behavior. Fix test.
127: 
128: **Test errors?** Fix error, re-run until it fails correctly.
129: 
130: ### GREEN - Minimal Code
131: 
132: Write simplest code to pass the test.
133: 
134: <Good>
135: ```typescript
136: async function retryOperation<T>(fn: () => Promise<T>): Promise<T> {
137:   for (let i = 0; i < 3; i++) {
138:     try {
139:       return await fn();
140:     } catch (e) {
141:       if (i === 2) throw e;
142:     }
143:   }
144:   throw new Error('unreachable');
145: }
146: ```
147: Just enough to pass
148: </Good>
149: 
150: <Bad>
151: ```typescript
152: async function retryOperation<T>(
153:   fn: () => Promise<T>,
154:   options?: {
155:     maxRetries?: number;
156:     backoff?: 'linear' | 'exponential';
157:     onRetry?: (attempt: number) => void;
158:   }
159: ): Promise<T> {
160:   // YAGNI
161: }
162: ```
163: Over-engineered
164: </Bad>
165: 
166: Don't add features, refactor other code, or "improve" beyond the test.
167: 
168: ### Verify GREEN - Watch It Pass
169: 
170: **MANDATORY.**
171: 
172: ```bash
173: npm test path/to/test.test.ts
174: ```
175: 
176: Confirm:
177: - Test passes
178: - Other tests still pass
179: - Output pristine (no errors, warnings)
180: 
181: **Test fails?** Fix code, not test.
182: 
183: **Other tests fail?** Fix now.
184: 
185: ### REFACTOR - Clean Up
186: 
187: After green only:
188: - Remove duplication
189: - Improve names
190: - Extract helpers
191: 
192: Keep tests green. Don't add behavior.
193: 
194: ### Repeat
195: 
196: Next failing test for next feature.
197: 
198: ## Good Tests
199: 
200: | Quality | Good | Bad |
201: |---------|------|-----|
202: | **Minimal** | One thing. "and" in name? Split it. | `test('validates email and domain and whitespace')` |
203: | **Clear** | Name describes behavior | `test('test1')` |
204: | **Shows intent** | Demonstrates desired API | Obscures what code should do |
205: 
206: ## Why Order Matters
207: 
208: **"I'll write tests after to verify it works"**
209: 
210: Tests written after code pass immediately. Passing immediately proves nothing:
211: - Might test wrong thing
212: - Might test implementation, not behavior
213: - Might miss edge cases you forgot
214: - You never saw it catch the bug
215: 
216: Test-first forces you to see the test fail, proving it actually tests something.
217: 
218: **"I already manually tested all the edge cases"**
219: 
220: Manual testing is ad-hoc. You think you tested everything but:
221: - No record of what you tested
222: - Can't re-run when code changes
223: - Easy to forget cases under pressure
224: - "It worked when I tried it" ≠ comprehensive
225: 
226: Automated tests are systematic. They run the same way every time.
227: 
228: **"Deleting X hours of work is wasteful"**
229: 
230: Sunk cost fallacy. The time is already gone. Your choice now:
231: - Delete and rewrite with TDD (X more hours, high confidence)
232: - Keep it and add tests after (30 min, low confidence, likely bugs)
233: 
234: The "waste" is keeping code you can't trust. Working code without real tests is technical debt.
235: 
236: **"TDD is dogmatic, being pragmatic means adapting"**
237: 
238: TDD IS pragmatic:
239: - Finds bugs before commit (faster than debugging after)
240: - Prevents regressions (tests catch breaks immediately)
241: - Documents behavior (tests show how to use code)
242: - Enables refactoring (change freely, tests catch breaks)
243: 
244: "Pragmatic" shortcuts = debugging in production = slower.
245: 
246: **"Tests after achieve the same goals - it's spirit not ritual"**
247: 
248: No. Tests-after answer "What does this do?" Tests-first answer "What should this do?"
249: 
250: Tests-after are biased by your implementation. You test what you built, not what's required. You verify remembered edge cases, not discovered ones.
251: 
252: Tests-first force edge case discovery before implementing. Tests-after verify you remembered everything (you didn't).
253: 
254: 30 minutes of tests after ≠ TDD. You get coverage, lose proof tests work.
255: 
256: ## Common Rationalizations
257: 
258: | Excuse | Reality |
259: |--------|---------|
260: | "Too simple to test" | Simple code breaks. Test takes 30 seconds. |
261: | "I'll test after" | Tests passing immediately prove nothing. |
262: | "Tests after achieve same goals" | Tests-after = "what does this do?" Tests-first = "what should this do?" |
263: | "Already manually tested" | Ad-hoc ≠ systematic. No record, can't re-run. |
264: | "Deleting X hours is wasteful" | Sunk cost fallacy. Keeping unverified code is technical debt. |
265: | "Keep as reference, write tests first" | You'll adapt it. That's testing after. Delete means delete. |
266: | "Need to explore first" | Fine. Throw away exploration, start with TDD. |
267: | "Test hard = design unclear" | Listen to test. Hard to test = hard to use. |
268: | "TDD will slow me down" | TDD faster than debugging. Pragmatic = test-first. |
269: | "Manual test faster" | Manual doesn't prove edge cases. You'll re-test every change. |
270: | "Existing code has no tests" | You're improving it. Add tests for existing code. |
271: 
272: ## Red Flags - STOP and Start Over
273: 
274: - Code before test
275: - Test after implementation
276: - Test passes immediately
277: - Can't explain why test failed
278: - Tests added "later"
279: - Rationalizing "just this once"
280: - "I already manually tested it"
281: - "Tests after achieve the same purpose"
282: - "It's about spirit not ritual"
283: - "Keep as reference" or "adapt existing code"
284: - "Already spent X hours, deleting is wasteful"
285: - "TDD is dogmatic, I'm being pragmatic"
286: - "This is different because..."
287: 
288: **All of these mean: Delete code. Start over with TDD.**
289: 
290: ## Example: Bug Fix
291: 
292: **Bug:** Empty email accepted
293: 
294: **RED**
295: ```typescript
296: test('rejects empty email', async () => {
297:   const result = await submitForm({ email: '' });
298:   expect(result.error).toBe('Email required');
299: });
300: ```
301: 
302: **Verify RED**
303: ```bash
304: $ npm test
305: FAIL: expected 'Email required', got undefined
306: ```
307: 
308: **GREEN**
309: ```typescript
310: function submitForm(data: FormData) {
311:   if (!data.email?.trim()) {
312:     return { error: 'Email required' };
313:   }
314:   // ...
315: }
316: ```
317: 
318: **Verify GREEN**
319: ```bash
320: $ npm test
321: PASS
322: ```
323: 
324: **REFACTOR**
325: Extract validation for multiple fields if needed.
326: 
327: ## Verification Checklist
328: 
329: Before marking work complete:
330: 
331: - [ ] Every new function/method has a test
332: - [ ] Watched each test fail before implementing
333: - [ ] Each test failed for expected reason (feature missing, not typo)
334: - [ ] Wrote minimal code to pass each test
335: - [ ] All tests pass
336: - [ ] Output pristine (no errors, warnings)
337: - [ ] Tests use real code (mocks only if unavoidable)
338: - [ ] Edge cases and errors covered
339: 
340: Can't check all boxes? You skipped TDD. Start over.
341: 
342: ## When Stuck
343: 
344: | Problem | Solution |
345: |---------|----------|
346: | Don't know how to test | Write wished-for API. Write assertion first. Ask your human partner. |
347: | Test too complicated | Design too complicated. Simplify interface. |
348: | Must mock everything | Code too coupled. Use dependency injection. |
349: | Test setup huge | Extract helpers. Still complex? Simplify design. |
350: 
351: ## Debugging Integration
352: 
353: Bug found? Write failing test reproducing it. Follow TDD cycle. Test proves fix and prevents regression.
354: 
355: Never fix bugs without a test.
356: 
357: ## Testing Anti-Patterns
358: 
359: When adding mocks or test utilities, read @testing-anti-patterns.md to avoid common pitfalls:
360: - Testing mock behavior instead of real behavior
361: - Adding test-only methods to production classes
362: - Mocking without understanding dependencies
363: 
364: ## Final Rule
365: 
366: ```
367: Production code → test exists and failed first
368: Otherwise → not TDD
369: ```
370: 
371: No exceptions without your human partner's permission.
</file>

<file path="__LOCAL-REPO/__skills/development/test-driven-development/testing-anti-patterns.md">
  1: # Testing Anti-Patterns
  2: 
  3: **Load this reference when:** writing or changing tests, adding mocks, or tempted to add test-only methods to production code.
  4: 
  5: ## Overview
  6: 
  7: Tests must verify real behavior, not mock behavior. Mocks are a means to isolate, not the thing being tested.
  8: 
  9: **Core principle:** Test what the code does, not what the mocks do.
 10: 
 11: **Following strict TDD prevents these anti-patterns.**
 12: 
 13: ## The Iron Laws
 14: 
 15: ```
 16: 1. NEVER test mock behavior
 17: 2. NEVER add test-only methods to production classes
 18: 3. NEVER mock without understanding dependencies
 19: ```
 20: 
 21: ## Anti-Pattern 1: Testing Mock Behavior
 22: 
 23: **The violation:**
 24: ```typescript
 25: // ❌ BAD: Testing that the mock exists
 26: test('renders sidebar', () => {
 27:   render(<Page />);
 28:   expect(screen.getByTestId('sidebar-mock')).toBeInTheDocument();
 29: });
 30: ```
 31: 
 32: **Why this is wrong:**
 33: - You're verifying the mock works, not that the component works
 34: - Test passes when mock is present, fails when it's not
 35: - Tells you nothing about real behavior
 36: 
 37: **your human partner's correction:** "Are we testing the behavior of a mock?"
 38: 
 39: **The fix:**
 40: ```typescript
 41: // ✅ GOOD: Test real component or don't mock it
 42: test('renders sidebar', () => {
 43:   render(<Page />);  // Don't mock sidebar
 44:   expect(screen.getByRole('navigation')).toBeInTheDocument();
 45: });
 46: 
 47: // OR if sidebar must be mocked for isolation:
 48: // Don't assert on the mock - test Page's behavior with sidebar present
 49: ```
 50: 
 51: ### Gate Function
 52: 
 53: ```
 54: BEFORE asserting on any mock element:
 55:   Ask: "Am I testing real component behavior or just mock existence?"
 56: 
 57:   IF testing mock existence:
 58:     STOP - Delete the assertion or unmock the component
 59: 
 60:   Test real behavior instead
 61: ```
 62: 
 63: ## Anti-Pattern 2: Test-Only Methods in Production
 64: 
 65: **The violation:**
 66: ```typescript
 67: // ❌ BAD: destroy() only used in tests
 68: class Session {
 69:   async destroy() {  // Looks like production API!
 70:     await this._workspaceManager?.destroyWorkspace(this.id);
 71:     // ... cleanup
 72:   }
 73: }
 74: 
 75: // In tests
 76: afterEach(() => session.destroy());
 77: ```
 78: 
 79: **Why this is wrong:**
 80: - Production class polluted with test-only code
 81: - Dangerous if accidentally called in production
 82: - Violates YAGNI and separation of concerns
 83: - Confuses object lifecycle with entity lifecycle
 84: 
 85: **The fix:**
 86: ```typescript
 87: // ✅ GOOD: Test utilities handle test cleanup
 88: // Session has no destroy() - it's stateless in production
 89: 
 90: // In test-utils/
 91: export async function cleanupSession(session: Session) {
 92:   const workspace = session.getWorkspaceInfo();
 93:   if (workspace) {
 94:     await workspaceManager.destroyWorkspace(workspace.id);
 95:   }
 96: }
 97: 
 98: // In tests
 99: afterEach(() => cleanupSession(session));
100: ```
101: 
102: ### Gate Function
103: 
104: ```
105: BEFORE adding any method to production class:
106:   Ask: "Is this only used by tests?"
107: 
108:   IF yes:
109:     STOP - Don't add it
110:     Put it in test utilities instead
111: 
112:   Ask: "Does this class own this resource's lifecycle?"
113: 
114:   IF no:
115:     STOP - Wrong class for this method
116: ```
117: 
118: ## Anti-Pattern 3: Mocking Without Understanding
119: 
120: **The violation:**
121: ```typescript
122: // ❌ BAD: Mock breaks test logic
123: test('detects duplicate server', () => {
124:   // Mock prevents config write that test depends on!
125:   vi.mock('ToolCatalog', () => ({
126:     discoverAndCacheTools: vi.fn().mockResolvedValue(undefined)
127:   }));
128: 
129:   await addServer(config);
130:   await addServer(config);  // Should throw - but won't!
131: });
132: ```
133: 
134: **Why this is wrong:**
135: - Mocked method had side effect test depended on (writing config)
136: - Over-mocking to "be safe" breaks actual behavior
137: - Test passes for wrong reason or fails mysteriously
138: 
139: **The fix:**
140: ```typescript
141: // ✅ GOOD: Mock at correct level
142: test('detects duplicate server', () => {
143:   // Mock the slow part, preserve behavior test needs
144:   vi.mock('MCPServerManager'); // Just mock slow server startup
145: 
146:   await addServer(config);  // Config written
147:   await addServer(config);  // Duplicate detected ✓
148: });
149: ```
150: 
151: ### Gate Function
152: 
153: ```
154: BEFORE mocking any method:
155:   STOP - Don't mock yet
156: 
157:   1. Ask: "What side effects does the real method have?"
158:   2. Ask: "Does this test depend on any of those side effects?"
159:   3. Ask: "Do I fully understand what this test needs?"
160: 
161:   IF depends on side effects:
162:     Mock at lower level (the actual slow/external operation)
163:     OR use test doubles that preserve necessary behavior
164:     NOT the high-level method the test depends on
165: 
166:   IF unsure what test depends on:
167:     Run test with real implementation FIRST
168:     Observe what actually needs to happen
169:     THEN add minimal mocking at the right level
170: 
171:   Red flags:
172:     - "I'll mock this to be safe"
173:     - "This might be slow, better mock it"
174:     - Mocking without understanding the dependency chain
175: ```
176: 
177: ## Anti-Pattern 4: Incomplete Mocks
178: 
179: **The violation:**
180: ```typescript
181: // ❌ BAD: Partial mock - only fields you think you need
182: const mockResponse = {
183:   status: 'success',
184:   data: { userId: '123', name: 'Alice' }
185:   // Missing: metadata that downstream code uses
186: };
187: 
188: // Later: breaks when code accesses response.metadata.requestId
189: ```
190: 
191: **Why this is wrong:**
192: - **Partial mocks hide structural assumptions** - You only mocked fields you know about
193: - **Downstream code may depend on fields you didn't include** - Silent failures
194: - **Tests pass but integration fails** - Mock incomplete, real API complete
195: - **False confidence** - Test proves nothing about real behavior
196: 
197: **The Iron Rule:** Mock the COMPLETE data structure as it exists in reality, not just fields your immediate test uses.
198: 
199: **The fix:**
200: ```typescript
201: // ✅ GOOD: Mirror real API completeness
202: const mockResponse = {
203:   status: 'success',
204:   data: { userId: '123', name: 'Alice' },
205:   metadata: { requestId: 'req-789', timestamp: 1234567890 }
206:   // All fields real API returns
207: };
208: ```
209: 
210: ### Gate Function
211: 
212: ```
213: BEFORE creating mock responses:
214:   Check: "What fields does the real API response contain?"
215: 
216:   Actions:
217:     1. Examine actual API response from docs/examples
218:     2. Include ALL fields system might consume downstream
219:     3. Verify mock matches real response schema completely
220: 
221:   Critical:
222:     If you're creating a mock, you must understand the ENTIRE structure
223:     Partial mocks fail silently when code depends on omitted fields
224: 
225:   If uncertain: Include all documented fields
226: ```
227: 
228: ## Anti-Pattern 5: Integration Tests as Afterthought
229: 
230: **The violation:**
231: ```
232: ✅ Implementation complete
233: ❌ No tests written
234: "Ready for testing"
235: ```
236: 
237: **Why this is wrong:**
238: - Testing is part of implementation, not optional follow-up
239: - TDD would have caught this
240: - Can't claim complete without tests
241: 
242: **The fix:**
243: ```
244: TDD cycle:
245: 1. Write failing test
246: 2. Implement to pass
247: 3. Refactor
248: 4. THEN claim complete
249: ```
250: 
251: ## When Mocks Become Too Complex
252: 
253: **Warning signs:**
254: - Mock setup longer than test logic
255: - Mocking everything to make test pass
256: - Mocks missing methods real components have
257: - Test breaks when mock changes
258: 
259: **your human partner's question:** "Do we need to be using a mock here?"
260: 
261: **Consider:** Integration tests with real components often simpler than complex mocks
262: 
263: ## TDD Prevents These Anti-Patterns
264: 
265: **Why TDD helps:**
266: 1. **Write test first** → Forces you to think about what you're actually testing
267: 2. **Watch it fail** → Confirms test tests real behavior, not mocks
268: 3. **Minimal implementation** → No test-only methods creep in
269: 4. **Real dependencies** → You see what the test actually needs before mocking
270: 
271: **If you're testing mock behavior, you violated TDD** - you added mocks without watching test fail against real code first.
272: 
273: ## Quick Reference
274: 
275: | Anti-Pattern | Fix |
276: |--------------|-----|
277: | Assert on mock elements | Test real component or unmock it |
278: | Test-only methods in production | Move to test utilities |
279: | Mock without understanding | Understand dependencies first, mock minimally |
280: | Incomplete mocks | Mirror real API completely |
281: | Tests as afterthought | TDD - tests first |
282: | Over-complex mocks | Consider integration tests |
283: 
284: ## Red Flags
285: 
286: - Assertion checks for `*-mock` test IDs
287: - Methods only called in test files
288: - Mock setup is >50% of test
289: - Test fails when you remove mock
290: - Can't explain why mock is needed
291: - Mocking "just to be safe"
292: 
293: ## The Bottom Line
294: 
295: **Mocks are tools to isolate, not things to test.**
296: 
297: If TDD reveals you're testing mock behavior, you've gone wrong.
298: 
299: Fix: Test real behavior or question why you're mocking at all.
</file>

</files>
