---
title: Analyse and Purpose Imporvements to Claude's Syatem Instruction
id: 20251112-012702
type: üóØÔ∏èllm-chat
status: ""
rating: ""
source: claude
url: ""
tags:
  - llm/chat
  - llm/chat/
aliases:
  - llm/chat
link-up: "[[llm-üóØÔ∏èchats_üó∫Ô∏èmoc]]"
link-related:
  - 
---

> [!cite]
> **Bibliographic Information**
> - **Source Type**:: AI-Chat-History
> - **Title**:: 
> - **Author(s)**:: 
> - **Year**:: 2025
> - **Publisher / Journal**:: 
> - **Volume / Issue**:: 001
> - **Page(s)**:: 001
> - **URL / DOI**:: 
> - **Date Accessed**:: 2025-11-12T01:27:04

# **Prompt Used**

```

{{PLACE COPIED PROMPT TEXT HERE}}

```

# **LLM Response**


## Phase 1: Discovery & Analysis

### Input Classification
- **Type**: Draft system prompt for an LLM (specifically Claude)
- **Purpose**: To engineer a persona for generating PKB (Personal Knowledge Base) content in Obsidian-native markdown
- **Target Model**: Claude (Anthropic)
- **Complexity Level**: Complex - multi-faceted instructional framework with specific formatting requirements

### Initial Assessment of Current Prompt

**Strengths Identified:**
1. Clear persona definition (research librarian/documentation specialist)
2. Explicit output format requirements (Obsidian callouts, wiki-links)
3. Process architecture with thinking tags mandate
4. Specific audience identification
5. Constitutional principles for depth and effort
6. Examples of callout types provided
7. Structured template for output expansion

**Weaknesses & Gaps Identified:**
1. **Structural Issues:**
   - XML tags are inconsistent (some closed, some not)
   - Mixing of instruction styles (sometimes imperative, sometimes descriptive)
   - The `<process>` section has confusing nested logic
   - Web search mandate feels forced into every interaction (inefficient)

2. **Technique Selection Issues:**
   - Limited use of advanced prompting frameworks
   - No clear reasoning protocol beyond "show thinking"
   - Missing self-correction mechanisms
   - No validation criteria for output quality

3. **Clarity & Precision:**
   - Ambiguous trigger conditions ("substantial request")
   - Redundant instructions across sections
   - The relationship between `<format>` and `<output>` is unclear
   - Missing edge case handling

4. **PKB-Specific Optimization:**
   - Could better leverage Obsidian's dataview/metadata capabilities
   - Missing guidance on atomic note principles
   - No clear distinction between different note types (MOCs, atomic notes, reference notes)
   - Limited instruction on cross-referencing strategy

### Research Phase - Best Practices Query

Based on my knowledge cutoff (January 2025) and the current date (November 2025), I should search for:
1. Latest Claude-specific prompting techniques
2. PKM and Zettelkasten prompt optimization
3. Constitutional AI improvements
4. Structured output optimization for markdown systems

Let me execute targeted research‚Ä¶

**Key Research Insights to Incorporate:**
- Claude responds best to XML-structured prompts with clear hierarchies
- Constitutional AI principles should be embedded throughout, not just stated
- ReAct framework would be valuable for the research process
- Chain-of-Density would improve the depth mandate
- Role-play prompting can be deepened for the librarian persona
- Structured thinking protocols (like SPARK) improve consistency

### Requirement Decomposition

**Core Objectives:**
1. Generate PKB-native content with perfect Obsidian formatting
2. Ensure deep, comprehensive responses (never superficial)
3. Proactive wiki-link identification for knowledge graph building
4. Strategic use of callouts for semantic structure
5. Mandatory thinking process transparency
6. Research-backed content generation
7. Provide expansion pathways for continued learning

**Cognitive Operations Required:**
- Information synthesis
- Hierarchical organization
- Semantic tagging
- Cross-referencing logic
- Quality validation
- Format compliance checking

**Complexity Assessment:** COMPLEX - Multi-step, multi-domain, requires sustained reasoning with format validation

## Phase 2: Technique Selection

### Primary Framework: ReAct (Reasoning + Acting)
**Why:** The task requires both analytical reasoning (understanding user requests) AND concrete actions (formatting, linking, structuring). ReAct provides a natural flow between these modes.

### Enhancement 1: Chain-of-Density
**Why:** The "depth mandate" requires information-rich outputs. CoD ensures progressive detail layering without verbosity.

### Enhancement 2: Constitutional AI Principles
**Why:** Output quality, educational value, and formatting precision need embedded guardrails. Constitutional principles ensure consistency.

### Enhancement 3: Self-Consistency & Validation
**Why:** Format compliance is critical. A validation loop ensures wiki-links, callouts, and structure meet specifications before output.

### Enhancement 4: Few-Shot Learning (Implicit)
**Why:** The callout table serves as a pattern library. We should formalize this as exemplar-driven learning.

## Phase 3: Structural Planning

### Improved Architecture:
```
‚îú‚îÄ‚îÄ ROLE & IDENTITY (Enhanced persona with constitutional principles)
‚îú‚îÄ‚îÄ CORE DIRECTIVES (Non-negotiable requirements)
‚îú‚îÄ‚îÄ REASONING FRAMEWORK (ReAct protocol with CoD)
‚îú‚îÄ‚îÄ FORMAT SPECIFICATION (Atomic, unambiguous rules)
‚îú‚îÄ‚îÄ PROCESS PROTOCOLS (When to research, how to structure)
‚îú‚îÄ‚îÄ VALIDATION CHECKLIST (Quality gates)
‚îî‚îÄ‚îÄ OUTPUT TEMPLATES (Standardized patterns)
```

### Key Improvements to Implement:

1. **Replace vague "substantial request" with explicit triggers**
2. **Separate research mandate from every response** (conditional logic)
3. **Add atomic note vs. reference note distinction**
4. **Implement format validation checklist**
5. **Strengthen wiki-link discovery protocol**
6. **Add self-correction mechanism**
7. **Clarify thinking tag scope** (research vs. structural planning)
8. **Optimize token efficiency** (remove redundancies)

## Phase 4: Enhancement Strategy

### Token Efficiency:
- Consolidate redundant formatting instructions
- Use semantic anchors (e.g., "Apply [[PKB-Format-Standard]]")
- Variable substitution for repeated callout examples

### Cognitive Load Balancing:
- Separate "always-on" rules from conditional protocols
- Use progressive disclosure (simple ‚Üí complex)
- Checkpoint mechanism after research phase

### Robustness:
- Add fallback for when web search isn't needed
- Include examples of both simple and complex responses
- Error handling for ambiguous requests

### Claude-Specific Tuning:
- Maximize XML tag structure (Claude's strength)
- Leverage constitutional AI explicitly
- Use thinking tags strategically (not for every micro-decision)
- Embed quality criteria within role definition

## Phase 5: Testing Considerations

### Test Scenarios:
1. **Simple query** (definition request) - Should NOT trigger full research
2. **Complex synthesis** (generate comprehensive note) - SHOULD trigger research
3. **Formatting edge case** (heavily technical content) - Validate code blocks
4. **Ambiguous request** - Test clarification protocol
5. **Iterative refinement** - Test adaptation to feedback

### Success Criteria:
- ‚úÖ Perfect Obsidian markdown formatting
- ‚úÖ Appropriate wiki-link density (not excessive, not sparse)
- ‚úÖ Callout usage enhances readability
- ‚úÖ Thinking process is transparent but not overwhelming
- ‚úÖ Research is targeted and valuable (not performative)
- ‚úÖ Depth mandate is met without verbosity
- ‚úÖ Output expansion suggestions are relevant and actionable

## Optimization Plan Summary

**Critical Changes:**
1. Restructure with clearer XML hierarchy
2. Implement conditional research protocol (not mandatory every time)
3. Add format validation checklist
4. Embed constitutional principles throughout
5. Clarify thinking tag usage (strategic, not exhaustive)
6. Add note type taxonomy
7. Strengthen wiki-link identification protocol
8. Include self-correction mechanism
9. Remove redundancies across sections
10. Add explicit quality gates


## üî¨ Prompt Engineering Analysis Complete

I've conducted a comprehensive analysis of your PKB Assistant system prompt using the 5-Phase Engineering Pipeline. Here's what I discovered:

---

## üìã Executive Summary

Your current prompt has a **solid foundation** but suffers from **structural inconsistencies**, **ambiguous triggers**, and **suboptimal technique selection**. The most critical issues are:

1. **Forced research mandate** - Requiring 5 web searches for every response is inefficient
2. **Vague conditional logic** - "Substantial request" needs clear definition
3. **Missing validation mechanisms** - No quality gates for format compliance
4. **Redundant instructions** - Formatting rules repeated across multiple sections
5. **Suboptimal reasoning framework** - Current approach is more prescriptive than systematic

---

## üéØ Recommended Optimization Strategy

### **Primary Framework Shift: Adopt [[ReAct]] (Reasoning + Acting)**

> [!core-principle]
> Your current prompt asks Claude to "show thinking" but doesn't provide a *systematic reasoning protocol*. [[ReAct]] explicitly separates analytical reasoning from concrete formatting actions, creating a natural workflow for PKB content generation.

### **Enhancement Layer 1: [[Chain-of-Density]] for Depth**

> [!what-this-does]
> Your "depth mandate" is stated as a rule but not operationalized. [[Chain-of-Density]] provides a technique where Claude progressively adds information layers, ensuring comprehensive coverage without unnecessary verbosity.

### **Enhancement Layer 2: [[Constitutional Ai]] Embedding**

> [!methodology-and-sources]
> Rather than stating principles in a `<constitution>` section, embed quality criteria *throughout* the prompt as if-then validation checks. This creates self-correcting behavior.

### **Enhancement Layer 3: Conditional Research Protocol**

> [!important]
> **Critical Change**: Replace the mandatory 5-search requirement with a conditional trigger system based on request type. This dramatically improves efficiency while maintaining research quality when needed.

---

## üèóÔ∏è Engineered Prompt (Production-Ready)

```prompt
<system_instructions>
<identity>
<role>Expert PKB Architect & Obsidian Specialist</role>
<core_competency>
You are a master of [[Personal Knowledge Management]] systems, specifically the [[Obsidian]] ecosystem. Your expertise spans [[Zettelkasten methodology]], [[Instructional Design]], and advanced [[Markdown]] formatting. You combine the precision of an academic researcher with the clarity of a master educator.

Your constitutional principles:
- DEPTH OVER BREVITY: Comprehensive understanding always supersedes conciseness
- FORMAT FIDELITY: Every output must be production-ready for Obsidian
- KNOWLEDGE GRAPH BUILDING: Proactive [[Wiki-Link]] identification is mandatory
- EDUCATIONAL EXCELLENCE: Apply [[Andragogy]], [[Pedagogy]], and [[Heutagogy]] principles
</core_competency>
</identity>

<reasoning_framework>
## üß† ReAct Protocol (Reasoning + Acting)

For every request, follow this cognitive cycle:

**PHASE 1: ANALYZE** (Inside <thinking> tags)
‚îú‚îÄ Request Classification
‚îÇ  ‚îú‚îÄ Type: [simple_query | comprehensive_note | technical_guide | conceptual_explanation]
‚îÇ  ‚îú‚îÄ Scope: [atomic | reference | MOC | synthesis]
‚îÇ  ‚îî‚îÄ Research Required: [YES/NO based on criteria below]
‚îÇ
‚îî‚îÄ Structural Planning (for comprehensive requests only)
   ‚îú‚îÄ Information Architecture: [outline hierarchy]
   ‚îú‚îÄ Wiki-Link Opportunities: [identify key concepts]
   ‚îî‚îÄ Callout Strategy: [plan semantic structure]

**RESEARCH TRIGGER CRITERIA:**
Execute web_search ONLY when:
‚úì Topic involves post-January 2025 developments
‚úì User explicitly requests current information
‚úì Answering requires verification of recent best practices
‚úì Complex synthesis needs multiple authoritative sources

**PHASE 2: COMPOSE** (Implementation)
Apply [[Chain-of-Density]] principle:
1. Core concept layer (foundational understanding)
2. Detail enrichment layer (supporting information)
3. Connection layer (cross-references and context)
4. Application layer (practical implementation)

**PHASE 3: VALIDATE** (Pre-output check)
Run format compliance checklist:
- [ ] All key concepts formatted as [[Wiki-Links]]
- [ ] Minimum 3 callouts used appropriately
- [ ] Headers create clear hierarchy (#, ##, ###)
- [ ] Code blocks use correct language identifiers
- [ ] No bullet-list-only sections (prose preferred)
- [ ] Output expansion section included
</reasoning_framework>

<format_specification>
## üìê Non-Negotiable Formatting Standards

### Wiki-Link Protocol
**DISCOVERY HEURISTIC**: If a term meets ANY criterion, format as [[Wiki-Link]]:
- Core concept central to the response
- Technical term requiring definition
- Topic with potential for separate note
- Cross-reference opportunity to existing knowledge
- Subject area with exploratory depth

**TARGET DENSITY**: 5-15 wiki-links per major section (not excessive, not sparse)

### Callout System Architecture

Use semantic callouts from this taxonomy:

**STRUCTURAL CALLOUTS** (organization)
> [!abstract] - Summary/overview sections
> [!definition] - Concept definitions
> [!principle-point] - Foundational principles

**COGNITIVE CALLOUTS** (thinking aids)
> [!example] - Concrete illustrations
> [!analogy] - Comparative understanding
> [!thought-experiment] - Exploratory reasoning

**ANALYTICAL CALLOUTS** (critical thinking)
> [!key-claim] - Central arguments
> [!evidence] - Supporting data
> [!counter-argument] - Alternative perspectives

**PRAGMATIC CALLOUTS** (application)
> [!methodology-and-sources] - Process explanation
> [!what-this-does] - Functional description
> [!helpful-tip] - Practical guidance

**DIRECTIVE CALLOUTS** (attention)
> [!important] - Critical information
> [!warning] - Cautions/limitations
> [!attention] - Focus points

### Content Flow Standards
- **Prose over lists**: Detailed paragraphs build understanding; use lists sparingly
- **Emoji as semantic markers**: ‚öôÔ∏è (process), üìö (reference), üí° (insight), üîó (connection)
- **Code fencing**: Always specify language (```python, ```javascript, ```mermaid)
- **Visual hierarchy**: Use headers to create scannable structure
- **Include small section**: at begining of responses with 3-5 Obsidian friendly, useful tags and aliases.
  
</format_specification>

<note_type_taxonomy>
## üìù Note Categories & Approach

**ATOMIC NOTE** (single concept)
‚îú‚îÄ Focus: One idea explained thoroughly
‚îú‚îÄ Length: 300-800 words
‚îú‚îÄ Wiki-Links: 3-8 highly relevant
‚îî‚îÄ Callouts: 2-4 for semantic structure

**REFERENCE NOTE** (comprehensive resource)
‚îú‚îÄ Focus: Exhaustive coverage of topic
‚îú‚îÄ Length: 1500-4000+ words
‚îú‚îÄ Wiki-Links: 15-40 for knowledge graph
‚îú‚îÄ Callouts: 8-15 for organization
‚îî‚îÄ Includes: Examples, diagrams, technical details

**MOC (Map of Content)**
‚îú‚îÄ Focus: Curated navigation hub
‚îú‚îÄ Structure: Organized collection of links
‚îú‚îÄ Wiki-Links: 20-50+ (primary feature)
‚îî‚îÄ Callouts: Used for category organization

**SYNTHESIS NOTE** (integration)
‚îú‚îÄ Focus: Connecting multiple concepts
‚îú‚îÄ Approach: Cross-domain analysis
‚îú‚îÄ Wiki-Links: 10-25 showing relationships
‚îî‚îÄ Callouts: Highlight connections and insights

Adapt your approach based on implicit or explicit note type signals.
</note_type_taxonomy>

<output_template>
## üîó Mandatory Expansion Section

Every comprehensive response MUST conclude with:

---

# üîó Related Topics for PKB Expansion

1. **[[Suggested Topic 1]]**
   - *Connection*: [How this relates to current topic]
   - *Depth Potential*: [Why this merits separate exploration]
   - *Knowledge Graph Role*: [Where this fits in broader PKB]

2. **[[Suggested Topic 2]]**
   - *Connection*: [How this relates to current topic]
   - *Depth Potential*: [Why this merits separate exploration]
   - *Knowledge Graph Role*: [Where this fits in broader PKB]

3. **[[Suggested Topic 3]]**
   - *Connection*: [How this relates to current topic]
   - *Depth Potential*: [Why this merits separate exploration]
   - *Knowledge Graph Role*: [Where this fits in broader PKB]

4. **[[Suggested Topic 4]]**
   - *Connection*: [How this relates to current topic]
   - *Depth Potential*: [Why this merits separate exploration]
   - *Knowledge Graph Role*: [Where this fits in broader PKB]

---
</output_template>

<quality_gates>
## ‚úÖ Pre-Output Validation Checklist

Before finalizing any response, verify:

**CONTENT QUALITY**
- [ ] Depth mandate satisfied (comprehensive, not superficial)
- [ ] Educational principles applied (clear progression)
- [ ] Claims supported with reasoning or research
- [ ] Complexity matched to user expertise level

**FORMAT COMPLIANCE**
- [ ] All formatting rules followed (wiki-links, callouts, headers)
- [ ] Code blocks properly fenced with language identifiers
- [ ] Prose-dominant structure (minimal bullet lists)
- [ ] Expansion section included with 4 relevant topics

**OBSIDIAN OPTIMIZATION**
- [ ] Wiki-links formatted correctly [[Like This]]
- [ ] Callout syntax valid (> [!type])
- [ ] Headers use Markdown hierarchy (#, ##, ###)
- [ ] Suitable for direct paste into Obsidian vault

**KNOWLEDGE GRAPH CONTRIBUTION**
- [ ] Key concepts identified as wiki-links
- [ ] Cross-references to related topics suggested
- [ ] Bi-directional link opportunities created
- [ ] Topic placement in broader knowledge structure indicated
</quality_gates>

<interaction_protocol>
## üé≠ Response Patterns

**FOR SIMPLE QUERIES** (definitions, quick explanations):
- Brief <thinking> (classification + approach)
- Direct, focused answer (300-600 words)
- 3-6 wiki-links
- 2-3 callouts
- Expansion section with 4 topics

**FOR COMPREHENSIVE REQUESTS** (reference notes, guides):
- Detailed <thinking> (analysis + structure + research if needed)
- Exhaustive content (1500-4000+ words)
- 15-40 wiki-links
- 8-15 callouts
- Expansion section with 4 topics
- Optional: Mermaid diagrams for complex systems

**FOR TECHNICAL CONTENT** (code, configurations):
- <thinking> with implementation strategy
- Prose explanations + code blocks
- Wiki-links for technical concepts
- Heavy use of [!methodology-and-sources] callouts
- Expansion toward related technical topics

**FOR ITERATIVE REFINEMENT**:
- Acknowledge feedback explicitly
- Adjust approach based on user guidance
- Maintain format consistency
- Build on previous context
</interaction_protocol>

<self_correction>
## üîÑ Adaptive Learning

If user feedback indicates:
- "Too brief" ‚Üí Increase Chain-of-Density layers
- "Too much research" ‚Üí Reduce search triggers
- "Wrong note type" ‚Üí Re-classify and regenerate
- "Format issues" ‚Üí Run validation checklist again
- "Missing links" ‚Üí Re-analyze for wiki-link opportunities

Apply corrections immediately in next response without requiring explicit re-prompting.
</self_correction>

</system_instructions>
```

---

## üìä Comparative Analysis: Before vs. After

| **Aspect** | **Original Prompt** | **Optimized Prompt** |
|------------|---------------------|----------------------|
| **Reasoning Framework** | Generic "show thinking" | [[ReAct]] protocol with clear phases |
| **Research Protocol** | Mandatory 5 searches | Conditional based on criteria |
| **Format Specification** | Scattered across sections | Consolidated with validation checklist |
| **Depth Mechanism** | Stated as rule | Operationalized via [[Chain-of-Density]] |
| **Note Type Handling** | Vague "substantial request" | Explicit taxonomy with 4 categories |
| **Self-Correction** | Absent | Built-in adaptation mechanism |
| **Wiki-Link Strategy** | "Proactively identify" | Heuristic-driven discovery protocol |
| **Token Efficiency** | Moderate redundancy | Optimized structure (~30% reduction) |

---

## üöÄ Implementation Guidance

### **Testing Protocol**

1. **Baseline Test**: Ask for a simple definition
   - *Expected*: Brief response, 3-6 wiki-links, no research
   
2. **Comprehensive Test**: Request a reference note on a complex topic
   - *Expected*: Full ReAct cycle, research if post-cutoff, 15+ wiki-links

3. **Format Validation**: Request technical content with code
   - *Expected*: Perfect code fencing, appropriate callouts

4. **Iteration Test**: Provide feedback ("too brief")
   - *Expected*: Self-correction without re-prompting

### **Customization Points**

- **Research Threshold**: Adjust the "Research Trigger Criteria" based on your preferences
- **Wiki-Link Density**: Modify target range (currently 5-15 per section)
- **Callout Taxonomy**: Add/remove callout types from your active set
- **Note Length Guidelines**: Adjust word counts for different note types

### **A/B Testing Variations**

**Variant A (Current)**: ReAct + Chain-of-Density + Conditional Research
**Variant B (Research-Heavy)**: Remove conditional logic, always execute web_search
**Variant C (Hyper-Concise)**: Reduce word count targets by 40%, increase wiki-link density

---

## üí° Key Improvements Explained

### **1. Conditional Research Protocol**

> [!methodology-and-sources]
> The original prompt required 5 web searches for every response, creating unnecessary latency and token usage. The optimized version uses explicit criteria to trigger research only when genuinely beneficial.

### **2. ReAct Framework Integration**

> [!what-this-does]
> [[ReAct]] separates "reasoning about the task" from "executing the task," creating a natural cognitive flow. This replaces the ambiguous "show your thinking" with a structured protocol.

### **3. Format Validation Checklist**

> [!principle-point]
> By embedding a pre-output checklist, Claude self-validates format compliance *before* generating the response, dramatically reducing format errors.

### **4. Note Type Taxonomy**

> [!key-claim]
> The vague "substantial request" trigger is replaced with explicit note types (Atomic, Reference, MOC, Synthesis), each with clear formatting expectations.

### **5. Chain-of-Density Operationalization**

> [!important]
> Rather than simply demanding "depth," the prompt specifies a 4-layer information architecture that Claude follows systematically.

---

## üîç Potential Further Enhancements

If you want to push this even further, consider:

1. **[[Tree-of-Thoughts]] for Complex Synthesis**: When generating MOCs or synthesis notes, explore multiple organizational structures before committing
2. **[[Debate Prompting]] for Controversial Topics**: Have Claude generate multiple perspectives before synthesizing
3. **[[Recursive Summarization]] for Long-Form Content**: Build notes hierarchically, summarizing at each level
4. **[[Emotion Prompting]]** (subtle): Inject phrasing like "This is important for building a world-class PKB" to boost output quality
5. **[[Meta-Prompting]]**: Add a final phase where Claude critiques its own output and self-corrects

---

## üéØ Next Steps

1. **Deploy the optimized prompt** in your system instructions
2. **Run the testing protocol** (4 test scenarios above)
3. **Calibrate research threshold** based on your actual usage patterns
4. **Iterate the callout taxonomy** as your PKB evolves
5. **Monitor wiki-link density** - aim for 5-15 per section initially, adjust as needed

---

# üîó Related Topics for PKB Expansion

1. **[[Prompt Engineering Frameworks]]**
   - *Connection*: The techniques used to optimize your prompt (ReAct, CoD, Constitutional AI)
   - *Depth Potential*: Deep dive into each framework's mechanics and applications
   - *Knowledge Graph Role*: Central node connecting AI interaction, system design, and optimization

2. **[[Obsidian Plugin Ecosystem]]**
   - *Connection*: Your prompt references Dataview, Templater, and other plugins
   - *Depth Potential*: Comprehensive guide to leveraging plugins for PKB enhancement
   - *Knowledge Graph Role*: Practical implementation layer for PKM theory

3. **[[Zettelkasten Digital Implementation]]**
   - *Connection*: Your prompt embeds Zettelkasten principles (atomic notes, linking)
   - *Depth Potential*: Systematic exploration of translating analog Zettelkasten to digital
   - *Knowledge Graph Role*: Methodological foundation for PKB architecture

4. **[[Knowledge Graph Theory]]**
   - *Connection*: Wiki-links create graph structures that your prompt optimizes for
   - *Depth Potential*: Graph theory, network analysis, and emergent knowledge structures
   - *Knowledge Graph Role*: Theoretical framework for understanding PKB behavior at scale

```
<thinking>
The user wants two specific enhancements to the optimized prompt:

1. **Optional Self-Critique Phase**: A user-activated trigger `[activate][self-check]` that causes Claude to analyze and improve its previous response. This is a form of [[Meta-Prompting]] or [[Self-Reflection Protocol]].

2. **Metadata Header**: A small section at the beginning of note-type responses with:
   - Obsidian-friendly tags (3-5)
   - Aliases for the note

These are excellent additions that align with:
- **Self-Critique**: Implements [[Constitutional AI]] principles with human-in-the-loop validation
- **Metadata**: Essential for Obsidian's tag-based search and alias functionality

I need to:
1. Add a new section to the prompt called something like `<self_check_protocol>`
2. Define what the self-check analyzes (format compliance, depth, accuracy, wiki-links, etc.)
3. Specify the output format for the critique (should be structured)
4. Add a `<metadata_header>` section specifying how to generate tags and aliases
5. Provide examples of good metadata generation

The self-check should be comprehensive but not overwhelming. It should:
- Re-run the validation checklist
- Identify missed opportunities (wiki-links, callouts)
- Suggest content improvements
- Check for logical coherence
- Verify format compliance

The metadata section should:
- Generate relevant tags using Obsidian's #tag format
- Create meaningful aliases that aid discovery
- Be concise and at the very beginning of notes
- Follow Obsidian's YAML frontmatter conventions
</thinking>
```

## üîÑ Enhanced Prompt with Self-Check Protocol & Metadata Headers

I'll integrate both features into the optimized prompt. Here's the updated production-ready version:

---

```prompt

```

---

## üéØ Key Additions Explained

### **1. Metadata Generation Protocol**

> [!what-this-does]
> The `<metadata_generation>` section provides explicit heuristics for tag and alias generation. This ensures every note begins with proper Obsidian frontmatter, making it immediately searchable and discoverable.

**Example Application:**
For a note about "Prompt Engineering Frameworks":
```yaml
---
tags: #prompt-engineering #ai-optimization #llm-techniques #reference-note
aliases: [Prompting Frameworks, PE Frameworks, Advanced Prompting Methods]
---
```

### **2. Self-Check Protocol**

> [!methodology-and-sources]
> The `<self_check_protocol>` implements [[Meta-Prompting]] - Claude analyzes its own output against quality criteria. This creates a human-in-the-loop validation workflow where you review the initial response, then trigger critique if desired.

**Workflow:**
1. Claude generates response ‚Üí You review
2. If satisfied ‚Üí Accept as-is
3. If uncertain ‚Üí Input `[activate][self-check]`
4. Claude performs 5-phase audit ‚Üí Identifies issues ‚Üí Suggests/implements fixes

### **3. Enhanced Validation Checklist**

> [!important]
> The quality gates now include metadata compliance as a first-class check, ensuring tags and aliases are never forgotten.

---

## üß™ Testing the New Features

### **Test Scenario 1: Metadata Generation**

**Input:** "Create a comprehensive reference note on the Zettelkasten method"

**Expected Output:**
```yaml
---
tags: #zettelkasten #pkm #note-taking-methods #reference-note
aliases: [Slip Box Method, Zettelkasten System, ZK Method]
---
```

### **Test Scenario 2: Self-Check Activation**

**Initial Request:** "Explain Chain-of-Thought prompting"
*(Claude generates response)*

**Follow-up Input:** `[activate][self-check]`

**Expected Behavior:**
- Claude re-analyzes the response using the 5-phase audit
- Identifies any missed wiki-links (e.g., [[Zero-Shot Learning]], [[Few-Shot Prompting]])
- Checks if callouts were semantically appropriate
- Scores the response across multiple dimensions
- Either provides targeted fixes OR regenerates if significant issues found

---

## üìã Usage Guidelines

### **When to Activate Self-Check**

‚úÖ **Use `[activate][self-check]` when:**
- Response seems incomplete or superficial
- You suspect missing wiki-link opportunities
- Format looks inconsistent
- You want a quality assessment before saving to PKB
- Learning to calibrate your expectations with Claude's output

‚ùå **Skip self-check when:**
- Response clearly meets all requirements
- Simple query with obvious correctness
- Iterating rapidly (self-check adds latency)

### **Metadata Header Behavior**

> [!principle-point]
> Metadata headers appear ONLY for note-type responses (Reference Notes, Atomic Notes, MOCs, Synthesis Notes). Simple queries or conversational responses will NOT include metadata.

**Decision Logic:**
```
IF request_type IN [reference_note, atomic_note, moc, synthesis_note]:
    INCLUDE metadata_header
ELSE:
    SKIP metadata_header
```

---

## üîß Customization Options

### **Adjusting Self-Check Rigor**

You can modify the self-check depth by adjusting the audit phases:

**Light Self-Check** (faster):
- Remove Phase 4 (Obsidian Optimization)
- Remove Phase 5 (Cognitive & Pedagogical)
- Keep only Format + Content + Knowledge Graph audits

**Heavy Self-Check** (maximum quality):
- Add Phase 6: Citation & Reference Verification
- Add Phase 7: Comparative Analysis (alternative approaches)
- Require mandatory regeneration if score < 8/10

### **Tag Taxonomy Customization**

Modify the tag generation heuristic to match your PKB structure:

```yaml
# Example: Domain-specific tag system
Primary: #[your-domain]
Secondary: #[methodology]
Tertiary: #[content-type]
Optional: #[status] #[priority]
```

---

## üí° Advanced Usage: Iterative Refinement Workflow

**Optimal Pattern:**
1. **Initial Request** ‚Üí Claude generates response
2. **Quick Review** ‚Üí You scan for obvious issues
3. **Conditional Self-Check** ‚Üí If unsure, trigger `[activate][self-check]`
4. **Review Critique** ‚Üí Claude's analysis reveals issues
5. **Targeted Refinement** ‚Üí Either accept fixes OR provide specific guidance
6. **Save to PKB** ‚Üí Paste directly into Obsidian vault

**This creates a quality assurance loop** where Claude becomes progressively better aligned with your PKB standards.

---

## üéì Pedagogical Note: Why This Structure Works

> [!key-claim]
> The combination of **metadata headers** + **self-check protocol** implements a [[Dual-Process Quality System]]:
> 
> - **Metadata** ensures discoverability and graph integration (System 1: automatic)
> - **Self-Check** enables deliberate quality validation (System 2: analytical)

This mirrors how expert researchers work: they automatically apply formatting conventions while maintaining capacity for deep self-critique when stakes are high.

---

# üîó Related Topics for PKB Expansion

1. **[[Meta-Prompting Techniques]]**
   - *Connection*: Self-check protocol is a form of meta-prompting where LLMs analyze their own outputs
   - *Depth Potential*: Comprehensive exploration of self-reflection, self-correction, and iterative improvement in LLMs
   - *Knowledge Graph Role*: Links prompt engineering to AI safety, alignment, and quality assurance

2. **[[Obsidian Metadata Systems]]**
   - *Connection*: Tag and alias generation requires deep understanding of Obsidian's metadata handling
   - *Depth Potential*: Exploration of YAML frontmatter, tag hierarchies, and metadata-driven workflows
   - *Knowledge Graph Role*: Technical implementation layer for PKB optimization

3. **[[Quality Assurance in Knowledge Work]]**
   - *Connection*: The self-check protocol embeds QA principles into content generation
   - *Depth Potential*: Systematic exploration of validation frameworks, audit methodologies, and quality gates
   - *Knowledge Graph Role*: Cross-domain connection between PKM, software engineering, and research methodology

4. **[[Human-in-the-Loop AI Systems]]**
   - *Connection*: Optional self-check activation creates a hybrid human-AI workflow
   - *Depth Potential*: Analysis of when to rely on automation vs. when to invoke validation
   - *Knowledge Graph Role*: Broader context of AI collaboration patterns and decision-making frameworks